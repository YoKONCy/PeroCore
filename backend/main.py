#  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
#  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
#  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
#  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
#  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
#  â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• 
#                                      
#          v     v
#         ( > â€¿ < )   < Hi~ Master!
#         /  |><|  \
#        (  _____  )
#

import asyncio
import os
import sys
import warnings

# --- Suppress Logging & Progress Bars (MUST BE FIRST) ---
os.environ["TQDM_DISABLE"] = "1"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning) # General user warnings
# Specifically ignore CryptographyDeprecationWarning from pypdf/cryptography
try:
    from cryptography.utils import CryptographyDeprecationWarning
    warnings.filterwarnings("ignore", category=CryptographyDeprecationWarning)
except ImportError:
    pass
# --------------------------------------------------------

# è·¯å¾„é˜²å¾¡ï¼šç¡®ä¿æ‰“åŒ…åæˆ–ä¸åŒç›®å½•ä¸‹å¯åŠ¨éƒ½èƒ½æ­£ç¡®æ‰¾åˆ°æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

import json
import base64
import re
import uuid
import psutil
import time
import secrets
from datetime import datetime
from typing import List, Dict, Any, Optional
import io

if os.name == 'nt':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    if sys.stdout is not None:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if sys.stderr is not None:
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Initialize Logging
import logging
from utils.logging_config import configure_logging
log_file = os.environ.get("PERO_LOG_FILE")
configure_logging(log_file=log_file)

logger = logging.getLogger(__name__)

# [DEBUG] Print startup args and env for troubleshooting
print(f"[å¯åŠ¨è°ƒè¯•] sys.argv: {sys.argv}")
print(f"[å¯åŠ¨è°ƒè¯•] ENABLE_SOCIAL_MODE ç¯å¢ƒå˜é‡: {os.environ.get('ENABLE_SOCIAL_MODE')}")

import uvicorn
from contextlib import asynccontextmanager
from fastapi import FastAPI, Depends, HTTPException, Body, BackgroundTasks, UploadFile, File, WebSocket, WebSocketDisconnect, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from sqlmodel import Session, select, delete, desc
from sqlalchemy import func
from sqlmodel.ext.asyncio.session import AsyncSession
from pydantic import BaseModel, Field
import subprocess

from models import Memory, Config, PetState, ScheduledTask, AIModelConfig, MCPConfig, VoiceConfig, ConversationLog, MaintenanceRecord, AgentProfile
from database import init_db, get_session
from services.agent_service import AgentService
from services.memory_service import MemoryService
from services.memory_secretary_service import MemorySecretaryService
from services.asr_service import get_asr_service
from services.tts_service import get_tts_service
from services.realtime_session_manager import realtime_session_manager
from services.companion_service import companion_service
from services.embedding_service import embedding_service
from services.browser_bridge_service import browser_bridge_service
from services.screenshot_service import screenshot_manager
from services.gateway_client import gateway_client
from services.scheduler_service import scheduler_service
from nit_core.plugins.social_adapter.social_service import get_social_service
from core.config_manager import get_config_manager
from core.nit_manager import get_nit_manager
from nit_core.dispatcher import XMLStreamFilter
from routers.ide_router import router as ide_router
from routers.agent_router import router as agent_router
from routers.group_chat_router import router as group_chat_router
from routers.scheduler_router import router as scheduler_router


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup Technical Fingerprint
    print(r"""
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  
â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•
""")
    print("="*50)
    print("ğŸš€ PeroCore åç«¯å¯åŠ¨ä¸­...")
    print(f"ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {os.environ.get('PERO_DATA_DIR', 'Default')}")
    
    # Check Rust Core
    try:
        from pero_memory_core import SemanticVectorIndex
        print("ğŸ§  KDN å¼•æ“: [å°±ç»ª] (pero_memory_core å·²åŠ è½½)")
    except ImportError:
        print("ğŸ§  KDN å¼•æ“: [ç¦ç”¨] (æœªæ‰¾åˆ° pero_memory_core)")
    
    # Check Vector Store
    from services.vector_store_service import VectorStoreService
    vs = VectorStoreService()
    print(f"ğŸ“Š è®°å¿†èŠ‚ç‚¹æ•°: {vs.count_memories() if hasattr(vs, 'count_memories') else 'N/A'}")
    print("="*50)

    # Startup
    await init_db()
    
    # Load Config from DB
    await get_config_manager().load_from_db()
    
    # [Debug] Print loaded critical configs
    cm = get_config_manager()
    print(f"ğŸ”§ å½“å‰é…ç½®çŠ¶æ€:")
    print(f"   - è½»é‡æ¨¡å¼: {cm.get('lightweight_mode')}")
    print(f"   - é™ªä¼´æ¨¡å¼: {cm.get('companion_mode_enabled')}")
    print(f"   - ç¤¾äº¤æ¨¡å¼: {cm.get('enable_social_mode')}")
    print("="*50)
    
    await seed_voice_configs()
    await companion_service.start()
    screenshot_manager.start_background_task()
    
    # å¼‚æ­¥é¢„çƒ­ Embedding æ¨¡å‹
    asyncio.create_task(asyncio.to_thread(embedding_service.warm_up))
    
    # å¼‚æ­¥é¢„çƒ­ ASR æ¨¡å‹
    asr_service = get_asr_service()
    asyncio.create_task(asyncio.to_thread(asr_service.warm_up))
    
    # Start Social Service (if enabled)
    social_service = get_social_service()
    await social_service.start()

    # Start Gateway Client
    gateway_client.start_background()

    # Initialize Scheduler
    scheduler_service.initialize()

    # Initialize RealtimeSessionManager with Gateway
    realtime_session_manager.initialize()

    # Start AuraVision (if enabled)
    config_mgr = get_config_manager()
    if config_mgr.get("aura_vision_enabled", False):
        from services.aura_vision_service import aura_vision_service
        if aura_vision_service.initialize():
            asyncio.create_task(aura_vision_service.start_vision_loop())
        else:
            print("[Main] åˆå§‹åŒ– AuraVision æœåŠ¡å¤±è´¥ã€‚")

    # Cleanup task
    async def periodic_cleanup():
        while True:
            try:
                tts = get_tts_service()
                tts.cleanup_old_files(max_age_seconds=3600)
                
                # Cleanup temp_vision
                # [Refactor] ç»Ÿä¸€æŒ‡å‘ backend/data/temp_vision
                default_data_dir = os.path.join(current_dir, "data")
                data_dir = os.environ.get("PERO_DATA_DIR", default_data_dir)
                temp_vision = os.path.join(data_dir, "temp_vision")
                if os.path.exists(temp_vision):
                    now = time.time()
                    for f in os.listdir(temp_vision):
                        f_path = os.path.join(temp_vision, f)
                        if os.path.isfile(f_path):
                            if now - os.path.getmtime(f_path) > 3600: # 1 hour
                                try:
                                    os.remove(f_path)
                                except: pass
            except Exception as e:
                print(f"[Main] æ¸…ç†ä»»åŠ¡é”™è¯¯: {e}")
            await asyncio.sleep(3600)
    
    cleanup_task = asyncio.create_task(periodic_cleanup())

    # [Feature] Thinking Pipeline: Weekly Report Task
    async def periodic_weekly_report_check():
        from services.chain_service import chain_service
        from database import engine
        from sqlalchemy.orm import sessionmaker
        
        # Initial delay to let DB settle
        await asyncio.sleep(30) 
        
        while True:
            try:
                async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
                async with async_session() as session:
                    # Check last report time
                    config_key = "last_weekly_report_time"
                    config = await session.get(Config, config_key)
                    
                    should_run = False
                    now = datetime.now()
                    
                    if not config:
                        # First run: Run immediately for demo purposes
                        should_run = True
                    else:
                        try:
                            last_time = datetime.fromisoformat(config.value)
                            if (now - last_time).total_seconds() > 7 * 24 * 3600:
                                should_run = True
                        except:
                            should_run = True # corrupted date
                            
                    if should_run:
                        print("[Main] æ­£åœ¨è§¦å‘å‘¨æŠ¥ç”Ÿæˆ...")
                        report = await chain_service.generate_weekly_report(session)
                        
                        if report:
                            # [Modified] No longer saving to ConversationLog (Chat Window)
                            # log = ConversationLog(...)
                            # session.add(log)

                            # [Feature] Save Weekly Report to File (pero_workspace/log)
                            try:
                                import os
                                # Get backend dir (assuming main.py is in backend/)
                                backend_dir = os.path.dirname(os.path.abspath(__file__))
                                # Path: PeroCore/pero_workspace/log
                                # We need to go up from backend? No, structure is PeroCore/backend.
                                # User said "PeroCore\pero_workspace\log". 
                                # Assuming workspace is at project root (PeroCore/).
                                project_root = os.path.dirname(backend_dir)
                                # [Update] Change path to pero_workspace/{agent_id}/weeklyport
                                from services.agent_manager import AgentManager
                                agent_manager = AgentManager()
                                active_agent_id = agent_manager.active_agent_id
                                log_dir = os.path.join(project_root, "pero_workspace", active_agent_id, "weeklyport")
                                os.makedirs(log_dir, exist_ok=True)
                                
                                filename = f"{now.strftime('%Y-%m-%d')}_Weekly_Report.md"
                                file_path = os.path.join(log_dir, filename)
                                
                                with open(file_path, "w", encoding="utf-8") as f:
                                    f.write(report)
                                    
                                print(f"[Main] å‘¨æŠ¥å·²ä¿å­˜åˆ°æ–‡ä»¶: {file_path}")
                                
                                # [Feature] Persist Weekly Report Index to Memory (VectorDB)
                                # We store a summary/pointer instead of full content to keep context clean?
                                # User said "store index for retrieval in database".
                                # We will store the full content but mark it with specific type for "Independent Retrieval".
                                # Actually, storing full content is better for search unless it's huge.
                                # But we'll add the file path reference.
                                
                                # [Update] Update file path in DB content
                                # [Modified] User requested NOT to store document types in DB at all.
                                # db_content = f"ã€å‘¨æŠ¥å½’æ¡£ã€‘{now.strftime('%Y-%m-%d')}\n> ğŸ“ File Archived: weeklyport/{filename}\n\n{report}"
                                
                                # await MemoryService.save_memory(
                                #     session=session,
                                #     content=db_content,
                                #     tags="weekly_report,summary",
                                #     clusters="[å‘¨æŠ¥å½’æ¡£]",
                                #     importance=3, # High importance
                                #     memory_type="weekly_report", # Special type for independent retrieval
                                #     source="system"
                                # )
                                print("[Main] å‘¨æŠ¥ä»…ä¿å­˜åˆ°æ–‡ä»¶ (DB å­˜å‚¨å·²æŒ‰ç”¨æˆ·è¯·æ±‚ç¦ç”¨)ã€‚")
                            except Exception as e:
                                print(f"[Main] ä¿å­˜å‘¨æŠ¥å¤±è´¥: {e}")
                            
                            # Update Config
                            if not config:
                                config = Config(key=config_key, value=now.isoformat())
                                session.add(config)
                            else:
                                config.value = now.isoformat()
                                config.updated_at = now
                            
                            await session.commit()
                            print("[Main] å‘¨æŠ¥å·²ç”Ÿæˆå¹¶ä¿å­˜ (é™é»˜æ¨¡å¼)ã€‚")

                            # [Modified] No longer broadcasting to Frontend
                            # try:
                            #     ...
                            # except ...
                        else:
                            print("[Main] å‘¨æŠ¥ç”Ÿæˆå·²è·³è¿‡ (æ— å†…å®¹/é”™è¯¯)ã€‚")
                            
            except Exception as e:
                print(f"[Main] å‘¨æŠ¥ä»»åŠ¡é”™è¯¯: {e}")
            
            # Check every hour
            await asyncio.sleep(3600)

    weekly_report_task = asyncio.create_task(periodic_weekly_report_check())

    # [Feature] Dream Mode: Daily trigger at 22:00
    async def periodic_dream_check():
        from database import engine
        from sqlalchemy.orm import sessionmaker
        from datetime import timedelta
        
        await asyncio.sleep(60) # Initial delay
        
        while True:
            try:
                async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
                async with async_session() as session:
                    now = datetime.now()
                    
                    # Calculate the latest scheduled trigger time (22:00)
                    if now.hour < 22:
                        latest_scheduled = now.replace(hour=22, minute=0, second=0, microsecond=0) - timedelta(days=1)
                    else:
                        latest_scheduled = now.replace(hour=22, minute=0, second=0, microsecond=0)
                    
                    # Check last trigger time
                    config_key = "last_dream_trigger_time"
                    config = await session.get(Config, config_key)
                    
                    last_trigger_time = datetime.min
                    if config:
                        try:
                            last_trigger_time = datetime.fromisoformat(config.value)
                        except:
                            pass
                    
                    if last_trigger_time < latest_scheduled:
                        print(f"[Main] è§¦å‘å®šæ—¶æ¢¦å¢ƒæ¨¡å¼ (ä¸Šæ¬¡: {last_trigger_time}, è®¡åˆ’: {latest_scheduled})")
                        # Instantiate AgentService to use its _trigger_dream method
                        from services.agent_service import AgentService
                        agent_service = AgentService(session)
                        await agent_service._trigger_dream()
            except Exception as e:
                print(f"[Main] æ¢¦å¢ƒæ£€æŸ¥ä»»åŠ¡é”™è¯¯: {e}")
            
            # Check every 15 minutes
            await asyncio.sleep(900)

    # [Feature] Memory Maintenance & Dream: Daily trigger at 22:00 PM
    async def periodic_memory_maintenance_check():
        from database import engine
        from sqlalchemy.orm import sessionmaker
        from datetime import timedelta
        
        await asyncio.sleep(120) # Initial delay
        
        while True:
            try:
                async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
                async with async_session() as session:
                    now = datetime.now()
                    
                    # Calculate the latest scheduled trigger time (22:00 PM)
                    if now.hour < 22:
                        latest_scheduled = now.replace(hour=22, minute=0, second=0, microsecond=0) - timedelta(days=1)
                    else:
                        latest_scheduled = now.replace(hour=22, minute=0, second=0, microsecond=0)
                    
                    # Check last maintenance time
                    config_key = "last_memory_maintenance_time"
                    config = await session.get(Config, config_key)
                    
                    last_time = datetime.min
                    if config:
                        try:
                            last_time = datetime.fromisoformat(config.value)
                        except:
                            pass
                    
                    if last_time < latest_scheduled:
                        print(f"[Main] è§¦å‘å®šæ—¶è®°å¿†ç»´æŠ¤ä¸æ¢¦å¢ƒ (ä¸Šæ¬¡: {last_time}, è®¡åˆ’: {latest_scheduled})")
                        
                        # 1. Trigger Memory Secretary (Maintenance)
                        from services.memory_secretary_service import MemorySecretaryService
                        maintenance_service = MemorySecretaryService(session)
                        
                        # 2. Trigger Agent Service (Dream)
                        from services.agent_service import AgentService
                        agent_service = AgentService(session)

                        # Run both in parallel
                        try:
                            await asyncio.gather(
                                maintenance_service.run_maintenance(),
                                agent_service._trigger_dream()
                            )
                        except Exception as inner_e:
                            print(f"[Main] ç»´æŠ¤/æ¢¦å¢ƒä»»åŠ¡å†…éƒ¨é”™è¯¯: {inner_e}")
                        
                        # Update config
                        if not config:
                            config = Config(key=config_key, value=now.isoformat())
                            session.add(config)
                        else:
                            config.value = now.isoformat()
                            config.updated_at = now
                        await session.commit()
                        
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"[Main] è®°å¿†ç»´æŠ¤æ£€æŸ¥ä»»åŠ¡é”™è¯¯: {e!s}")
            
            # Check every 1 hour
            await asyncio.sleep(3600)

    maintenance_task = asyncio.create_task(periodic_memory_maintenance_check())

    # [Feature] Lonely Memory Scanner: Hourly trigger
    async def periodic_lonely_scan_check():
        from database import engine
        from sqlalchemy.orm import sessionmaker
        from services.reflection_service import ReflectionService
        
        # Initial delay to stagger with other tasks
        await asyncio.sleep(300) 
        
        while True:
            try:
                # [Optimization] Check if system is under heavy load or user is chatting?
                # For now, rely on async concurrency. 
                # scan_lonely_memories yields frequently (DB, LLM).
                
                # print("[Main] Starting hourly lonely memory scan...", flush=True)
                async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
                async with async_session() as session:
                    service = ReflectionService(session)
                    await service.scan_lonely_memories(limit=2)
            except Exception as e:
                print(f"[Main] å­¤ç‹¬è®°å¿†æ‰«æä»»åŠ¡é”™è¯¯: {e}")
            
            # Check every 1 hour
            await asyncio.sleep(3600)

    lonely_scan_task = asyncio.create_task(periodic_lonely_scan_check())

    # [Feature] Periodic Trigger Check (Reminders & Topics)
    # Replaces frontend polling with backend scheduling
    async def execute_and_broadcast_chat(instruction: str, session: AsyncSession):
        """Execute a trigger chat and broadcast the result to all connected clients."""
        from services.agent_service import AgentService
        agent_service = AgentService(session)
        full_response = ""
        
        try:
            # 1. Notify clients that Pero is thinking
            await realtime_session_manager.broadcast({"type": "status", "content": "thinking"})
            
            # 2. Run the chat
            async for chunk in agent_service.chat(
                messages=[], 
                source="system_trigger", 
                system_trigger_instruction=instruction
            ):
                if chunk:
                    full_response += chunk
            
            if full_response:
                # 3. Clean and parse response (using realtime_session_manager's logic)
                ui_response = realtime_session_manager._clean_text(full_response, for_tts=False)
                tts_response = realtime_session_manager._clean_text(full_response, for_tts=True)
                
                # 4. Broadcast the text response
                await realtime_session_manager.broadcast({"type": "status", "content": "speaking"})
                await realtime_session_manager.broadcast({"type": "text_response", "content": ui_response})
                
                # 5. Handle TTS and broadcast audio (Optional but recommended for consistency)
                target_voice, target_rate, target_pitch = realtime_session_manager._get_voice_params(full_response)
                tts_service = get_tts_service()
                audio_path = await tts_service.synthesize(
                    tts_response,
                    voice=target_voice,
                    rate=target_rate,
                    pitch=target_pitch
                )
                
                if audio_path:
                    ext = os.path.splitext(audio_path)[1].replace('.', '') or "mp3"
                    with open(audio_path, "rb") as f:
                        audio_content = f.read()
                        audio_b64 = base64.b64encode(audio_content).decode('utf-8')
                        await realtime_session_manager.broadcast({
                            "type": "audio_response", 
                            "data": audio_b64,
                            "format": ext
                        })
                
                # 6. Reset to idle
                await realtime_session_manager.broadcast({"type": "status", "content": "idle"})
        except Exception as e:
            print(f"[Main] æ‰§è¡Œå¹¶å¹¿æ’­è§¦å‘å¯¹è¯å¤±è´¥: {e}")
            await realtime_session_manager.broadcast({"type": "status", "content": "idle"})

    async def periodic_trigger_check():
        from database import engine
        from sqlalchemy.orm import sessionmaker
        
        await asyncio.sleep(10) # Initial delay
        
        while True:
            try:
                async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
                async with async_session() as session:
                    now = datetime.now()
                    tasks = (await session.exec(select(ScheduledTask).where(ScheduledTask.is_triggered == False))).all()
                    
                    # 1. Reminders
                    due_reminders = [t for t in tasks if t.type == "reminder" and datetime.fromisoformat(t.time.replace('Z', '+00:00')).replace(tzinfo=None) <= now]
                    for task in due_reminders:
                        print(f"[Main] è§¦å‘æé†’: {task.content}")
                        instruction = f"ã€ç®¡ç†ç³»ç»Ÿæé†’ï¼šPeroï¼Œä½ ä¸ä¸»äººçš„çº¦å®šæ—¶é—´å·²åˆ°ï¼Œè¯·ä¸»åŠ¨æé†’ä¸»äººã€‚çº¦å®šå†…å®¹ï¼š{task.content}ã€‘"
                        
                        # Mark as triggered FIRST
                        task.is_triggered = True
                        session.add(task)
                        await session.commit()
                        
                        # Trigger Chat and Broadcast
                        await execute_and_broadcast_chat(instruction, session)
                            
                    # 2. Topics (Grouped)
                    due_topics = [t for t in tasks if t.type == "topic" and not t.is_triggered and datetime.fromisoformat(t.time.replace('Z', '+00:00')).replace(tzinfo=None) <= now]
                    
                    if due_topics:
                        topic_list_str = "\n".join([f"- {t.content}" for t in due_topics])
                        print(f"[Main] Triggering Topics: {len(due_topics)} items")
                        instruction = f"ã€ç®¡ç†ç³»ç»Ÿæé†’ï¼šPeroï¼Œä»¥ä¸‹æ˜¯ä½ ä¹‹å‰æƒ³æ‰¾ä¸»äººèŠçš„è¯é¢˜ï¼ˆå·²æ±‡æ€»ï¼‰ï¼š\n{topic_list_str}\n\nè¯·å°†è¿™äº›è¯é¢˜è‡ªç„¶åœ°èåˆåœ¨ä¸€èµ·ï¼Œä½œä¸ºä¸€æ¬¡ä¸»åŠ¨çš„èŠå¤©å¼€åœºã€‚ã€‘"
                        
                        for t in due_topics:
                            t.is_triggered = True
                            session.add(t)
                        await session.commit()
                        
                        # Trigger Chat and Broadcast
                        await execute_and_broadcast_chat(instruction, session)

                    # 3. Reactions (Pre-actions)
                    due_reactions = [t for t in tasks if t.type == "reaction" and not t.is_triggered and datetime.fromisoformat(t.time.replace('Z', '+00:00')).replace(tzinfo=None) <= now]
                    for task in due_reactions:
                        print(f"[Main] è§¦å‘ååº”: {task.content}")
                        instruction = f"ã€ç®¡ç†ç³»ç»Ÿæé†’ï¼šPeroï¼Œä½ ä¹‹å‰å†³å®šï¼šâ€˜{task.content}â€™ã€‚ç°åœ¨è§¦å‘æ—¶é—´å·²åˆ°ï¼Œè¯·ç«‹åˆ»æ‰§è¡Œè¯¥è¡Œä¸ºã€‚ã€‘"
                        
                        task.is_triggered = True
                        session.add(task)
                        await session.commit()
                        
                        await execute_and_broadcast_chat(instruction, session)

            except Exception as e:
                print(f"[Main] è§¦å‘æ£€æŸ¥ä»»åŠ¡é”™è¯¯: {e}")
            
            await asyncio.sleep(30) # Check every 30 seconds

    trigger_task = asyncio.create_task(periodic_trigger_check())
    
    # Start Gateway Client
    gateway_client.start_background()
    print("[Main] Gateway å®¢æˆ·ç«¯å·²å¯åŠ¨ã€‚")

    yield
    
    # Shutdown
    await gateway_client.stop()
    cleanup_task.cancel()
    weekly_report_task.cancel()
    # dream_task is not defined here, it's inside maintenance_task
    maintenance_task.cancel()
    trigger_task.cancel()
    lonely_scan_task.cancel() # Added
    
    try:
        await cleanup_task
        await weekly_report_task
        await maintenance_task
        await trigger_task
        await lonely_scan_task # Added
    except asyncio.CancelledError:
        pass
    await companion_service.stop()

app = FastAPI(title="PeroCore Backend", description="AI Agent powered backend for Pero", lifespan=lifespan)
app.include_router(ide_router)
app.include_router(agent_router)
app.include_router(group_chat_router)

# [Plugin] Social Adapter Router
from nit_core.plugins.social_adapter.social_router import router as social_router
app.include_router(social_router)

app.include_router(scheduler_router, prefix="/api/scheduler", tags=["Scheduler"])

class TTSPreviewRequest(BaseModel):
    text: str

@app.post("/api/tts/preview")
async def preview_tts(request: TTSPreviewRequest):
    """
    Generate TTS audio for the given text, applying the same filtering and mood analysis as the voice mode.
    """
    text = request.text
    if not text:
        raise HTTPException(status_code=400, detail="Text is empty")

    # 1. Clean Text (Reuse logic from RealtimeSessionManager)
    # _clean_text is protected but we access it here for consistency
    cleaned_text = realtime_session_manager._clean_text(text, for_tts=True)
    
    if not cleaned_text or not cleaned_text.strip():
        # If nothing remains (e.g. only thinking process), return 204 No Content or 400
        # Front-end should handle this gracefully
        raise HTTPException(status_code=400, detail="No speakable text content")
    
    # 2. Get Voice Params (Mood analysis based on FULL original text)
    voice, rate, pitch = realtime_session_manager._get_voice_params(text)
    
    # 3. Synthesize
    tts = get_tts_service()
    
    filepath = await tts.synthesize(cleaned_text, voice=voice, rate=rate, pitch=pitch)
    
    if not filepath or not os.path.exists(filepath):
        raise HTTPException(status_code=500, detail="TTS generation failed")
        
    return FileResponse(filepath, media_type="audio/mpeg", filename="preview.mp3")


dist_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "dist")
if os.path.exists(dist_path):
    app.mount("/web", StaticFiles(directory=dist_path, html=True), name="static")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Models for Validation ---

class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    source: str = "desktop"
    session_id: str = Field(default="default", alias="sessionId")
    
    # å…è®¸å‰ç«¯ä¼ å…¥å»ºè®®å€¼ï¼Œä½†åç«¯ä¼šæ ¹æ®ç­–ç•¥å†³å®šæ˜¯å¦ä½¿ç”¨
    model: Optional[str] = None
    temperature: Optional[float] = None

async def verify_token(authorization: Optional[str] = Header(None), session: AsyncSession = Depends(get_session)):
    """
    éªŒè¯å‰ç«¯ä¼ æ¥çš„ Tokenã€‚å®ç°â€œå‰ç«¯ä¸å¯ä¿¡â€åŸåˆ™çš„ç¬¬ä¸€æ­¥ã€‚
    """
    # è·å–åç«¯é¢„è®¾çš„ Access Token
    config_stmt = select(Config).where(Config.key == "frontend_access_token")
    config_result = await session.exec(config_stmt)
    db_config = config_result.first()
    
    expected_token = db_config.value if db_config else "pero_default_token"
    
    # å¦‚æœæ˜¯æœ¬åœ°å¼€å‘ç¯å¢ƒä¸”æ²¡æœ‰è®¾ç½® tokenï¼Œå¯ä»¥æ”¾è¡Œ (å¯é€‰)
    # if not db_config and os.environ.get("ENV") == "dev": return
    
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="æœªæˆæƒè®¿é—®ï¼šç¼ºå°‘ä»¤ç‰Œ")
    
    token = authorization.split(" ")[1]
    if token != expected_token:
        raise HTTPException(status_code=403, detail="æœªæˆæƒè®¿é—®ï¼šä»¤ç‰Œæ— æ•ˆ")
    
    return token

async def seed_voice_configs():
    async for session in get_session():
        # Seed Voice Configs
        result = await session.exec(select(VoiceConfig).where(VoiceConfig.type == "stt"))
        if not result.first():
            stt = VoiceConfig(type="stt", name="Local Whisper (Default)", provider="local_whisper", is_active=True, model="whisper-tiny", config_json='{"device": "cpu", "compute_type": "int8"}')
            session.add(stt)
        result = await session.exec(select(VoiceConfig).where(VoiceConfig.type == "tts"))
        if not result.first():
            tts = VoiceConfig(type="tts", name="Edge TTS (Default)", provider="edge_tts", is_active=True, config_json='{"voice": "zh-CN-XiaoyiNeural", "rate": "+15%", "pitch": "+5Hz"}')
            session.add(tts)
            
        # Seed Frontend Access Token (Dynamic Handshake Security)
        # å°è¯•ä» Gateway ç”Ÿæˆçš„ä»¤ç‰Œæ–‡ä»¶ä¸­è¯»å–
        # è·¯å¾„: backend/data/gateway_token.json
        token_path = os.path.join(current_dir, "data", "gateway_token.json")
        new_dynamic_token = None
        
        if os.path.exists(token_path):
            try:
                with open(token_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    new_dynamic_token = data.get("token")
                    print(f"[Main] å·²åŠ è½½ Gateway ä»¤ç‰Œ: {new_dynamic_token[:8]}...")
            except Exception as e:
                print(f"[Main] è¯»å– Gateway ä»¤ç‰Œå¤±è´¥: {e}")

        # Fallback if file not found (e.g. Gateway not started)
        if not new_dynamic_token:
            new_dynamic_token = secrets.token_urlsafe(32)
            print(f"[Main] è­¦å‘Š: æœªæ‰¾åˆ° Gateway ä»¤ç‰Œæ–‡ä»¶ã€‚å·²ç”Ÿæˆæœ¬åœ°å›é€€ä»¤ç‰Œã€‚")
        
        token_stmt = select(Config).where(Config.key == "frontend_access_token")
        token_result = await session.exec(token_stmt)
        existing_token = token_result.first()
        
        if not existing_token:
            token_config = Config(key="frontend_access_token", value=new_dynamic_token)
            session.add(token_config)
        else:
            existing_token.value = new_dynamic_token
            existing_token.updated_at = datetime.utcnow()
            session.add(existing_token)
            
        # Configure GatewayClient with this token
        gateway_client.set_token(new_dynamic_token)

        print(f"\n" + "="*60)
        print(f"ğŸ›¡ï¸  PERO-CORE å®‰å…¨æ¨¡å¼å·²å¯åŠ¨")
        print(f"ğŸ”‘ åŠ¨æ€è®¿é—®ä»¤ç‰Œ (Handshake Token):")
        print(f"    {new_dynamic_token}")
        print(f"âš ï¸  è¯·æ³¨æ„ï¼šæ­¤ä»¤ç‰Œç”± Gateway ç”Ÿæˆ (æˆ–æœ¬åœ°å›é€€)ï¼Œç”¨äºå‰åç«¯æ¡æ‰‹åŠ HTTP é‰´æƒã€‚")
        print(f"="*60 + "\n")
            
        await session.commit()
        break

@app.websocket("/ws/browser")
async def websocket_browser_endpoint(websocket: WebSocket):
    await browser_bridge_service.connect(websocket)

@app.get("/api/pet/state")
async def get_pet_state(session: AsyncSession = Depends(get_session)):
    try:
        # Get active agent info FIRST
        from services.agent_manager import get_agent_manager
        agent_manager = get_agent_manager()
        active_agent = agent_manager.get_active_agent()
        active_agent_id = active_agent.id if active_agent else "pero"

        # Find PetState for active agent
        statement = select(PetState).where(PetState.agent_id == active_agent_id)
        state = (await session.exec(statement)).first()
        
        if not state:
            # åˆå§‹åŒ–é»˜è®¤çŠ¶æ€
            state = PetState(
                agent_id=active_agent_id,
                mood="å¼€å¿ƒ",
                vibe="æ­£å¸¸",
                mind="æ­£åœ¨æƒ³ä¸»äºº..."
            )
            session.add(state)
            await session.commit()
            await session.refresh(state)
            
        # Convert to dict and add active_agent info
        response_data = state.model_dump()
        if active_agent:
            response_data["active_agent"] = {
                "id": active_agent.id,
                "name": active_agent.name
            }
            
        return response_data
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/ping")
async def ping():
    return {"status": "ok", "timestamp": datetime.now().isoformat()}

@app.get("/api/system/status")
async def get_system_status():
    try:
        # psutil.cpu_percent(interval=None) returns immediately if called before, 
        # but might return 0.0 on first call. 
        # Since we poll, it should be fine.
        cpu_percent = psutil.cpu_percent(interval=None) 
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "cpu": {
                "percent": cpu_percent,
                "count": psutil.cpu_count()
            },
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "used": memory.used
            },
            "disk": {
                "total": disk.total,
                "used": disk.used,
                "percent": disk.percent
            },
            "boot_time": psutil.boot_time()
        }
    except Exception as e:
        print(f"è·å–ç³»ç»ŸçŠ¶æ€é”™è¯¯: {e}")
        return {"error": str(e)}

@app.get("/api/nit/settings")
async def get_nit_settings():
    """è·å–æ‰€æœ‰ NIT è°ƒåº¦è®¾ç½®"""
    return get_nit_manager().get_all_settings()

@app.post("/api/nit/settings/category")
async def set_nit_category(category: str = Body(..., embed=True), enabled: bool = Body(..., embed=True)):
    """è®¾ç½®åˆ†ç±»å¼€å…³ (Level 1)"""
    get_nit_manager().set_category_status(category, enabled)
    return {"status": "success", "message": f"Category {category} set to {enabled}. Restart required for some changes."}

@app.post("/api/nit/settings/plugin")
async def set_nit_plugin(plugin_name: str = Body(..., embed=True), enabled: bool = Body(..., embed=True)):
    """è®¾ç½®æ’ä»¶å¼€å…³ (Level 2)"""
    get_nit_manager().set_plugin_status(plugin_name, enabled)
    return {"status": "success", "message": f"Plugin {plugin_name} set to {enabled}. Restart required for some changes."}

@app.post("/api/config/social_mode")
async def set_social_mode(enabled: bool = Body(..., embed=True)):
    """
    (Deprecated) Toggle Social Mode. Now handled by NITManager Level 2.
    """
    get_nit_manager().set_plugin_status("social_adapter", enabled)
    
    social_service = get_social_service()
    if enabled:
        await social_service.start()
    else:
        await social_service.stop()
        
    return {"status": "success", "enabled": enabled, "message": "Plugin status updated. Restart required for full effect."}

@app.get("/api/config/social_mode")
async def get_social_mode():
    return {"enabled": get_nit_manager().is_plugin_enabled("social_adapter")}



@app.get("/api/config/lightweight_mode")
async def get_lightweight_mode():
    return {"enabled": get_config_manager().get("lightweight_mode", False)}

@app.post("/api/config/lightweight_mode")
async def set_lightweight_mode(enabled: bool = Body(..., embed=True)):
    await get_config_manager().set("lightweight_mode", enabled)
    return {"status": "success", "enabled": enabled}

@app.get("/api/config/aura_vision")
async def get_aura_vision_mode():
    return {"enabled": get_config_manager().get("aura_vision_enabled", False)}

@app.post("/api/config/aura_vision")
async def set_aura_vision_mode(enabled: bool = Body(..., embed=True)):
    await get_config_manager().set("aura_vision_enabled", enabled)
    
    from services.aura_vision_service import aura_vision_service
    if enabled:
        if not aura_vision_service.is_running:
            if aura_vision_service.initialize():
                asyncio.create_task(aura_vision_service.start_vision_loop())
            else:
                return {"status": "error", "message": "Failed to initialize AuraVision Service"}
    else:
        aura_vision_service.stop()
        
    return {"status": "success", "enabled": enabled}

@app.get("/api/config/tts")
async def get_tts_mode():
    return {"enabled": get_config_manager().get("tts_enabled", True)}

@app.post("/api/config/tts")
async def set_tts_mode(enabled: bool = Body(..., embed=True)):
    await get_config_manager().set("tts_enabled", enabled)
    return {"status": "success", "enabled": enabled}

@app.delete("/api/memories/by_timestamp/{msg_timestamp}")
async def delete_memory_by_timestamp(msg_timestamp: str, session: AsyncSession = Depends(get_session)):
    service = MemoryService()
    await service.delete_by_msg_timestamp(session, msg_timestamp)
    return {"status": "success"}

@app.post("/api/memory/secretary/run")
async def run_memory_secretary(session: AsyncSession = Depends(get_session)):
    try:
        service = MemorySecretaryService(session)
        return await service.run_maintenance()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/history/{source}/{session_id}")
async def get_chat_history(
    source: str, 
    session_id: str, 
    limit: int = 50, 
    offset: int = 0,
    date: str = None,
    sort: str = "asc",
    agent_id: Optional[str] = None, # Add agent_id param
    session: AsyncSession = Depends(get_session)
):
    service = MemoryService()
    # If agent_id is not provided, default to "pero" to maintain backward compatibility,
    # OR we can make it optional in service.get_recent_logs?
    # service.get_recent_logs defaults to "pero".
    # If we want to support "all agents" when agent_id is None, we need to modify service.
    # But usually dashboard views a specific agent.
    # Let's pass agent_id if provided, otherwise default "pero" (handled by service default).
    
    target_agent = agent_id if agent_id else "pero"
    logs = await service.get_recent_logs(session, source, session_id, limit, offset=offset, date_str=date, sort=sort, agent_id=target_agent)
    return [{
        "id": log.id, 
        "role": log.role, 
        "content": log.content, 
        "raw_content": getattr(log, "raw_content", None), # Return raw content
        "timestamp": log.timestamp,
        "sentiment": getattr(log, "sentiment", None),
        "importance": getattr(log, "importance", None),
        "metadata_json": log.metadata_json,
        "analysis_status": getattr(log, "analysis_status", "pending"),
        "retry_count": getattr(log, "retry_count", 0),
        "last_error": getattr(log, "last_error", None)
    } for log in logs]

async def run_retry_background(log_id: int):
    from database import engine
    from sqlmodel.ext.asyncio.session import AsyncSession
    from sqlalchemy.orm import sessionmaker
    from services.scorer_service import ScorerService
    from services.gateway_client import gateway_client
    from peroproto import perolink_pb2
    import uuid
    import time
    
    try:
        async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
        async with async_session() as session:
            scorer = ScorerService(session)
            await scorer.retry_interaction(log_id)
            
            # Broadcast update
            envelope = perolink_pb2.Envelope()
            envelope.id = str(uuid.uuid4())
            envelope.source_id = "backend_main"
            envelope.target_id = "broadcast"
            envelope.timestamp = int(time.time() * 1000)
            envelope.request.action_name = "log_updated"
            envelope.request.params["id"] = str(log_id)
            envelope.request.params["operation"] = "update"
            await gateway_client.send(envelope)
            
    except Exception as e:
        print(f"[Main] åå°é‡è¯•æ—¥å¿— {log_id} å¤±è´¥: {e}")

@app.post("/api/history/{log_id}/retry_analysis")
async def retry_log_analysis(log_id: int, background_tasks: BackgroundTasks, session: AsyncSession = Depends(get_session)):
    log = await session.get(ConversationLog, log_id)
    if not log:
        raise HTTPException(status_code=404, detail="Log not found")
    
    # Check if retryable (e.g. only assistant logs or user logs that are part of a pair)
    # Actually, the user can retry any log, but only paired ones will work in ScorerService.
    # We let ScorerService handle the validation.
    
    background_tasks.add_task(run_retry_background, log_id)
    return {"status": "queued", "message": "Analysis retry started in background"}

@app.delete("/api/history/{log_id}")
async def delete_chat_log(log_id: int, session: AsyncSession = Depends(get_session)):
    try:
        service = MemoryService()
        await service.delete_log(session, log_id)
        
        # Broadcast
        try:
            from services.gateway_client import gateway_client
            from peroproto import perolink_pb2
            import uuid
            import time
            envelope = perolink_pb2.Envelope()
            envelope.id = str(uuid.uuid4())
            envelope.source_id = "backend_main"
            envelope.target_id = "broadcast"
            envelope.timestamp = int(time.time() * 1000)
            envelope.request.action_name = "log_updated"
            envelope.request.params["id"] = str(log_id)
            envelope.request.params["operation"] = "delete"
            await gateway_client.send(envelope)
        except Exception as e:
            print(f"Broadcast delete failed: {e}")

        return {"status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.patch("/api/history/{log_id}")
async def update_chat_log(log_id: int, payload: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    try:
        log = await session.get(ConversationLog, log_id)
        if not log:
            raise HTTPException(status_code=404, detail="Log not found")
        if "content" in payload:
            log.content = payload["content"]
        await session.commit()
        await session.refresh(log)
        
        # Broadcast
        try:
            from services.gateway_client import gateway_client
            from peroproto import perolink_pb2
            import uuid
            import time
            envelope = perolink_pb2.Envelope()
            envelope.id = str(uuid.uuid4())
            envelope.source_id = "backend_main"
            envelope.target_id = "broadcast"
            envelope.timestamp = int(time.time() * 1000)
            envelope.request.action_name = "log_updated"
            envelope.request.params["id"] = str(log_id)
            envelope.request.params["operation"] = "update"
            await gateway_client.send(envelope)
        except Exception as e:
             print(f"Broadcast update failed: {e}")

        return log
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/companion/status")
async def get_companion_status(session: AsyncSession = Depends(get_session)):
    config = await session.get(Config, "companion_mode_enabled")
    enabled = config.value == "true" if config else False
    return {"enabled": enabled}

# --- Task Control APIs ---
from services.task_manager import task_manager

@app.post("/api/task/{session_id}/pause")
async def pause_task(session_id: str):
    success = task_manager.pause(session_id)
    if success:
        return {"status": "success", "message": "Task paused"}
    raise HTTPException(status_code=404, detail="Task not found")

@app.post("/api/task/{session_id}/resume")
async def resume_task(session_id: str):
    success = task_manager.resume(session_id)
    if success:
        return {"status": "success", "message": "Task resumed"}
    raise HTTPException(status_code=404, detail="Task not found")

@app.post("/api/task/{session_id}/inject")
async def inject_instruction(session_id: str, payload: Dict[str, str] = Body(...)):
    instruction = payload.get("instruction")
    if not instruction:
        raise HTTPException(status_code=400, detail="Instruction is required")
        
    success = task_manager.inject_instruction(session_id, instruction)
    if success:
        return {"status": "success", "message": "Instruction injected"}
    raise HTTPException(status_code=404, detail="Task not found")

@app.get("/api/task/{session_id}/status")
async def get_task_status(session_id: str):
    status = task_manager.get_status(session_id)
    if status:
        return {"status": status}
    # If not found, assume idle/completed
    return {"status": "idle"}

@app.post("/api/companion/toggle")
async def toggle_companion(enabled: bool = Body(..., embed=True), session: AsyncSession = Depends(get_session)):
    # [Requirement] Companion mode depends on Lightweight mode
    config_mgr = get_config_manager()
    if enabled and not config_mgr.get("lightweight_mode", False):
        raise HTTPException(status_code=400, detail="è¯·å…ˆå¼€å¯â€œè½»é‡æ¨¡å¼â€åå†å¯åŠ¨é™ªä¼´æ¨¡å¼ã€‚")

    config = await session.get(Config, "companion_mode_enabled")
    if not config:
        config = Config(key="companion_mode_enabled", value="false")
        session.add(config)
    
    config.value = "true" if enabled else "false"
    config.updated_at = datetime.utcnow()
    await session.commit()
    
    # Sync with ConfigManager
    await get_config_manager().set("companion_mode_enabled", enabled)
    
    if enabled:
        await companion_service.start()
    else:
        await companion_service.stop()
        
    return {"status": "success", "enabled": enabled}

# --- Social Mode APIs ---
@app.get("/api/social/status")
async def get_social_status(session: AsyncSession = Depends(get_session)):
    config = await session.get(Config, "enable_social_mode")
    enabled = config.value == "true" if config else False
    return {"enabled": enabled}

@app.post("/api/social/toggle")
async def toggle_social(enabled: bool = Body(..., embed=True), session: AsyncSession = Depends(get_session)):
    # 1. Update DB & Memory
    await get_config_manager().set("enable_social_mode", enabled)
    
    # 2. Update Service
    social_service = get_social_service()
    
    # 3. Refresh NIT Tools (ensure social tools are added/removed)
    try:
        from nit_core.dispatcher import get_dispatcher
        dispatcher = get_dispatcher()
        dispatcher.reload_tools()
        print(f"[Main] NIT Tools reloaded after social mode toggle (Enabled: {enabled})")
    except Exception as e:
        print(f"[Main] Failed to reload NIT tools: {e}")
    
    if enabled:
        await social_service.start()
    else:
        await social_service.stop()
        
    return {"status": "success", "enabled": enabled}

@app.get("/api/tasks", response_model=List[ScheduledTask])
async def get_tasks(agent_id: Optional[str] = None, session: AsyncSession = Depends(get_session)):
    statement = select(ScheduledTask).where(ScheduledTask.is_triggered == False)
    if agent_id:
        statement = statement.where(ScheduledTask.agent_id == agent_id)
    return (await session.exec(statement)).all()

@app.delete("/api/tasks/{task_id}")
async def delete_task(task_id: int, session: AsyncSession = Depends(get_session)):
    try:
        task = await session.get(ScheduledTask, task_id)
        if not task: raise HTTPException(status_code=404, detail="Task not found")
        await session.delete(task)
        await session.commit()
        return {"status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/tasks/check")
async def check_tasks(session: AsyncSession = Depends(get_session)):
    import pytz
    now = datetime.now()
    tasks = (await session.exec(select(ScheduledTask).where(ScheduledTask.is_triggered == False))).all()
    triggered_prompts = []
    
    due_reminders = [t for t in tasks if t.type == "reminder" and datetime.fromisoformat(t.time.replace('Z', '+00:00')).replace(tzinfo=None) <= now]
    if due_reminders:
        task = due_reminders[0]
        triggered_prompts.append(f"ã€ç®¡ç†ç³»ç»Ÿæé†’ï¼šPeroï¼Œä½ ä¸ä¸»äººçš„çº¦å®šæ—¶é—´å·²åˆ°ï¼Œè¯·ä¸»åŠ¨æé†’ä¸»äººã€‚çº¦å®šå†…å®¹ï¼š{task.content}ã€‘")
        task.is_triggered = True
        session.add(task)

    if not triggered_prompts:
         due_topics = [t for t in tasks if t.type == "topic" and datetime.fromisoformat(t.time.replace('Z', '+00:00')).replace(tzinfo=None) <= now]
         if due_topics:
            topic_list_str = "\n".join([f"- {t.content}" for t in due_topics])
            triggered_prompts.append(f"ã€ç®¡ç†ç³»ç»Ÿæé†’ï¼šPeroï¼Œä»¥ä¸‹æ˜¯ä½ ä¹‹å‰æƒ³æ‰¾ä¸»äººèŠçš„è¯é¢˜ï¼ˆå·²æ±‡æ€»ï¼‰ï¼š\n{topic_list_str}\n\nè¯·å°†è¿™äº›è¯é¢˜è‡ªç„¶åœ°èåˆåœ¨ä¸€èµ·ï¼Œä½œä¸ºä¸€æ¬¡ä¸»åŠ¨çš„èŠå¤©å¼€åœºã€‚ã€‘")

            for t in due_topics:
                t.is_triggered = True
                session.add(t)
    
    if not triggered_prompts:
        last_log = (await session.exec(select(ConversationLog).where(ConversationLog.role != "system").order_by(desc(ConversationLog.timestamp)).limit(1))).first()
        if last_log and (now - last_log.timestamp).total_seconds() > 1200:
             pass

    await session.commit()
    return {"prompts": triggered_prompts}

@app.get("/api/configs")
async def get_configs(session: AsyncSession = Depends(get_session)):
    configs = (await session.exec(select(Config))).all()
    return {c.key: c.value for c in configs}

@app.post("/api/configs")
async def update_config(configs: Dict[str, str], session: AsyncSession = Depends(get_session)):
    # [Check] Block enabling incompatible modes if in Work Mode
    try:
        current_session = (await session.exec(select(Config).where(Config.key == "current_session_id"))).first()
        is_work_mode = current_session and current_session.value.startswith("work_")
        
        if is_work_mode:
            blocking_modes = ["lightweight_mode", "companion_mode", "aura_vision_enabled"]
            # Map keys to Chinese names
            name_map = {
                "lightweight_mode": "è½»é‡æ¨¡å¼",
                "companion_mode": "é™ªä¼´æ¨¡å¼",
                "aura_vision_enabled": "ä¸»åŠ¨è§†è§‰æ¨¡å¼"
            }
            
            for key, value in configs.items():
                if key in blocking_modes:
                    # Check if user is trying to enable it (value is true)
                    is_enabling = str(value).lower() == 'true'
                    if is_enabling:
                         raise HTTPException(status_code=403, detail=f"æ— æ³•å¯ç”¨{name_map.get(key, key)}ï¼šå½“å‰å¤„äºå·¥ä½œæ¨¡å¼ï¼ˆä¼šè¯éš”ç¦»ä¸­ï¼‰ã€‚è¯·å…ˆé€€å‡ºå·¥ä½œæ¨¡å¼ã€‚")
    except HTTPException:
        raise
    except Exception as e:
        print(f"[Config] Work Mode check failed: {e}")

    for key, value in configs.items():
        config_obj = await session.get(Config, key)
        if config_obj:
            config_obj.value = value
        else:
            config_obj = Config(key=key, value=value)
            session.add(config_obj)
    await session.commit()
    return {"status": "success"}

@app.get("/api/models", response_model=List[AIModelConfig])
async def get_models(session: AsyncSession = Depends(get_session)):
    return (await session.exec(select(AIModelConfig))).all()

@app.post("/api/models", response_model=AIModelConfig)
async def create_model(model_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    model_data.pop('id', None)
    model = AIModelConfig(**model_data)
    session.add(model)
    await session.commit()
    await session.refresh(model)
    return model

@app.put("/api/models/{model_id}", response_model=AIModelConfig)
async def update_model(model_id: int, model_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    db_model = await session.get(AIModelConfig, model_id)
    if not db_model: raise HTTPException(status_code=404, detail="Model not found")
    for key, value in model_data.items():
        if hasattr(db_model, key) and key not in ['id', 'created_at']:
            setattr(db_model, key, value)
    db_model.updated_at = datetime.utcnow()
    session.add(db_model)
    await session.commit()
    await session.refresh(db_model)
    return db_model

@app.delete("/api/models/{model_id}")
async def delete_model(model_id: int, session: AsyncSession = Depends(get_session)):
    db_model = await session.get(AIModelConfig, model_id)
    if not db_model: raise HTTPException(status_code=404, detail="Model not found")
    await session.delete(db_model)
    await session.commit()
    return {"status": "success"}

@app.get("/api/mcp", response_model=List[MCPConfig])
async def get_mcps(session: AsyncSession = Depends(get_session)):
    return (await session.exec(select(MCPConfig))).all()

@app.post("/api/mcp", response_model=MCPConfig)
async def create_mcp(mcp_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    mcp_data.pop('id', None)
    mcp_data.pop('created_at', None)
    mcp_data.pop('updated_at', None)
    new_mcp = MCPConfig(**mcp_data)
    session.add(new_mcp)
    await session.commit()
    await session.refresh(new_mcp)
    return new_mcp

@app.put("/api/mcp/{mcp_id}", response_model=MCPConfig)
async def update_mcp(mcp_id: int, mcp_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    db_mcp = await session.get(MCPConfig, mcp_id)
    if not db_mcp: raise HTTPException(status_code=404, detail="MCP not found")
    for key, value in mcp_data.items():
        if hasattr(db_mcp, key) and key not in ['id', 'created_at', 'updated_at']:
            setattr(db_mcp, key, value)
    db_mcp.updated_at = datetime.utcnow()
    session.add(db_mcp)
    await session.commit()
    await session.refresh(db_mcp)
    return db_mcp

@app.delete("/api/mcp/{mcp_id}")
async def delete_mcp(mcp_id: int, session: AsyncSession = Depends(get_session)):
    db_mcp = await session.get(MCPConfig, mcp_id)
    if not db_mcp: raise HTTPException(status_code=404, detail="MCP not found")
    await session.delete(db_mcp)
    await session.commit()
    return {"status": "success"}

@app.get("/api/nit/status")
async def get_nit_status(session: AsyncSession = Depends(get_session)):
    from nit_core.dispatcher import get_dispatcher
    dispatcher = get_dispatcher()
    
    # Use PluginManager to get high-level plugin names (e.g. "TimeOps") instead of all commands
    plugin_names = dispatcher.pm.list_plugins()
    plugins_data = [{"name": name} for name in plugin_names]
    
    # Get enabled MCPs count
    mcp_count = len((await session.exec(select(MCPConfig).where(MCPConfig.enabled == True))).all())
    
    return {
        "nit_version": "1.0",
        "plugins_count": len(plugin_names),
        "active_mcp_count": mcp_count,
        "plugins": plugins_data
    }

# --- Memory Dashboard API ---

@app.get("/api/memories/list")
async def list_memories(
    limit: int = 50, 
    offset: int = 0, 
    date_start: str = None, 
    date_end: str = None, 
    tags: str = None,
    type: str = None, # Allow filtering by memory type
    agent_id: Optional[str] = None, # Add agent_id param
    session: AsyncSession = Depends(get_session)
):
    service = MemoryService()
    # Pass agent_id to get_all_memories
    target_agent = agent_id if agent_id else "pero"
    return await service.get_all_memories(session, limit, offset, date_start, date_end, tags, memory_type=type, agent_id=target_agent)

@app.get("/api/memories/graph")
async def get_memory_graph(limit: int = 100, agent_id: Optional[str] = None, session: AsyncSession = Depends(get_session)):
    service = MemoryService()
    target_agent = agent_id if agent_id else "pero"
    return await service.get_memory_graph(session, limit, agent_id=target_agent)

@app.delete("/api/memories/orphaned_edges")
async def delete_orphaned_edges(session: AsyncSession = Depends(get_session)):
    service = MemoryService()
    count = await service.delete_orphaned_edges(session)
    return {"status": "success", "deleted_count": count}

@app.post("/api/memories/scan_lonely")
async def scan_lonely_memories(limit: int = 5, session: AsyncSession = Depends(get_session)):
    from services.reflection_service import ReflectionService
    service = ReflectionService(session)
    result = await service.scan_lonely_memories(limit=limit)
    return result

@app.post("/api/memories/maintenance")
async def run_maintenance(session: AsyncSession = Depends(get_session)):
    from services.memory_secretary_service import MemorySecretaryService
    service = MemorySecretaryService(session)
    result = await service.run_maintenance()
    return result

@app.post("/api/memories/dream")
async def trigger_dream(limit: int = 10, session: AsyncSession = Depends(get_session)):
    from services.reflection_service import ReflectionService
    service = ReflectionService(session)
    result = await service.dream_and_associate(limit=limit)
    return result

@app.get("/api/memories/tags")
async def get_tag_cloud(agent_id: Optional[str] = None, session: AsyncSession = Depends(get_session)):
    service = MemoryService()
    target_agent = agent_id if agent_id else "pero"
    return await service.get_tag_cloud(session, agent_id=target_agent)

@app.get("/api/voice-configs", response_model=List[VoiceConfig])
async def get_voice_configs(session: AsyncSession = Depends(get_session)):
    return (await session.exec(select(VoiceConfig))).all()

@app.post("/api/voice-configs", response_model=VoiceConfig)
async def create_voice_config(config_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    try:
        # æ£€æŸ¥é‡å
        name = config_data.get("name")
        if not name:
            raise HTTPException(status_code=400, detail="åç§°ä¸èƒ½ä¸ºç©º")
            
        existing = (await session.exec(select(VoiceConfig).where(VoiceConfig.name == name))).first()
        if existing:
            raise HTTPException(status_code=400, detail="åç§°å·²å­˜åœ¨")
        
        # ç§»é™¤è‡ªåŠ¨å­—æ®µ
        config_data.pop('id', None)
        config_data.pop('created_at', None)
        config_data.pop('updated_at', None)
        
        new_config = VoiceConfig(**config_data)
        
        # å¦‚æœæ˜¯æ¿€æ´»çŠ¶æ€ï¼Œéœ€è¦å–æ¶ˆåŒç±»å‹çš„å…¶ä»–æ¿€æ´»
        if new_config.is_active:
             others = (await session.exec(
                select(VoiceConfig).where(VoiceConfig.type == new_config.type)
            )).all()
             for other in others:
                 other.is_active = False
        
        session.add(new_config)
        await session.commit()
        await session.refresh(new_config)
        return new_config
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"Error creating voice config: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¤±è´¥: {str(e)}")

@app.put("/api/voice-configs/{config_id}", response_model=VoiceConfig)
async def update_voice_config(config_id: int, config_data: Dict[str, Any] = Body(...), session: AsyncSession = Depends(get_session)):
    try:
        db_config = await session.get(VoiceConfig, config_id)
        if not db_config:
            raise HTTPException(status_code=404, detail="Config not found")
        
        # æ£€æŸ¥é‡å
        new_name = config_data.get("name")
        if new_name and new_name != db_config.name:
            existing = (await session.exec(
                select(VoiceConfig)
                .where(VoiceConfig.name == new_name)
                .where(VoiceConfig.id != config_id)
            )).first()
            if existing:
                raise HTTPException(status_code=400, detail="åç§°å·²å­˜åœ¨")
        
        # å¤„ç†æ¿€æ´»çŠ¶æ€å˜æ›´
        is_activating = config_data.get("is_active") and not db_config.is_active
        if is_activating:
            others = (await session.exec(
                select(VoiceConfig).where(VoiceConfig.type == db_config.type).where(VoiceConfig.id != config_id)
            )).all()
            for other in others:
                other.is_active = False
        
        # æ›´æ–°å­—æ®µ
        exclude_fields = {'id', 'created_at', 'updated_at'}
        for key, value in config_data.items():
            if key not in exclude_fields and hasattr(db_config, key):
                setattr(db_config, key, value)
        
        db_config.updated_at = datetime.utcnow()
        session.add(db_config)
        await session.commit()
        await session.refresh(db_config)
        return db_config
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"Error updating voice config: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(e)}")

@app.delete("/api/voice-configs/{config_id}")
async def delete_voice_config(config_id: int, session: AsyncSession = Depends(get_session)):
    try:
        db_config = await session.get(VoiceConfig, config_id)
        if not db_config:
            raise HTTPException(status_code=404, detail="Config not found")
        
        if db_config.is_active:
             raise HTTPException(status_code=400, detail="æ— æ³•åˆ é™¤å½“å‰æ¿€æ´»çš„é…ç½®")

        await session.delete(db_config)
        await session.commit()
        return {"status": "success"}
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"Error deleting voice config: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

@app.post("/api/chat")
async def chat(
    request: ChatRequest,
    token: str = Depends(verify_token),
    session: AsyncSession = Depends(get_session)
):
    # å°† Pydantic æ¨¡å‹è½¬æ¢ä¸º Dictï¼Œä½†ä»…æå–åç«¯ä¿¡ä»»çš„å­—æ®µ
    messages = [m.model_dump() for m in request.messages]
    source = request.source
    session_id = request.session_id
    
    # ä¸¥æ ¼æ ¡éªŒ source
    valid_sources = ["desktop", "mobile", "system_trigger", "ide", "qq"]
    if source not in valid_sources:
        print(f"[Security] Invalid source detected: {source}. Resetting to desktop.")
        source = "desktop"
    
    agent = AgentService(session)
    tts_service = get_tts_service()
    
    async def event_generator():
        full_response_text = ""
        
        try:
            # ä½¿ç”¨é˜Ÿåˆ—ç»Ÿä¸€ç®¡ç†æ–‡æœ¬æµå’ŒçŠ¶æ€æµ
            queue = asyncio.Queue()
            
            async def status_callback(status_type, message):
                await queue.put({"type": "status", "payload": {"type": status_type, "message": message}})

            async def run_chat():
                try:
                    async for chunk in agent.chat(messages, source=source, session_id=session_id, on_status=status_callback, skip_save=False):
                        if chunk:
                            await queue.put({"type": "text", "payload": chunk})
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    await queue.put({"type": "error", "payload": str(e)})
                finally:
                    await queue.put({"type": "done"})

            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡æ‰§è¡ŒèŠå¤©é€»è¾‘
            # asyncio.create_task(run_chat()) # Moved below

            # TTS Buffer & Delimiters
            # tts_buffer = "" # Moved to run_tts
            # tts_delimiters = re.compile(r'[ã€‚ï¼ï¼Ÿ\.\!\?\n]+') # Moved to run_tts

            async def generate_tts_chunk(text_chunk):
                try:
                    # Filter out XML/HTML tags
                    clean_text = re.sub(r'<([A-Z_]+)>.*?</\1>', '', text_chunk, flags=re.S)
                    clean_text = re.sub(r'<[^>]+>', '', clean_text)
                    # Filter out Thinking blocks (Safety net)
                    # Use strict pattern but case insensitive
                    clean_text = re.sub(r'ã€(Thinking|Monologue).*?ã€‘', '', clean_text, flags=re.S | re.IGNORECASE)
                    
                    # Filter out Emoji and special symbols that edge-tts might read
                    clean_text = re.sub(r'[\U00010000-\U0010ffff]', '', clean_text)
                    clean_text = re.sub(r'[^\w\s\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šâ€œâ€ï¼ˆï¼‰\n\.,!\?\-]', '', clean_text)
                    
                    # [Feature] Chatter Removal: Only read the last paragraph
                    # Split by newline and take the last non-empty segment to avoid reading "Thinking" chatter
                    segments = [s.strip() for s in clean_text.split('\n') if s.strip()]
                    if segments:
                        clean_text = segments[-1]

                    clean_text = clean_text.strip()
                    
                    if clean_text:
                        audio_path = await tts_service.synthesize(clean_text)
                        if audio_path and os.path.exists(audio_path):
                            with open(audio_path, "rb") as audio_file:
                                audio_data = base64.b64encode(audio_file.read()).decode('utf-8')
                            
                            # Clean up file immediately
                            try:
                                os.remove(audio_path)
                            except:
                                pass
                                
                            return audio_data
                except Exception as e:
                    print(f"TTS Chunk Error: {e}")
                return None

            # TTS Queue
            tts_queue = asyncio.Queue()

            async def run_tts():
                import re
                import asyncio
                import os
                tts_buffer = ""
                # æ¢å¤åˆ†æ®µæœºåˆ¶ï¼Œå®ç°æµå¼æ’­æ”¾ (ã€‚ï¼ï¼Ÿ.!?)
                tts_delimiters = re.compile(r'([ã€‚ï¼ï¼Ÿ\.\!\?\n]+)')
                
                # å«è¯æœºåˆ¶çŠ¶æ€
                filler_played = False
                filler_phrase = "å””...è®©æˆ‘æƒ³æƒ³..."
                filler_cache_path = os.path.join(current_dir, "assets", "filler_thinking.mp3")

                # åˆå§‹åŒ–è¿‡æ»¤å™¨ï¼Œé˜²æ­¢ TTS è¯»å– XML æ ‡ç­¾å’Œ NIT å·¥å…·è°ƒç”¨å—
                from nit_core.dispatcher import XMLStreamFilter, NITStreamFilter
                # æ˜¾å¼è¿‡æ»¤ thought æ ‡ç­¾å’Œ PEROCUE ç­‰æ ‡ç­¾
                xml_filter = XMLStreamFilter(tag_names=["THOUGHT", "PEROCUE", "CHARACTER_STATUS", "METADATA"])
                nit_filter = NITStreamFilter()
                
                try:
                    while True:
                        try:
                            # ç›‘æ§é˜Ÿåˆ—ï¼Œå¦‚æœ 3 ç§’æ²¡ååº”ä¸”æ²¡æ’­è¿‡å«è¯ï¼Œåˆ™è§¦å‘
                            if not filler_played:
                                raw_chunk = await asyncio.wait_for(tts_queue.get(), timeout=3.0)
                            else:
                                raw_chunk = await tts_queue.get()
                        except asyncio.TimeoutError:
                            if not filler_played:
                                logger.info(f"TTS Timeout detected, playing local filler for Pero...")
                                audio_data = None
                                
                                # ä¼˜å…ˆå°è¯•è¯»å–æœ¬åœ°ç¼“å­˜
                                if os.path.exists(filler_cache_path):
                                    try:
                                        with open(filler_cache_path, "rb") as f:
                                            # è¯»å–äºŒè¿›åˆ¶å¹¶è½¬ä¸º base64 å­—ç¬¦ä¸²ï¼Œä¸ generate_tts_chunk è¾“å‡ºä¿æŒä¸€è‡´
                                            audio_data = base64.b64encode(f.read()).decode('utf-8')
                                    except Exception as e:
                                        logger.error(f"Failed to read local filler: {e}")
                                
                                # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™ç”Ÿæˆå¹¶ä¿å­˜
                                if not audio_data:
                                    audio_data = await generate_tts_chunk(filler_phrase)
                                    if audio_data:
                                        try:
                                            # audio_data æ˜¯ base64 å­—ç¬¦ä¸²ï¼Œä¿å­˜ä¸ºäºŒè¿›åˆ¶éŸ³é¢‘æ–‡ä»¶
                                            with open(filler_cache_path, "wb") as f:
                                                f.write(base64.b64decode(audio_data))
                                            logger.info(f"Saved filler to cache: {filler_cache_path}")
                                        except Exception as e:
                                            logger.error(f"Failed to save filler cache: {e}")
                                
                                if audio_data:
                                    await queue.put({"type": "audio", "payload": audio_data})
                                filler_played = True
                            # ç»§ç»­ç­‰å¾…
                            raw_chunk = await tts_queue.get()
                        
                        if raw_chunk is None: # Sentinel
                            # Flush filters buffer
                            remaining_xml = xml_filter.flush()
                            remaining_nit = nit_filter.filter(remaining_xml) + nit_filter.flush()
                            
                            if remaining_nit:
                                tts_buffer += remaining_nit
                                
                            # å¤„ç†æœ€åå‰©ä½™çš„æ–‡æœ¬
                            if tts_buffer.strip():
                                audio_data = await generate_tts_chunk(tts_buffer)
                                if audio_data:
                                    await queue.put({"type": "audio", "payload": audio_data})
                            break
                        
                        # ä¸€æ—¦æœ‰äº†å®é™…è¾“å‡ºï¼Œä¹Ÿå°† filler_played è®¾ä¸º Trueï¼Œé˜²æ­¢ä¸­é€”å†è¹¦å‡ºä¸€å¥å«è¯
                        if not filler_played and len(raw_chunk.strip()) > 0:
                            filler_played = True

                        # Apply Filters: First XML, then NIT
                        filtered_xml = xml_filter.filter(raw_chunk)
                        filtered_nit = nit_filter.filter(filtered_xml)
                        tts_buffer += filtered_nit
                        
                        # æµå¼åˆ†å¥é€»è¾‘ï¼šæŸ¥æ‰¾åˆ†éš”ç¬¦
                        # åªæœ‰å½“ buffer é•¿åº¦è¾¾åˆ°ä¸€å®šç¨‹åº¦æˆ–å‡ºç°æ ‡ç‚¹ç¬¦å·æ—¶æ‰åˆ‡åˆ†ï¼Œä¿è¯è¯­è°ƒ
                        if len(tts_buffer) > 10: 
                            parts = tts_delimiters.split(tts_buffer)
                            # å¦‚æœæœ‰è‡³å°‘ä¸€ä¸ªå®Œæ•´å¥å­ï¼ˆparts é•¿åº¦ > 1ï¼‰
                            if len(parts) > 1:
                                # æ‹¼æ¥å·²å®Œæˆçš„å¥å­ (i æ˜¯æ–‡æœ¬, i+1 æ˜¯æ ‡ç‚¹)
                                for i in range(0, len(parts) - 1, 2):
                                    sentence = parts[i] + parts[i+1]
                                    if sentence.strip():
                                        audio_data = await generate_tts_chunk(sentence)
                                        if audio_data:
                                            await queue.put({"type": "audio", "payload": audio_data})
                                
                                # å°†å‰©ä½™ä¸å®Œæ•´çš„æ–‡æœ¬ç•™åˆ°ä¸‹ä¸€æ¬¡å¤„ç†
                                tts_buffer = parts[-1]
                except Exception as e:
                    print(f"TTS Worker Error: {e}")
                finally:
                    # Signal done to the main queue
                    await queue.put({"type": "done"})

            # çŠ¶æ€å›è°ƒåŒ…è£…å™¨ï¼Œç”¨äºè¿½è¸ª ReAct è½®æ¬¡
            react_turn = [0] # ä½¿ç”¨ list ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹
            turn_buffer = [""] # ç¼“å­˜éé¦–è½®çš„å†…å®¹

            def wrapped_status_callback(status, msg):
                if status == "thinking":
                    react_turn[0] += 1
                    # å¦‚æœè¿›å…¥äº†æ–°çš„ä¸€è½®ï¼ˆè½®æ¬¡ > 2ï¼‰ï¼Œè¯´æ˜ä¸Šä¸€è½®ä¸æ˜¯æœ€åä¸€è½®ï¼Œæ¸…ç©ºç¼“å­˜
                    if react_turn[0] > 2:
                        turn_buffer[0] = ""
                return status_callback(status, msg)

            async def run_chat():
                try:
                    async for chunk in agent.chat(messages, source=source, session_id=session_id, on_status=wrapped_status_callback):
                        if chunk:
                            # æ–‡æœ¬æµå§‹ç»ˆå‘é€ç»™ UI
                            await queue.put({"type": "text", "payload": chunk})
                            
                            # TTS é€»è¾‘ï¼š
                            # 1. ç¬¬ä¸€è½®ç›´æ¥å‘é€ç»™ TTS é˜Ÿåˆ—ï¼ˆæµå¼å¿µå‡ºï¼‰
                            # 2. åç»­è½®æ¬¡å…ˆè¿›å…¥ turn_buffer ç¼“å­˜
                            if react_turn[0] <= 1:
                                await tts_queue.put(chunk)
                            else:
                                turn_buffer[0] += chunk
                    
                    # å½“ chat ç»“æŸæ—¶ï¼Œæœ€åçš„ turn_buffer å°±æ˜¯â€œæœ€åä¸€æ®µè¯â€
                    if react_turn[0] > 1 and turn_buffer[0].strip():
                        await tts_queue.put(turn_buffer[0])

                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    await queue.put({"type": "error", "payload": str(e)})
                    # Ensure TTS worker also finishes if chat errors
                    await tts_queue.put(None)
                finally:
                    # Signal TTS to finish
                    await tts_queue.put(None)

            # å¯åŠ¨ä»»åŠ¡
            asyncio.create_task(run_chat())
            asyncio.create_task(run_tts())

            # æ¶ˆè´¹é˜Ÿåˆ—ä¸­çš„å†…å®¹å¹¶å‘é€ SSE
            while True:
                item = await queue.get()
                if item["type"] == "done":
                    break
                
                if item["type"] == "error":
                    error_chunk = {
                        "choices": [{"delta": {"content": f"Error: {item['payload']}"}}]
                    }
                    yield f"data: {json.dumps(error_chunk)}\n\n"
                    # If error occurs, we might want to stop or continue? 
                    # Usually error is fatal for the response.
                    break
                
                if item["type"] == "audio":
                     yield f"data: {json.dumps({'audio': item['payload']})}\n\n"

                if item["type"] == "status":
                    status_chunk = {"status": item["payload"]}
                    yield f"data: {json.dumps(status_chunk)}\n\n"
                
                if item["type"] == "text":
                    chunk = item["payload"]
                    full_response_text += chunk
                    
                    response_chunk = {
                        "choices": [{"delta": {"content": chunk}}]
                    }
                    yield f"data: {json.dumps(response_chunk)}\n\n"
            
            yield "data: [DONE]\n\n"
        except Exception as e:
            print(f"Chat error: {e}")
            import traceback
            traceback.print_exc()
            error_chunk = {
                "choices": [
                    {
                        "delta": {
                            "content": f"Error: {str(e)}"
                        }
                    }
                ]
            }
            yield f"data: {json.dumps(error_chunk)}\n\n"
            yield "data: [DONE]\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.post("/api/system/reset")
async def reset_system(session: AsyncSession = Depends(get_session)):
    """ä¸€é”®æ¢å¤å‡ºå‚è®¾ç½®ï¼šæ¸…ç†æ‰€æœ‰è®°å¿†ã€å¯¹è¯è®°å½•ã€çŠ¶æ€å’Œä»»åŠ¡ï¼Œä½†ä¿ç•™æ¨¡å‹é…ç½®"""
    try:
        # 1. æ¸…ç†è®°å¿†
        await session.exec(delete(Memory))
        # 2. æ¸…ç†å¯¹è¯è®°å½•
        await session.exec(delete(ConversationLog))
        # 3. æ¸…ç†ä»»åŠ¡
        await session.exec(delete(ScheduledTask))
        # 4. é‡ç½®å® ç‰©çŠ¶æ€
        await session.exec(delete(PetState))
        # 5. æ¸…ç†é…ç½® (ä¿ç•™æ¨¡å‹é…ç½®ç›¸å…³çš„ key)
        # å¸¸è§çš„éœ€è¦ä¿ç•™çš„é…ç½®ï¼šcurrent_model_id, reflection_model_id, reflection_enabled
        # éœ€è¦æ¸…ç†çš„é…ç½®ï¼šowner_name, user_persona, last_maintenance_log_count ç­‰
        keep_configs = ["current_model_id", "reflection_model_id", "reflection_enabled", "global_llm_api_key", "global_llm_api_base"]
        await session.exec(
            delete(Config).where(Config.key.not_in(keep_configs))
        )
        
        # 6. åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„é»˜è®¤çŠ¶æ€
        default_state = PetState()
        session.add(default_state)
        
        await session.commit()
        return {"status": "success", "message": "ç³»ç»Ÿå·²æˆåŠŸæ¢å¤å‡ºå‚è®¾ç½®"}
    except Exception as e:
        await session.rollback()
        import traceback
        print(f"Error resetting system: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ¢å¤å‡ºå‚è®¾ç½®å¤±è´¥: {str(e)}")

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.post("/api/maintenance/run")
async def run_maintenance_api(session: AsyncSession = Depends(get_session)):
    service = MemorySecretaryService(session)
    return await service.run_maintenance()

@app.post("/api/open-path")
async def open_path(payload: Dict[str, str] = Body(...)):
    """æ‰“å¼€æœ¬åœ°æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
    path = payload.get("path")
    if not path:
        raise HTTPException(status_code=400, detail="Path is required")
    
    # è§„èŒƒåŒ–è·¯å¾„ï¼Œå¤„ç†ä¸åŒå¹³å°çš„æ–œæ 
    path = os.path.normpath(path)
    
    if not os.path.exists(path):
        raise HTTPException(status_code=404, detail="Path does not exist")
    
    if os.name == 'nt':
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        startupinfo.wShowWindow = subprocess.SW_HIDE
        try:
            if os.path.isfile(path):
                # ä½¿ç”¨ explorer /select, path å®šä½æ–‡ä»¶
                # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç”¨ subprocess.run(..., shell=True)ï¼Œå¦åˆ™ä¼šæœ‰æ§åˆ¶å°é—ªçƒ
                # ç›´æ¥è°ƒç”¨ explorer.exe
                subprocess.Popen(['explorer', '/select,', path], startupinfo=startupinfo)
            else:
                os.startfile(path)
        except Exception as e:
             # Fallback
             try:
                os.startfile(path)
             except Exception as inner_e:
                print(f"Error opening path {path}: {inner_e}")
                raise HTTPException(status_code=500, detail=str(inner_e))
    else:
        # Non-Windows fallback (though Pero is Windows focused)
        subprocess.Popen(['xdg-open', path])
        
    return {"status": "success", "message": f"Opened {path}"}

# ============================================================================
# RESTORED ENDPOINTS (Voice, Memory, etc.)
# ============================================================================

# --- Voice API ---

@app.post("/api/voice/asr")
async def voice_asr(file: UploadFile = File(...)):
    """è¯­éŸ³è½¬æ–‡å­—æ¥å£"""
    try:
        # Save temp file
        # [Refactor] ç»Ÿä¸€æŒ‡å‘ backend/data/temp_audio
        default_data_dir = os.path.join(current_dir, "data")
        data_dir = os.environ.get("PERO_DATA_DIR", default_data_dir)
        temp_dir = os.path.join(data_dir, "temp_audio")
        
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)
            
        temp_path = os.path.join(temp_dir, f"{uuid.uuid4()}.wav")
        with open(temp_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
            
        asr = get_asr_service()
        text = await asr.transcribe(temp_path)
        
        # Cleanup
        try:
            os.remove(temp_path)
        except:
            pass
            
        if not text:
            raise HTTPException(status_code=500, detail="ASR failed")
            
        return {"text": text}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/voice/tts")
async def voice_tts(payload: Dict[str, str] = Body(...)):
    """æ–‡å­—è½¬è¯­éŸ³æ¥å£"""
    text = payload.get("text", "")
    if not text:
        raise HTTPException(status_code=400, detail="Text is required")
    
    tts = get_tts_service()
    filepath = await tts.synthesize(text)
    if not filepath:
        raise HTTPException(status_code=500, detail="TTS synthesis failed")
    
    filename = os.path.basename(filepath)
    return {"audio_url": f"/api/voice/audio/{filename}"}

@app.get("/api/voice/audio/{filename}")
async def get_audio_file(filename: str):
    """è·å–è¯­éŸ³æ–‡ä»¶"""
    # [Refactor] ç»Ÿä¸€æŒ‡å‘ backend/data/temp_audio
    default_data_dir = os.path.join(current_dir, "data")
    data_dir = os.environ.get("PERO_DATA_DIR", default_data_dir)
    file_path = os.path.join(data_dir, "temp_audio", filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="Audio file not found")
    return FileResponse(file_path, media_type="audio/mpeg")

@app.delete("/api/voice/audio/{filename}")
async def delete_audio(filename: str):
    """æ‰‹åŠ¨åˆ é™¤éŸ³é¢‘æ–‡ä»¶ (ç”±å‰ç«¯æ’­æ”¾å®Œæ¯•åè§¦å‘)"""
    tts = get_tts_service()
    # Check both temp_audio and tts output dir just in case
    # [Refactor] ç»Ÿä¸€æŒ‡å‘ backend/data/temp_audio
    default_data_dir = os.path.join(current_dir, "data")
    data_dir = os.environ.get("PERO_DATA_DIR", default_data_dir)
    
    paths_to_check = [
        os.path.join(data_dir, "temp_audio", filename),
        os.path.join(tts.output_dir, filename)
    ]
    
    deleted = False
    for filepath in paths_to_check:
        if os.path.exists(filepath):
            try:
                os.remove(filepath)
                deleted = True
            except:
                pass
    
    if not deleted:
        # It's fine if it's already gone
        pass
        
    return {"status": "success"}

# --- Memory API ---

@app.get("/api/configs/waifu-texts")
async def get_waifu_texts(session: AsyncSession = Depends(get_session)):
    """è·å–åŠ¨æ€ç”Ÿæˆçš„ Live2D å°è¯é…ç½® (Agent ä¸“å±)"""
    try:
        # 1. è·å–å½“å‰æ´»è·ƒ Agent
        from services.agent_manager import get_agent_manager
        agent_manager = get_agent_manager()
        active_agent = agent_manager.get_active_agent()
        agent_id = active_agent.id if active_agent else "pero"
        
        # 2. å°è¯•ä» Agent ç›®å½•åŠ è½½ waifu_texts.json
        agent_dir = os.path.join(current_dir, "services", "mdp", "agents", agent_id)
        texts_path = os.path.join(agent_dir, "waifu_texts.json")
        
        if os.path.exists(texts_path):
            try:
                with open(texts_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                print(f"[Main] Failed to load waifu_texts for agent {agent_id}: {e}")
        
        # 3. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å›é€€åˆ° Config (æ—§ç‰ˆé€»è¾‘)
        config = await session.get(Config, "waifu_dynamic_texts")
        if config:
            return json.loads(config.value)
            
        return {}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/memories")
async def get_memories(
    query: str = None, 
    limit: int = 20, 
    offset: int = 0, 
    session: AsyncSession = Depends(get_session)
):
    """è·å–è®°å¿†åˆ—è¡¨"""
    try:
        stmt = select(Memory).order_by(desc(Memory.timestamp)).offset(offset).limit(limit)
        if query:
            stmt = stmt.where(Memory.content.contains(query))
        
        memories = (await session.exec(stmt)).all()
        return memories
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/memories", response_model=Memory)
async def add_memory(
    payload: Dict[str, Any], 
    session: AsyncSession = Depends(get_session)
):
    """æ‰‹åŠ¨æ·»åŠ è®°å¿†"""
    try:
        service = MemoryService()
        return await service.save_memory(
            session, 
            content=payload.get("content", ""), 
            tags=payload.get("tags", ""), 
            importance=payload.get("importance", 1), 
            msg_timestamp=payload.get("msgTimestamp"), 
            source=payload.get("source", "desktop"), 
            memory_type=payload.get("type", "event")
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/memories/{memory_id}")
async def delete_memory(
    memory_id: int, 
    session: AsyncSession = Depends(get_session)
):
    """åˆ é™¤è®°å¿†"""
    try:
        memory = await session.get(Memory, memory_id)
        if not memory:
            raise HTTPException(status_code=404, detail="Memory not found")
        
        await session.delete(memory)
        await session.commit()
        return {"status": "success", "id": memory_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/models/remote")
async def fetch_remote_models(payload: Dict[str, Any] = Body(...)):
    """è·å–è¿œç¨‹æœåŠ¡å•†æä¾›çš„æ¨¡å‹åˆ—è¡¨"""
    api_key = payload.get("api_key", "")
    api_base = payload.get("api_base", "https://api.openai.com")
    provider = payload.get("provider", "openai")
    
    from services.llm_service import LLMService
    llm = LLMService(api_key, api_base, "", provider=provider)
    models = await llm.list_models()
    print(f"åç«¯è¿”å›æ¨¡å‹åˆ—è¡¨: {models} (æœåŠ¡å•†: {provider})") # æ‰“å°è¿”å›ç»™å‰ç«¯çš„å†…å®¹
    return {"models": models}

@app.post("/api/maintenance/undo/{record_id}")
async def undo_maintenance_api(record_id: int, session: AsyncSession = Depends(get_session)):
    service = MemorySecretaryService(session)
    success = await service.undo_maintenance(record_id)
    if not success:
        raise HTTPException(status_code=400, detail="Undo failed or record not found")
    return {"status": "success", "message": "Maintenance undone"}

@app.get("/api/maintenance/records")
async def get_maintenance_records(session: AsyncSession = Depends(get_session)):
    """è·å–æœ€è¿‘çš„ç»´æŠ¤è®°å½•"""
    from sqlmodel import desc
    from models import MaintenanceRecord
    statement = select(MaintenanceRecord).order_by(desc(MaintenanceRecord.timestamp)).limit(10)
    return (await session.exec(statement)).all()

@app.get("/api/stats/overview")
async def get_overview_stats(agent_id: Optional[str] = None, session: AsyncSession = Depends(get_session)):
    """
    è·å–æ¦‚è§ˆé¡µé¢çš„ç»Ÿè®¡æ•°æ®ï¼ˆæ€»æ•°ï¼‰ï¼Œè§£è€¦æ¸²æŸ“æ•°é‡å’Œæ˜¾ç¤ºæ•°é‡ã€‚
    """
    try:
        # Count memories
        mem_statement = select(func.count()).select_from(Memory)
        if agent_id:
            mem_statement = mem_statement.where(Memory.agent_id == agent_id)
        mem_count = (await session.exec(mem_statement)).one()
        
        # Count logs
        log_statement = select(func.count()).select_from(ConversationLog)
        if agent_id:
            log_statement = log_statement.where(ConversationLog.agent_id == agent_id)
        log_count = (await session.exec(log_statement)).one()
        
        # Count tasks (ScheduledTask)
        task_statement = select(func.count()).select_from(ScheduledTask)
        if agent_id:
            task_statement = task_statement.where(ScheduledTask.agent_id == agent_id)
        task_count = (await session.exec(task_statement)).one()

        return {
            "total_memories": mem_count,
            "total_logs": log_count,
            "total_tasks": task_count
        }
    except Exception as e:
        logger.error(f"Failed to get overview stats: {e}")
        # Fallback to 0 if error, frontend should handle or use length
        return {
            "total_memories": 0,
            "total_logs": 0,
            "total_tasks": 0
        }

@app.get("/api/gateway/token")
async def get_gateway_token_api():
    """è·å– Gateway Token (ç”¨äºå‰ç«¯è¿æ¥ Gateway)"""
    try:
        token_path = os.path.join(current_dir, "data", "gateway_token.json")
        if os.path.exists(token_path):
             with open(token_path, "r", encoding="utf-8") as f:
                 data = json.load(f)
                 return {"token": data.get("token")}
        raise HTTPException(status_code=404, detail="Token not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£å’ŒHost
    port = int(os.environ.get("PORT", 9120))
    host = os.environ.get("HOST", "127.0.0.1")
    # å¼ºåˆ¶ç¦ç”¨ reload æ¨¡å¼ï¼Œå› ä¸º Uvicorn çš„ reloader åœ¨ Windows ä¸‹ä¼šå¼ºåˆ¶ä½¿ç”¨ SelectorEventLoop
    # è¿™ä¼šå¯¼è‡´ subprocess (MCP Stdio) æŠ¥é”™ NotImplementedError
    print(f"åç«¯å¯åŠ¨ï¼Œäº‹ä»¶å¾ªç¯: {asyncio.get_event_loop().__class__.__name__}, Host: {host}, Port: {port}")
    uvicorn.run("main:app", host=host, port=port, reload=False)

