"""
AuraVision Service - è§†è§‰æ„å›¾æ„ŸçŸ¥æœåŠ¡ (V3.0 å¤šæ¨¡æ€ç‰ˆ)

ä½¿ç”¨ Rust åŸç”Ÿæ¨ç†å¼•æ“ï¼Œå®ç°æŠ€æœ¯æ–‡æ¡£è®¾è®¡çš„å®Œæ•´é“¾è·¯ï¼š
- è§†è§‰ç¼–ç  -> 384D å‘é‡
- EMA æ—¶åºå¹³æ»‘
- æ„å›¾é”šç‚¹åŒ¹é…
- æ‰©æ•£æ¿€æ´»è®°å¿†å”¤é†’
- ä¸Šä¸‹æ–‡é¥±å’Œåº¦æ£€æµ‹

V3.0 æ–°å¢:
- å¤šæ¨¡æ€ä¸»åŠ¨è§¦å‘åè°ƒå™¨é›†æˆ
- è‡ªé€‚åº”é‡‡æ ·é¢‘ç‡
- æ—¶é—´æ„ŸçŸ¥èåˆ

ç‰ˆæœ¬: 3.0.0
"""

import asyncio
import cv2
import numpy as np
import base64
import os
from typing import Optional, List, Dict, Any
from loguru import logger

from services.screenshot_service import screenshot_manager

# å¤šæ¨¡æ€åè°ƒå™¨ (V3.0)
try:
    from services.multimodal_trigger_service import (
        MultimodalTriggerCoordinator, TriggerMode, multimodal_coordinator
    )
    MULTIMODAL_AVAILABLE = True
except ImportError as e:
    logger.warning(f"[AuraVision] å¤šæ¨¡æ€åè°ƒå™¨ä¸å¯ç”¨: {e}")
    MULTIMODAL_AVAILABLE = False
    multimodal_coordinator = None

# å°è¯•å¯¼å…¥ Rust æ ¸å¿ƒæ¨¡å—
try:
    from pero_memory_core import VisionIntentMemoryManager, VisionProcessResult
    RUST_VISION_AVAILABLE = True
    logger.info("[AuraVision] Rust è§†è§‰æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    logger.warning(f"[AuraVision] Rust è§†è§‰æ¨¡å—ä¸å¯ç”¨: {e}")
    RUST_VISION_AVAILABLE = False
    VisionIntentMemoryManager = None
    VisionProcessResult = None


class AuraVisionService:
    """
    è§†è§‰æ„å›¾æ„ŸçŸ¥æœåŠ¡
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. å®šæœŸæˆªå–å±å¹• -> è„±æ•å¤„ç† -> æ„å›¾ç¼–ç 
    2. åŒ¹é…æ„å›¾é”šç‚¹ -> è§¦å‘æ‰©æ•£æ¿€æ´» -> å”¤é†’ç›¸å…³è®°å¿†
    3. é¥±å’Œåº¦æ£€æµ‹ -> å†³å®šæ˜¯å¦ä¸»åŠ¨å¯¹è¯
    """
    
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        
        self.is_running = False
        self.manager: Optional[VisionIntentMemoryManager] = None
        
        # æ¨¡å‹è·¯å¾„
        self.model_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "models", "AuraVision", "weights", "auravision_v1.onnx"
        )
        
        # é”šç‚¹æ•°æ®è·¯å¾„
        base_dir = os.environ.get("PERO_DATA_DIR", os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        self.anchors_path = os.path.join(base_dir, "data", "rust_db", "intent_anchors.json")
        
        # é…ç½®å‚æ•°
        self.observation_interval = 30  # ç§’
        self.ema_alpha = 0.3
        self.similarity_threshold = 0.85
        self.saturation_threshold = 0.7
        
        self._initialized = True
        logger.info("[AuraVision] æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def initialize(self) -> bool:
        """
        åˆå§‹åŒ– Rust è§†è§‰å¼•æ“
        
        Returns:
            bool: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        if not RUST_VISION_AVAILABLE:
            logger.error("[AuraVision] Rust æ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–")
            return False
        
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.model_path):
                logger.warning(f"[AuraVision] æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                # åˆ›å»ºç®¡ç†å™¨ä½†ä¸åŠ è½½æ¨¡å‹
                self.manager = VisionIntentMemoryManager(None, 384)
                logger.info("[AuraVision] ç®¡ç†å™¨å·²åˆ›å»º (æ— æ¨¡å‹)")
                return True
            
            # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
            self.manager = VisionIntentMemoryManager(self.model_path, 384)
            
            # é…ç½®å‚æ•°
            self.manager.configure(
                ema_alpha=self.ema_alpha,
                similarity_threshold=self.similarity_threshold,
                saturation_threshold=self.saturation_threshold
            )
            
            # å°è¯•åŠ è½½å·²ä¿å­˜çš„é”šç‚¹
            if os.path.exists(self.anchors_path):
                try:
                    self.manager.load_anchors(self.anchors_path)
                    logger.info(f"[AuraVision] åŠ è½½äº† {self.manager.anchor_count()} ä¸ªé”šç‚¹")
                except Exception as e:
                    logger.warning(f"[AuraVision] åŠ è½½é”šç‚¹å¤±è´¥: {e}")
            
            logger.info(f"[AuraVision] Rust å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"[AuraVision] åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def is_ready(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å°±ç»ª"""
        return self.manager is not None and self.manager.is_model_loaded()

    def load_intent_anchors(self, anchors: List[Dict[str, Any]]) -> int:
        """
        åŠ è½½æ„å›¾é”šç‚¹
        
        Args:
            anchors: é”šç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªé”šç‚¹åŒ…å«:
                - id: int
                - vector: List[float] (384ç»´)
                - description: str
                - importance: float (0-1, å¯é€‰)
                - tags: str (å¯é€‰)
        
        Returns:
            int: æˆåŠŸåŠ è½½çš„é”šç‚¹æ•°é‡
        """
        if not self.manager:
            logger.error("[AuraVision] ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return 0
        
        count = 0
        for anchor in anchors:
            try:
                self.manager.add_intent_anchor(
                    id=anchor["id"],
                    vector=anchor["vector"],
                    description=anchor["description"],
                    importance=anchor.get("importance", 1.0),
                    tags=anchor.get("tags", "")
                )
                count += 1
            except Exception as e:
                logger.warning(f"[AuraVision] æ·»åŠ é”šç‚¹ {anchor.get('id')} å¤±è´¥: {e}")
        
        logger.info(f"[AuraVision] åŠ è½½äº† {count}/{len(anchors)} ä¸ªæ„å›¾é”šç‚¹")
        
        # ä¿å­˜é”šç‚¹
        try:
            os.makedirs(os.path.dirname(self.anchors_path), exist_ok=True)
            self.manager.save_anchors(self.anchors_path)
        except Exception as e:
            logger.warning(f"[AuraVision] ä¿å­˜é”šç‚¹å¤±è´¥: {e}")
        
        return count

    def load_memory_connections(self, connections: List[tuple]) -> None:
        """
        åŠ è½½è®°å¿†å…³è”è¾¹ (ç”¨äºæ‰©æ•£æ¿€æ´»)
        
        Args:
            connections: [(source_id, target_id, weight), ...]
        """
        if not self.manager:
            return
        
        self.manager.add_memory_connections(connections)
        logger.info(f"[AuraVision] åŠ è½½äº† {len(connections)} æ¡è®°å¿†å…³è”")

    def _preprocess_screenshot(self, img_bgr: np.ndarray) -> List[float]:
        """
        é¢„å¤„ç†æˆªå›¾ä¸ºæ¨¡å‹è¾“å…¥
        
        æµç¨‹:
        1. ç¼©æ”¾åˆ° 64x64
        2. ç°åº¦åŒ–
        3. Canny è¾¹ç¼˜æ£€æµ‹ (éšç§è„±æ•)
        4. å½’ä¸€åŒ–åˆ° [-1, 1]
        
        Args:
            img_bgr: BGR æ ¼å¼çš„å›¾åƒ (OpenCV é»˜è®¤)
        
        Returns:
            List[float]: 4096 ä¸ªåƒç´ å€¼
        """
        # 1. ç¼©æ”¾
        img_resized = cv2.resize(img_bgr, (64, 64), interpolation=cv2.INTER_AREA)
        
        # 2. ç°åº¦åŒ–
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
        
        # 3. Canny è¾¹ç¼˜æ£€æµ‹ (éšç§è„±æ•çš„å…³é”®æ­¥éª¤)
        img_edges = cv2.Canny(img_gray, 100, 200)
        
        # 4. å½’ä¸€åŒ–åˆ° [-1, 1]
        pixels = (img_edges.astype(np.float32) / 255.0 - 0.5) / 0.5
        
        return pixels.flatten().tolist()

    async def process_current_screen(self) -> Optional[VisionProcessResult]:
        """
        å¤„ç†å½“å‰å±å¹•å¹¶è¿”å›è§†è§‰æ„ŸçŸ¥ç»“æœ
        
        Returns:
            VisionProcessResult: å¤„ç†ç»“æœï¼ŒåŒ…å«:
                - triggered: æ˜¯å¦åº”è§¦å‘ä¸»åŠ¨å¯¹è¯
                - top_anchor_id: æœ€åŒ¹é…çš„é”šç‚¹ ID
                - top_similarity: åŒ¹é…ç›¸ä¼¼åº¦
                - top_description: é”šç‚¹æè¿°
                - activated_memory_ids: å”¤é†’çš„è®°å¿† ID åˆ—è¡¨
                - saturation: ä¸Šä¸‹æ–‡é¥±å’Œåº¦
        """
        if not self.is_ready():
            logger.debug("[AuraVision] æœåŠ¡æœªå°±ç»ªï¼Œè·³è¿‡å¤„ç†")
            return None
        
        try:
            # 1. æˆªå›¾
            shot_data = screenshot_manager.capture()
            if not shot_data or not shot_data.get("base64"):
                logger.debug("[AuraVision] æˆªå›¾å¤±è´¥")
                return None
            
            # 2. è§£ç  Base64
            img_data = base64.b64decode(shot_data["base64"])
            nparr = np.frombuffer(img_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                logger.warning("[AuraVision] å›¾åƒè§£ç å¤±è´¥")
                return None
            
            # 3. é¢„å¤„ç†
            pixels = self._preprocess_screenshot(img)
            
            # 4. Rust å¼•æ“å¤„ç†
            result = self.manager.process_visual_input(
                pixels=pixels,
                propagation_steps=2,
                propagation_decay=0.5
            )
            
            return result
            
        except Exception as e:
            logger.error(f"[AuraVision] å¤„ç†å¤±è´¥: {e}")
            return None

    async def start_vision_loop(self, interval: int = None):
        """
        å¯åŠ¨è§†è§‰æ„ŸçŸ¥å¾ªç¯ (V3.0 å¤šæ¨¡æ€ç‰ˆ)
        
        Args:
            interval: åˆå§‹è§‚å¯Ÿé—´éš” (ç§’)ï¼Œä¹‹åä¼šè‡ªé€‚åº”è°ƒæ•´
        """
        if self.is_running:
            logger.warning("[AuraVision] å¾ªç¯å·²åœ¨è¿è¡Œ")
            return
        
        if interval:
            self.observation_interval = interval
        
        self.is_running = True
        
        # é€šçŸ¥åè°ƒå™¨ä¼šè¯å¼€å§‹
        if MULTIMODAL_AVAILABLE:
            multimodal_coordinator.update_session_start()
        
        logger.info(f"[AuraVision] è§†è§‰æ„ŸçŸ¥å¾ªç¯å·²å¯åŠ¨ (åˆå§‹é—´éš”: {self.observation_interval}s, å¤šæ¨¡æ€: {MULTIMODAL_AVAILABLE})")
        
        try:
            while self.is_running:
                result = await self.process_current_screen()
                
                if result and MULTIMODAL_AVAILABLE:
                    # V3.0: ä½¿ç”¨å¤šæ¨¡æ€åè°ƒå™¨è¿›è¡Œå†³ç­–
                    decision = await self._multimodal_decision(result)
                    
                    if decision.should_trigger:
                        logger.info(
                            f"[AuraVision] ğŸ¯ å¤šæ¨¡æ€è§¦å‘! "
                            f"æ¨¡å¼: {decision.mode.value}, "
                            f"ç»¼åˆå¾—åˆ†: {decision.final_score:.4f}, "
                            f"ç†ç”±: {decision.reasoning}"
                        )
                        
                        # å¼‚æ­¥è§¦å‘ä¸»åŠ¨å¯¹è¯ (ä½¿ç”¨åè°ƒå™¨ç”Ÿæˆçš„ä¸Šä¸‹æ–‡)
                        asyncio.create_task(
                            self._trigger_proactive_dialogue_v3(decision)
                        )
                    
                    elif decision.mode == TriggerMode.INTERNAL:
                        logger.debug(
                            f"[AuraVision] ğŸ“ æ„ŸçŸ¥å·²è®°å½• (å¾—åˆ†: {decision.final_score:.4f})"
                        )
                    
                    else:
                        logger.debug(
                            f"[AuraVision] ğŸ‘€ é™é»˜è§‚å¯Ÿ (å¾—åˆ†: {decision.final_score:.4f})"
                        )
                    
                    # ä½¿ç”¨è‡ªé€‚åº”é‡‡æ ·é—´éš”
                    current_interval = multimodal_coordinator.get_current_sample_interval()
                    
                elif result:
                    # é™çº§åˆ° V2.0 é€»è¾‘
                    if result.triggered:
                        logger.info(
                            f"[AuraVision] ğŸ¯ è§¦å‘ä¸»åŠ¨æ„ŸçŸ¥! "
                            f"é”šç‚¹: {result.top_description[:30]}... "
                            f"(ç›¸ä¼¼åº¦: {result.top_similarity:.4f}, "
                            f"é¥±å’Œåº¦: {result.saturation:.4f})"
                        )
                        asyncio.create_task(self._trigger_proactive_dialogue(result))
                    else:
                        logger.debug(
                            f"[AuraVision] è§‚å¯Ÿä¸­... "
                            f"æœ€ä½³åŒ¹é…: {result.top_similarity:.4f} "
                        )
                    current_interval = self.observation_interval
                
                else:
                    current_interval = self.observation_interval
                
                await asyncio.sleep(current_interval)
                
        except asyncio.CancelledError:
            logger.info("[AuraVision] å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"[AuraVision] å¾ªç¯å´©æºƒ: {e}")
        finally:
            self.is_running = False

    async def _multimodal_decision(self, visual_result):
        """
        ä½¿ç”¨å¤šæ¨¡æ€åè°ƒå™¨è¿›è¡Œå†³ç­–
        
        Args:
            visual_result: VisionProcessResult å¯¹è±¡
        
        Returns:
            MultimodalDecision: èåˆå†³ç­–ç»“æœ
        """
        # è½¬æ¢ VisionProcessResult ä¸º dict
        visual_dict = {
            "top_similarity": visual_result.top_similarity,
            "top_description": visual_result.top_description,
            "top_anchor_id": visual_result.top_anchor_id,
            "saturation": visual_result.saturation,
            "activated_memory_ids": visual_result.activated_memory_ids,
        }
        
        # æ„å»ºè¯­ä¹‰æ‰©æ•£åˆ†æ•° (ä»æ¿€æ´»çš„è®°å¿† ID)
        activated_ids = visual_result.activated_memory_ids
        semantic_scores = {mid: 0.5 for mid in activated_ids}  # ç®€åŒ–: ç»Ÿä¸€æ¿€æ´»åˆ†æ•°
        
        # è°ƒç”¨åè°ƒå™¨
        decision = multimodal_coordinator.compute_decision(
            visual_result=visual_dict,
            semantic_memories=activated_ids,
            semantic_scores=semantic_scores,
            force_time_check=True
        )
        
        return decision

    async def _trigger_proactive_dialogue_v3(self, decision):
        """
        V3.0 å¤šæ¨¡æ€ç‰ˆä¸»åŠ¨å¯¹è¯è§¦å‘
        
        ä½¿ç”¨åè°ƒå™¨ç”Ÿæˆçš„å®Œæ•´ä¸Šä¸‹æ–‡
        """
        try:
            from services.agent_service import AgentService
            from database import get_session
            
            # ä½¿ç”¨åè°ƒå™¨ç”Ÿæˆçš„ä¸Šä¸‹æ–‡
            internal_prompt = decision.context_for_llm
            
            async for session in get_session():
                agent = AgentService(session)
                response_text = ""
                
                async for chunk in agent.chat(
                    messages=[],
                    source="vision",
                    session_id="proactive",
                    system_trigger_instruction=internal_prompt
                ):
                    response_text += chunk
                
                # æ£€æŸ¥æ˜¯å¦é€‰æ‹©ä¸è¯´è¯
                if "<NOTHING>" in response_text.upper():
                    logger.info("[AuraVision] Agent é€‰æ‹©ä¿æŒæ²‰é»˜")
                else:
                    logger.info(f"[AuraVision] Agent ä¸»åŠ¨å‘è¨€: {response_text[:100]}...")
                    
                    # æ¸…ç©ºæ„ŸçŸ¥æ—¥å¿— (å·²ç»è½¬åŒ–ä¸ºå¯¹è¯)
                    if MULTIMODAL_AVAILABLE:
                        multimodal_coordinator.clear_perception_log()
                
                break
                
        except Exception as e:
            logger.error(f"[AuraVision] V3 è§¦å‘å¯¹è¯å¤±è´¥: {e}")

    async def _trigger_proactive_dialogue(self, result: VisionProcessResult):
        """
        è§¦å‘ä¸»åŠ¨å¯¹è¯
        
        å°†è§†è§‰æ„ŸçŸ¥ç»“æœè½¬åŒ–ä¸º AgentService å¯ç†è§£çš„å†…éƒ¨æç¤º
        """
        try:
            from services.agent_service import AgentService
            from database import get_session
            
            # æ„å»ºå†…éƒ¨æ„ŸçŸ¥æç¤ºè¯
            memory_ids_str = ", ".join(str(id) for id in result.activated_memory_ids[:5])
            
            internal_prompt = self.mdp.render("capabilities/aura_internal_sense", {
                "visual_intent": result.top_description,
                "confidence": f"{result.top_similarity:.4f}",
                "saturation": f"{result.saturation:.4f}",
                "memory_ids": memory_ids_str
            })
            
            async for session in get_session():
                agent = AgentService(session)
                response_text = ""
                
                async for chunk in agent.chat(
                    messages=[],
                    source="vision",
                    session_id="proactive",
                    system_trigger_instruction=internal_prompt
                ):
                    response_text += chunk
                
                # æ£€æŸ¥æ˜¯å¦é€‰æ‹©ä¸è¯´è¯
                if "<NOTHING>" in response_text.upper():
                    logger.info("[AuraVision] Agent é€‰æ‹©ä¿æŒæ²‰é»˜")
                else:
                    logger.info(f"[AuraVision] Agent ä¸»åŠ¨å‘è¨€: {response_text[:100]}...")
                
                break
                
        except Exception as e:
            logger.error(f"[AuraVision] è§¦å‘å¯¹è¯å¤±è´¥: {e}")

    def stop(self):
        """åœæ­¢è§†è§‰æ„ŸçŸ¥å¾ªç¯"""
        self.is_running = False
        logger.info("[AuraVision] è§†è§‰æ„ŸçŸ¥å¾ªç¯å·²åœæ­¢")

    def configure(
        self,
        observation_interval: int = None,
        ema_alpha: float = None,
        similarity_threshold: float = None,
        saturation_threshold: float = None
    ):
        """
        é…ç½®æœåŠ¡å‚æ•°
        
        Args:
            observation_interval: è§‚å¯Ÿé—´éš” (ç§’)
            ema_alpha: EMA å¹³æ»‘ç³»æ•° (0-1)
            similarity_threshold: ç›¸ä¼¼åº¦è§¦å‘é˜ˆå€¼ (0-1)
            saturation_threshold: é¥±å’Œåº¦æŠ‘åˆ¶é˜ˆå€¼ (0-1)
        """
        if observation_interval is not None:
            self.observation_interval = observation_interval
        
        if self.manager:
            self.manager.configure(
                ema_alpha=ema_alpha,
                similarity_threshold=similarity_threshold,
                saturation_threshold=saturation_threshold
            )
        
        # ä¿å­˜åˆ°å®ä¾‹å˜é‡
        if ema_alpha is not None:
            self.ema_alpha = ema_alpha
        if similarity_threshold is not None:
            self.similarity_threshold = similarity_threshold
        if saturation_threshold is not None:
            self.saturation_threshold = saturation_threshold

    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            "rust_available": RUST_VISION_AVAILABLE,
            "model_loaded": self.is_ready(),
            "is_running": self.is_running,
            "anchor_count": self.manager.anchor_count() if self.manager else 0,
            "config": {
                "observation_interval": self.observation_interval,
                "ema_alpha": self.ema_alpha,
                "similarity_threshold": self.similarity_threshold,
                "saturation_threshold": self.saturation_threshold,
            }
        }


# å…¨å±€å•ä¾‹
aura_vision_service = AuraVisionService()
