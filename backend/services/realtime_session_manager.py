import asyncio
import os
import logging
import re
import json
import base64
from typing import Optional
from services.asr_service import get_asr_service
from services.tts_service import get_tts_service
# from services.agent_service import AgentService # Moved to local import to avoid circular dependency
from database import get_session
from models import ConversationLog, Config, AIModelConfig
from sqlmodel import select
from services.gateway_client import gateway_client
from peroproto import perolink_pb2
import uuid
import time

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class RealtimeSessionManager:
    """
    å®æ—¶ä¼šè¯ç®¡ç†å™¨ (åŸ VoiceManager)
    - æ¥æ”¶å‰ç«¯éŸ³é¢‘æµ/æ–‡æœ¬æµ
    - VAD æ£€æµ‹ (ç›®å‰ç”±å‰ç«¯åšï¼Œè¿™é‡Œåªæ¥æ”¶åˆ†ç‰‡)
    - è¯­éŸ³è½¬æ–‡å­— (ASR)
    - æ–‡æœ¬å¯¹è¯ (Agent)
    - æ–‡å­—è½¬è¯­éŸ³ (TTS)
    - æ¨é€éŸ³é¢‘æµ/æ–‡æœ¬æµå›å‰ç«¯
    """
    def __init__(self):
        self.asr_service = get_asr_service()
        self.tts_service = get_tts_service()
        self.current_task: Optional[asyncio.Task] = None
        self.pending_confirmations: dict[str, asyncio.Future] = {}
        self.active_commands: dict[int, asyncio.Event] = {}
        
    def initialize(self):
        """Initialize Gateway listeners"""
        gateway_client.on("stream", self.handle_stream)
        gateway_client.on("action:voice_interaction", self.handle_voice_interaction)
        gateway_client.on("action:confirm", self.handle_confirmation_response_action)
        logger.info("å®æ—¶ä¼šè¯ç®¡ç†å™¨å·²ä½¿ç”¨ GatewayClient åˆå§‹åŒ–")

    async def handle_stream(self, envelope):
        """Handle incoming audio stream"""
        # Currently we expect VAD to be done on client, receiving full speech segment?
        # Or raw stream? 
        # If stream_id implies a session.
        # For now, let's assume client sends a stream that represents a "speech_end" equivalent or raw chunks.
        # But looking at previous logic: "speech_end" event contained base64 data.
        # DataStream payload has bytes.
        
        # If it's a complete audio file (simulated stream):
        if envelope.stream.is_end:
             # Process as voice turn
             await self._process_voice_turn_gateway(envelope.source_id, envelope.stream.data, envelope.trace_id)

    async def handle_voice_interaction(self, envelope):
        """Handle voice control messages (text, status, etc)"""
        req = envelope.request
        msg_type = req.params.get("type")
        
        if msg_type == "text":
            # Handle text input equivalent to voice
            pass # TODO

    async def handle_confirmation_response_action(self, envelope):
        """Handle confirmation response via ActionRequest"""
        req = envelope.request
        req_id = req.params.get("id")
        approved = req.params.get("approved") == "true"
        
        if req_id in self.pending_confirmations:
            future = self.pending_confirmations[req_id]
            if not future.done():
                future.set_result(approved)
        else:
            logger.warning(f"æ”¶åˆ°æœªçŸ¥è¯·æ±‚çš„ç¡®è®¤: {req_id}")

    # ... existing methods ...

    def register_skippable_command(self, pid: int, event: asyncio.Event):
        """æ³¨å†Œä¸€ä¸ªå¯è·³è¿‡ç­‰å¾…çš„å‘½ä»¤"""
        self.active_commands[pid] = event

    def unregister_skippable_command(self, pid: int):
        """æ³¨é”€å‘½ä»¤"""
        if pid in self.active_commands:
            del self.active_commands[pid]

    def skip_command(self, pid: int) -> bool:
        """è§¦å‘è·³è¿‡å‘½ä»¤ç­‰å¾…"""
        if pid in self.active_commands:
            logger.info(f"è·³è¿‡ PID {pid} çš„å‘½ä»¤ç­‰å¾…")
            self.active_commands[pid].set()
            return True
        return False

    async def broadcast_gateway(self, message: dict):
        """Broadcast message via Gateway"""
        envelope = perolink_pb2.Envelope()
        envelope.id = str(uuid.uuid4())
        envelope.source_id = gateway_client.device_id
        envelope.target_id = "broadcast"
        envelope.timestamp = int(time.time() * 1000)
        
        envelope.request.action_name = "voice_update"
        for k, v in message.items():
            envelope.request.params[k] = str(v)
            
        await gateway_client.send(envelope)

    async def broadcast(self, message: dict):
        """[Deprecated] Forward legacy broadcast calls to Gateway"""
        await self.broadcast_gateway(message)

    async def send_audio_stream_gateway(self, target_id: str, trace_id: str, audio_path: str):
        """Send audio file as DataStream via Gateway"""
        try:
            with open(audio_path, "rb") as f:
                audio_data = f.read()
            
            envelope = perolink_pb2.Envelope()
            envelope.id = str(uuid.uuid4())
            envelope.source_id = gateway_client.device_id
            envelope.target_id = target_id
            envelope.timestamp = int(time.time() * 1000)
            envelope.trace_id = trace_id
            
            # Use DataStream
            envelope.stream.stream_id = str(uuid.uuid4())
            envelope.stream.data = audio_data
            envelope.stream.is_end = True
            envelope.stream.content_type = "audio/mp3" # or wav based on file
            
            await gateway_client.send(envelope)
        except Exception as e:
            logger.error(f"é€šè¿‡ç½‘å…³å‘é€éŸ³é¢‘æµå¤±è´¥: {e}")

    async def _process_voice_turn_gateway(self, source_id: str, audio_bytes: bytes, trace_id: str):
        """Handle voice turn via Gateway"""
        import time
        start_turn_time = time.time()
        
        # 1. Save temp file
        temp_audio_path = f"temp_voice_gw_{source_id}_{int(time.time())}.wav"
        try:
            print("\n" + "="*60)
            print(f"[Gateway Voice] å¼€å§‹å¯¹è¯è½®æ¬¡ {time.strftime('%H:%M:%S')}")
            print("="*60)
            
            with open(temp_audio_path, "wb") as f:
                f.write(audio_bytes)
            
            # 2. ASR
            print("[ASR] æ­£åœ¨è½¬å½•...")
            await self.broadcast_gateway({"type": "status", "content": "listening"})
            
            asr_start = time.time()
            try:
                user_text = await self.asr_service.transcribe(temp_audio_path)
            except Exception as e:
                error_msg = f"ASR å¤±è´¥: {str(e)}"
                logger.error(error_msg)
                await self.broadcast_gateway({"type": "text_response", "content": f"[{error_msg}]"})
                await self.broadcast_gateway({"type": "status", "content": "idle"})
                return

            asr_duration = time.time() - asr_start
            
            if not user_text or not user_text.strip():
                print(f"[ASR] æœªæ£€æµ‹åˆ°è¯­éŸ³ ({asr_duration:.2f}s).")
                await self.broadcast_gateway({"type": "status", "content": "idle"})
                return

            print(f"[ASR] ç”¨æˆ·: \"{user_text}\" ({asr_duration:.2f}s)")
            await self.broadcast_gateway({"type": "transcription", "content": user_text})

            # Reset companion timer
            try:
                from services.companion_service import companion_service
                companion_service.update_activity()
            except Exception as e:
                logger.warning(f"æ›´æ–°æ´»åŠ¨å¤±è´¥: {e}")

            # 3. Agent
            print("[Agent] æ­£åœ¨ç”Ÿæˆå›å¤...")
            
            async def report_status(status_type: str, content: str):
                await self.broadcast_gateway({"type": "status", "content": status_type, "message": content})

            await self.broadcast_gateway({"type": "status", "content": "thinking"})
            
            agent_start = time.time()
            async for session in get_session():
                # Check native voice input
                enable_voice_input = False
                try:
                    config_obj = (await session.exec(select(Config).where(Config.key == "current_model_id"))).first()
                    if config_obj and config_obj.value:
                        model_id_db = int(config_obj.value)
                        model_config = await session.get(AIModelConfig, model_id_db)
                        if model_config and model_config.enable_voice:
                            enable_voice_input = True
                except: pass

                messages_payload = [{"role": "user", "content": user_text}]
                if enable_voice_input:
                    try:
                        audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                        messages_payload = [{
                            "role": "user",
                            "content": [
                                {"type": "text", "text": f"[User speaking (ASR: {user_text})]"},
                                {"type": "input_audio", "input_audio": {"data": audio_b64, "format": "wav"}}
                            ]
                        }]
                    except Exception as e:
                        print(f"å‡†å¤‡éŸ³é¢‘è´Ÿè½½å¤±è´¥: {e}")

                from services.agent_service import AgentService
                agent = AgentService(session)
                full_response = ""
                generation_error = None
                
                try:
                    async for chunk in agent.chat(
                        messages_payload, 
                        source="gateway",
                        session_id="voice_session",
                        on_status=report_status,
                        is_voice_mode=True,
                        user_text_override=user_text
                    ):
                        if chunk:
                            full_response += chunk
                except Exception as e:
                    print(f"ç”Ÿæˆé”™è¯¯: {e}")
                    generation_error = str(e)
                
                agent_duration = time.time() - agent_start
                print(f"[Agent] å›å¤å·²ç”Ÿæˆ ({len(full_response)} å­—ç¬¦, {agent_duration:.2f}s)")
                
                # 4. Process Response & TTS
                ui_response = self._clean_text(full_response, for_tts=False)
                tts_response = self._clean_text(full_response, for_tts=True)
                
                if not ui_response:
                    if generation_error:
                        ui_response = f"(é”™è¯¯: {generation_error})"
                        tts_response = "å“å‘€ï¼Œå‡ºé”™äº†ã€‚"
                    elif full_response.strip():
                        ui_response = "(Pero æ‰§è¡Œäº†åŠ¨ä½œ...)"
                    else:
                        ui_response = "..."
                if not tts_response:
                    tts_response = "..."

                # Send text
                await self.broadcast_gateway({"type": "status", "content": "speaking"})
                await self.broadcast_gateway({"type": "text_response", "content": ui_response})

                # TTS
                target_voice, target_rate, target_pitch = self._get_voice_params(full_response)
                print(f"[TTS] æ­£åœ¨åˆæˆ {target_voice}...")
                tts_start = time.time()
                audio_path = await self.tts_service.synthesize(
                    tts_response, 
                    voice=target_voice, 
                    rate=target_rate, 
                    pitch=target_pitch
                )
                tts_duration = time.time() - tts_start
                
                if audio_path:
                    print(f"[TTS] éŸ³é¢‘å°±ç»ª ({tts_duration:.2f}s). æ­£åœ¨å‘é€æµ.")
                    await self.send_audio_stream_gateway(source_id, trace_id, audio_path)
                else:
                    print(f"âŒ TTS å¤±è´¥.")
                
                total_duration = time.time() - start_turn_time
                print(f"ğŸ [Gateway Voice] å¯¹è¯è½®æ¬¡ç»“æŸ ({total_duration:.2f}s)\n")
                
                await self.broadcast_gateway({"type": "status", "content": "idle"})
                break

        except Exception as e:
            logger.error(f"Gateway è¯­éŸ³é”™è¯¯: {e}")
            await self.broadcast_gateway({"type": "error", "content": str(e)})
        finally:
            if os.path.exists(temp_audio_path):
                try: os.remove(temp_audio_path)
                except: pass

    async def request_user_confirmation(self, command: str, risk_info: dict = None, is_high_risk: bool = False) -> bool:
        """
        å‘å‰ç«¯å‘é€ç¡®è®¤è¯·æ±‚ï¼Œå¹¶ç­‰å¾…ç”¨æˆ·å“åº”ã€‚
        è¿”å› True (åŒæ„) æˆ– False (æ‹’ç»)ã€‚
        :param command: æŒ‡ä»¤å†…å®¹
        :param risk_info: è¯¦ç»†çš„é£é™©å®¡è®¡ä¿¡æ¯ {level, reason, highlight}
        :param is_high_risk: (å…¼å®¹æ—§å‚æ•°) æ˜¯å¦é«˜é£é™©ï¼Œå¦‚æœ risk_info å­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨ risk_info['level'] >= 2 åˆ¤æ–­
        """
        import uuid
        request_id = str(uuid.uuid4())
        
        # åˆ›å»º Future ä»¥ç­‰å¾…å“åº”
        loop = asyncio.get_running_loop()
        future = loop.create_future()
        self.pending_confirmations[request_id] = future
        
        # å…¼å®¹å¤„ç†
        if risk_info is None:
            risk_info = {
                "level": 2 if is_high_risk else 1,
                "reason": "æ£€æµ‹åˆ°é«˜é£é™©æ“ä½œ" if is_high_risk else "å¸¸è§„æ“ä½œ",
                "highlight": None
            }
        
        try:
            # å¹¿æ’­è¯·æ±‚
            payload = {
                "type": "confirmation_request",
                "id": request_id,
                "command": command,
                "risk_info": json.dumps(risk_info), # Gateway params must be string
                "is_high_risk": str(risk_info["level"] >= 2)
            }
            await self.broadcast_gateway(payload)
            # Legacy broadcast removed
            
            # ç­‰å¾…å“åº” (è®¾ç½®è¶…æ—¶ï¼Œä¾‹å¦‚ 5 åˆ†é’Ÿ)
            result = await asyncio.wait_for(future, timeout=300)
            return result
        except asyncio.TimeoutError:
            logger.warning(f"ç¡®è®¤è¯·æ±‚ {request_id} è¶…æ—¶ã€‚")
            return False
        finally:
            if request_id in self.pending_confirmations:
                del self.pending_confirmations[request_id]

    def _clean_text(self, text: str, for_tts: bool = True) -> str:
        """æ¸…æ´—æ–‡æœ¬ï¼Œç§»é™¤æ ‡ç­¾ã€åŠ¨ä½œæè¿°ç­‰ä¸åº”æœ—è¯»çš„å†…å®¹"""
        if not text:
            return ""

        cleaned = text

        # 1. ç§»é™¤ XML æ ‡ç­¾ (åŒ…æ‹¬å†…å®¹)
        cleaned = re.sub(r'<[^>]+>.*?</[^>]+>', '', cleaned, flags=re.DOTALL)
        
        # 2. ç§»é™¤ NIT è°ƒç”¨å—
        from nit_core.dispatcher import remove_nit_tags
        cleaned = remove_nit_tags(cleaned)
        
        if for_tts:
            # [é‡è¦] ä¼˜å…ˆç§»é™¤ Markdown ä»£ç å—ï¼Œé¿å…æœ—è¯»ä»£ç å†…å®¹
            # åŒ¹é… ```...``` (å¤šè¡Œ) å’Œ `...` (å•è¡Œ)
            cleaned = re.sub(r'```[\s\S]*?```', ' ', cleaned)
            cleaned = re.sub(r'`[^`\n]+`', ' ', cleaned)

            # [é‡è¦] ç§»é™¤ URL é“¾æ¥
            cleaned = re.sub(r'https?://\S+', ' ', cleaned)

            # [ç‰¹æ€§] æ™ºèƒ½ ReAct è¿‡æ»¤å™¨
            # ç›®æ ‡ï¼šåªæœ—è¯»æœ€ç»ˆå›å¤ï¼Œå¿½ç•¥ æ€è€ƒ/è®¡åˆ’/è¡ŒåŠ¨/è§‚å¯Ÿ (Thinking/Plan/Action/Observation) çš„å†å²è®°å½•ã€‚
            
            # 0. å…¨å±€ç§»é™¤æ€è€ƒ (Thinking) å’Œ ç¢ç¢å¿µ (Monologue)
            # æ— è®ºæ˜¯å¦æ£€æµ‹åˆ° Final Answerï¼Œè¿™äº›å†…å®¹éƒ½ç»å¯¹ä¸åº”è¯¥æœ—è¯»
            cleaned = re.sub(r'ã€(?:Thinking|Monologue).*?ã€‘', '', cleaned, flags=re.DOTALL | re.IGNORECASE)
            cleaned = re.sub(r'\[(?:Thinking|Monologue).*?\]', '', cleaned, flags=re.DOTALL | re.IGNORECASE)

            # ç­–ç•¥ 1ï¼šå¦‚æœå­˜åœ¨ "Final Answer" (æœ€ç»ˆå›ç­”) æ ‡è®°ï¼Œåˆ™æå–å…¶åçš„æ‰€æœ‰å†…å®¹ã€‚
            final_marker = re.search(r'(?:Final Answer|æœ€ç»ˆå›ç­”|å›å¤)[:ï¼š]?\s*(.*)', cleaned, flags=re.DOTALL | re.IGNORECASE)
            if final_marker:
                cleaned = final_marker.group(1)
            else:
                # ç­–ç•¥ 2ï¼šé€šè¿‡å·²çŸ¥çš„ ReAct å—æ ‡é¢˜è¿›è¡Œåˆ†å‰²ï¼Œå¹¶æå–æœ€åä¸€å—ã€‚
                # è¿™å‡è®¾å›å¤æ€»æ˜¯åœ¨æœ€åã€‚
                
                # æ ‡å‡†åŒ–æ¢è¡Œç¬¦
                cleaned = cleaned.replace('\r\n', '\n')
                
                # è¯†åˆ«æœ€åä¸€ä¸ª "æŠ€æœ¯æ ‡é¢˜" å¹¶æå–å…¶åçš„å†…å®¹
                # æ ‡é¢˜åŒ…æ‹¬ï¼šPlan:, Action:, Observation:, Result:, Thought:
                # æˆ‘ä»¬æŸ¥æ‰¾è¿™äº›æ ‡é¢˜åœ¨è¡Œé¦–çš„æœ€åä¸€æ¬¡å‡ºç°
                headers_pattern = r'(?m)^(?:Plan|è®¡åˆ’|Action|Action Input|Observation|Result|Thought|Prompt)[:ï¼š]'
                
                matches = list(re.finditer(headers_pattern, cleaned))
                if matches:
                    last_match = matches[-1]
                    # ä»æœ€åä¸€ä¸ªæ ‡é¢˜ä¹‹åçš„è¡Œå¼€å§‹
                    # ç­‰ç­‰ï¼Œå¦‚æœæœ€åä¸€ä¸ªæ ‡é¢˜æ˜¯ "Plan:"ï¼Œæˆ‘ä»¬ä¹Ÿæƒ³è·³è¿‡è®¡åˆ’å†…å®¹ã€‚
                    # è®¡åˆ’å†…å®¹é€šå¸¸åœ¨ä¸‹ä¸€ä¸ªæ ‡é¢˜æˆ–åŒæ¢è¡Œç¬¦å¤„ç»“æŸã€‚
                    # æ—¢ç„¶æˆ‘ä»¬æ‰¾åˆ°äº†æœ€åä¸€ä¸ªæ ‡é¢˜ï¼Œé‚£ä¹ˆå®ƒä¹‹åçš„å†…å®¹è¦ä¹ˆæ˜¯è¯¥æ ‡é¢˜çš„å†…å®¹ï¼Œè¦ä¹ˆæ˜¯æœ€ç»ˆå›å¤ã€‚
                    
                    remaining = cleaned[last_match.start():]
                    
                    # å¯å‘å¼è§„åˆ™ï¼šå¦‚æœæ˜¯ Observation/Result/Actionï¼Œæˆ‘ä»¬è¦ä¹ˆä¸è¯»å®ƒã€‚
                    # ä½†å¦‚æœå®ƒæ˜¯å‰©ä¸‹çš„å”¯ä¸€å†…å®¹ï¼Œä¹Ÿè®¸æˆ‘ä»¬ä»€ä¹ˆéƒ½ä¸åº”è¯¥è¯»ï¼Ÿ
                    # ç„¶è€Œï¼Œé€šå¸¸åœ¨æŠ€æœ¯å—ä¹‹åä¼šæœ‰æ–‡æœ¬ã€‚
                    
                    # è®©æˆ‘ä»¬å°è¯•ç§»é™¤ä¸æœ€åä¸€ä¸ªå—å…³è”çš„ *è¡Œ*ï¼Œå¦‚æœå®ƒä»¬çœ‹èµ·æ¥åƒæŠ€æœ¯å†…å®¹ã€‚
                    # ä½†æ›´ç®€å•çš„æ–¹æ³•ï¼šæœ€ç»ˆå›å¤é€šå¸¸ä¸ä»¥å…³é”®å­—å¼€å¤´ã€‚
                    # æ‰€ä»¥å¦‚æœæˆ‘ä»¬æœ‰ `Observation: ... \n Hello`ï¼Œæˆ‘ä»¬è¦çš„æ˜¯ `Hello`ã€‚
                    
                    # è®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª "å—å‰¥ç¦»å™¨" (Block Stripper) æ¥ç§»é™¤æ‰€æœ‰å·²çŸ¥çš„æŠ€æœ¯å—ã€‚
                    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æŠ€æœ¯å—ï¼šæ ‡é¢˜ -> å†…å®¹ -> ä¸‹ä¸€ä¸ªæ ‡é¢˜/ç»“å°¾
                    
                    block_pattern = r'(?m)^(?:Plan|è®¡åˆ’|Action|Action Input|Observation|Result|Thought|Prompt)[:ï¼š][\s\S]*?(?=(?:^(?:Plan|è®¡åˆ’|Action|Action Input|Observation|Result|Thought|Prompt|Final Answer|æœ€ç»ˆå›ç­”|å›å¤)[:ï¼š])|\Z)'
                    cleaned = re.sub(block_pattern, '', cleaned)

        # 4. ç§»é™¤åŠ¨ä½œæè¿° *...* æˆ– (åŠ¨ä½œ) æˆ– ï¼ˆåŠ¨ä½œï¼‰
        if for_tts:
            cleaned = re.sub(r'\*.*?\*', '', cleaned)
            cleaned = re.sub(r'\(.*?\)', '', cleaned) # ç§»é™¤åŠè§’æ‹¬å·å†…çš„åŠ¨ä½œæˆ–å¤‡æ³¨
            cleaned = re.sub(r'ï¼ˆ.*?ï¼‰', '', cleaned) # ç§»é™¤å…¨è§’æ‹¬å·å†…çš„åŠ¨ä½œæˆ–å¤‡æ³¨
        
        # 5. ç§»é™¤ Markdown æ ‡è®°
        if for_tts:
            cleaned = re.sub(r'#+\s+', '', cleaned) # ç§»é™¤æ ‡é¢˜ç¬¦å·
            cleaned = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', cleaned) # ç§»é™¤é“¾æ¥ï¼Œåªä¿ç•™æ–‡å­—
            cleaned = re.sub(r'[*_~]', '', cleaned) # ç§»é™¤ç²—ä½“ã€æ–œä½“ã€åˆ é™¤çº¿ç­‰æ ‡è®°
        
        # 6. ç§»é™¤ Emoji å’Œç‰¹æ®Šç¬¦å· (ä»…é’ˆå¯¹ TTS)
        if for_tts:
            # ç§»é™¤å¸¸è§ Emoji
            cleaned = re.sub(r'[\U00010000-\U0010ffff]', '', cleaned)
            # ç§»é™¤ç‰¹å®šé¢œæ–‡å­—æˆ–ç¬¦å·
            cleaned = re.sub(r'[^\w\s\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šâ€œâ€ï¼ˆï¼‰\n\.,!\?\-]', '', cleaned)
            # è¿›ä¸€æ­¥æ¸…æ´—å¯èƒ½æ®‹ç•™çš„è¿ç»­æ ‡ç‚¹æˆ–æ— æ„ä¹‰å­—ç¬¦
            cleaned = re.sub(r'[\-_]{2,}', ' ', cleaned)
        
        # 7. ç§»é™¤å¤šä½™ç©ºç™½
        cleaned = re.sub(r'\n+', '\n', cleaned).strip()
        
        return cleaned

    def _get_voice_params(self, full_response: str):
        """é²æ£’åœ°æ ¹æ®å›å¤ä¸­çš„å¿ƒæƒ…æ ‡ç­¾ (XML æˆ– NIT) æˆ–å†…å®¹ï¼ŒåŠ¨æ€è°ƒæ•´è¯­éŸ³å‚æ•°"""
        # ç»Ÿä¸€ä½¿ç”¨æ™“ä¼ŠéŸ³è‰²ï¼Œä½œä¸ºå…¨å±€é»˜è®¤åŸºç¡€å€¼
        voice = "zh-CN-XiaoyiNeural" 
        rate = "+15%"
        pitch = "+5Hz"

        # å°è¯•æå–å¿ƒæƒ…å…³é”®è¯
        mood_text = ""
        
        # æ–¹æ¡ˆ A: ä»å›å¤å†…å®¹ä¸­å¯»æ‰¾å¿ƒæƒ…æš—ç¤º (ç®€å•çš„å…³é”®è¯åŒ¹é…)
        mood_keywords = {
            "happy": ["å¼€å¿ƒ", "é«˜å…´", "å…´å¥‹", "ä¹"],
            "sad": ["ä¼¤å¿ƒ", "éš¾è¿‡", "å“­", "å§”å±ˆ"],
            "angry": ["ç”Ÿæ°”", "æ„¤æ€’", "ç«å¤§", "æ¼"],
            "neutral": ["å¥½å§", "çŸ¥é“", "å“¦", "å—¯"]
        }
        
        for mood, keywords in mood_keywords.items():
            if any(k in full_response for k in keywords):
                mood_text = mood
                break
        
        # æ–¹æ¡ˆ B: å°è¯•æ­£åˆ™åŒ¹é… <PEROCUE> æ ‡ç­¾ (æ—§ç‰ˆå…¼å®¹)
        if not mood_text:
            perocue_match = re.search(r'<PEROCUE>(.*?)</PEROCUE>', full_response, re.S)
            if perocue_match:
                raw_content = perocue_match.group(1).strip()
                try:
                    data = json.loads(raw_content)
                    mood_text = str(data.get("mood", ""))
                except:
                    mood_match = re.search(r'["\']mood["\']\s*:\s*["\']([^"\']+)["\']', raw_content)
                    if mood_match:
                        mood_text = mood_match.group(1)

        # æ–¹æ¡ˆ C: å¦‚æœæ ‡ç­¾è§£æå½»åº•å¤±è´¥ï¼Œå°±åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­æœç´¢â€œå¿ƒæƒ…â€ç›¸å…³çš„è¯ï¼ˆæœ€åçš„ä¿åº•ï¼‰
        if not mood_text:
            mood_text = full_response

        # æƒ…ç»ªå¾®è°ƒé€»è¾‘ (åœ¨æ™“ä¼Šçš„åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒ)
        if any(word in mood_text for word in ["å…´å¥‹", "å¼€å¿ƒ", "å–œæ‚¦", "æ¿€æ˜‚", "å˜¿å˜¿", "å¤ªæ£’äº†"]):
            # ä¿æŒå·…å³°çŠ¶æ€
            rate = "+20%"
            pitch = "+7Hz"
        elif any(word in mood_text for word in ["éš¾è¿‡", "ä½è½", "å§”å±ˆ", "ç–²æƒ«", "å””", "å‘œ"]):
            # ç¨å¾®æ²‰ç¨³ä¸€ç‚¹ï¼Œä½†ä¾ç„¶ä¿ç•™æ™“ä¼Šçš„åº•è‰²
            rate = "+5%"
            pitch = "+2Hz"
        elif any(word in mood_text for word in ["ç”Ÿæ°”", "æ„¤æ€’", "å“¼"]):
            # è¯­é€ŸåŠ å¿«ï¼ŒéŸ³è°ƒå˜å†²
            rate = "+25%"
            pitch = "+4Hz"
        elif any(word in mood_text for word in ["æ¸©é¦¨", "æ¸©æƒ…", "çˆ±", "ä¸»äºº"]):
            # ç¨å¾®æ…¢ä¸€ç‚¹ï¼Œæ˜¾å¾—ä¹–å·§
            rate = "+10%"
            pitch = "+5Hz"

        return voice, rate, pitch

    def _extract_triggers(self, text: str) -> dict:
        """
        [å·²å¼ƒç”¨] ä» LLM å›å¤ä¸­æå–äº¤äº’ç±»è§¦å‘å™¨æ ‡ç­¾ã€‚
        ç°å·²ç”± NIT åè®®ä¸‹çš„ UpdateStatusPlugin ç»Ÿä¸€å¤„ç†ã€‚
        """
        return {}





# å•ä¾‹
realtime_session_manager = RealtimeSessionManager()
