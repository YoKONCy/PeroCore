import asyncio
import os
import logging
import re
import json
import base64
from fastapi import WebSocket, WebSocketDisconnect
from typing import Optional
from services.asr_service import get_asr_service
from services.tts_service import get_tts_service
from services.agent_service import AgentService
from database import get_session
from models import ConversationLog, Config, AIModelConfig
from sqlmodel import select

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class RealtimeVoiceManager:
    """
    å®æ—¶è¯­éŸ³å¯¹è¯ç®¡ç†å™¨ (æ¨¡æ‹Ÿ N.E.K.O çš„å®æ—¶è¯­éŸ³æµç¨‹)
    - æ¥æ”¶å‰ç«¯éŸ³é¢‘æµ
    - VAD æ£€æµ‹ (ç›®å‰ç”±å‰ç«¯åšï¼Œè¿™é‡Œåªæ¥æ”¶åˆ†ç‰‡)
    - è¯­éŸ³è½¬æ–‡å­— (ASR)
    - æ–‡æœ¬å¯¹è¯ (Agent)
    - æ–‡å­—è½¬è¯­éŸ³ (TTS)
    - æ¨é€éŸ³é¢‘æµå›å‰ç«¯
    """
    def __init__(self):
        self.active_connections: list[WebSocket] = []
        self.asr_service = get_asr_service()
        self.tts_service = get_tts_service()
        self.current_task: Optional[asyncio.Task] = None

    def _clean_text(self, text: str, for_tts: bool = True) -> str:
        """æ¸…æ´—æ–‡æœ¬ï¼Œç§»é™¤æ ‡ç­¾ã€åŠ¨ä½œæè¿°ç­‰ä¸åº”æœ—è¯»çš„å†…å®¹"""
        # 1. ç§»é™¤ XML æ ‡ç­¾ (åŒ…æ‹¬å†…å®¹)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªç§»é™¤ç‰¹å®šçš„æ ‡ç­¾ï¼Œæˆ–è€…æ‰€æœ‰æ ‡ç­¾ï¼Ÿ
        # ç›®å‰ä¸»è¦ç§»é™¤ <PEROCUE> ç­‰æ§åˆ¶æ ‡ç­¾
        cleaned = re.sub(r'<[^>]+>.*?</[^>]+>', '', text, flags=re.DOTALL)
        
        # 2. ç§»é™¤ NIT è°ƒç”¨å—
        from nit_core.parser import NITParser
        cleaned = NITParser.remove_nit_blocks(cleaned)
        
        # 3. ç§»é™¤æ€è€ƒè¿‡ç¨‹ ã€Thinking: ...ã€‘
        # å¦‚æœæ˜¯ç”¨äº TTSï¼Œå¿…é¡»ç§»é™¤ï¼›å¦‚æœæ˜¯ç”¨äº UIå±•ç¤ºï¼Œå¯ä»¥ä¿ç•™ï¼ˆç”±å‰ç«¯æŠ˜å ï¼‰
        if for_tts:
            cleaned = re.sub(r'ã€Thinking.*?ã€‘', '', cleaned, flags=re.DOTALL | re.IGNORECASE)
        
        # 4. ç§»é™¤åŠ¨ä½œæè¿° *...*
        # TTS é€šå¸¸ä¸è¯»åŠ¨ä½œï¼ŒUI å¯ä»¥é€‰æ‹©ä¿ç•™æˆ–ç§»é™¤ã€‚è¿™é‡Œä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼ŒTTS æ¨¡å¼ä¸‹ç§»é™¤ã€‚
        # å¦‚æœæ˜¯ä¸ºäº† UI å±•ç¤ºï¼Œä¿ç•™åŠ¨ä½œæè¿°å¯èƒ½æ›´å¥½ï¼Œå¢åŠ è¡¨ç°åŠ›ã€‚
        if for_tts:
            cleaned = re.sub(r'\*.*?\*', '', cleaned)
        
        # 5. ç§»é™¤æ‹¬å·å†…çš„å¤‡æ³¨ (å¯é€‰ï¼Œè§†æƒ…å†µè€Œå®š)
        # cleaned = re.sub(r'\(.*?\)', '', cleaned)
        
        # 6. ç§»é™¤å¤šä½™ç©ºç™½
        cleaned = re.sub(r'\n+', '\n', cleaned)
        
        # 7. [Feature] Chatter Removal: Only read the last paragraph if for_tts is True
        # This helps avoid reading "Thinking" chatter or prefix text that is not the main response
        if for_tts:
             segments = [s.strip() for s in cleaned.split('\n') if s.strip()]
             if segments:
                 cleaned = segments[-1]
                 
        return cleaned.strip()

    def _get_voice_params(self, full_response: str):
        """é²æ£’åœ°æ ¹æ®å›å¤ä¸­çš„å¿ƒæƒ…æ ‡ç­¾ (XML æˆ– NIT) æˆ–å†…å®¹ï¼ŒåŠ¨æ€è°ƒæ•´è¯­éŸ³å‚æ•°"""
        # ç»Ÿä¸€ä½¿ç”¨æ™“ä¼ŠéŸ³è‰²ï¼Œä½œä¸ºå…¨å±€é»˜è®¤åŸºç¡€å€¼
        voice = "zh-CN-XiaoyiNeural" 
        rate = "+15%"
        pitch = "+5Hz"

        # å°è¯•æå–å¿ƒæƒ…å…³é”®è¯
        mood_text = ""
        
        # æ–¹æ¡ˆ A: å°è¯•ä» NIT åè®®å—ä¸­æå– mood å‚æ•° (æ–°ç‰ˆ)
        from nit_core.parser import NITParser
        nit_calls = NITParser.parse_text(full_response)
        for call in nit_calls:
            if call['plugin'] in ['update_character_status', 'update_status', 'set_status']:
                mood_text = call['params'].get('mood', '')
                if mood_text:
                    break
        
        # æ–¹æ¡ˆ B: å°è¯•æ­£åˆ™åŒ¹é… <PEROCUE> æ ‡ç­¾ (æ—§ç‰ˆå…¼å®¹)
        if not mood_text:
            perocue_match = re.search(r'<PEROCUE>(.*?)</PEROCUE>', full_response, re.S)
            if perocue_match:
                raw_content = perocue_match.group(1).strip()
                try:
                    data = json.loads(raw_content)
                    mood_text = str(data.get("mood", ""))
                except:
                    mood_match = re.search(r'["\']mood["\']\s*:\s*["\']([^"\']+)["\']', raw_content)
                    if mood_match:
                        mood_text = mood_match.group(1)

        # æ–¹æ¡ˆ C: å¦‚æœæ ‡ç­¾è§£æå½»åº•å¤±è´¥ï¼Œå°±åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­æœç´¢â€œå¿ƒæƒ…â€ç›¸å…³çš„è¯ï¼ˆæœ€åçš„ä¿åº•ï¼‰
        if not mood_text:
            mood_text = full_response

        # æƒ…ç»ªå¾®è°ƒé€»è¾‘ (åœ¨æ™“ä¼Šçš„åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒ)
        if any(word in mood_text for word in ["å…´å¥‹", "å¼€å¿ƒ", "å–œæ‚¦", "æ¿€æ˜‚", "å˜¿å˜¿", "å¤ªæ£’äº†"]):
            # ä¿æŒå·…å³°çŠ¶æ€
            rate = "+20%"
            pitch = "+7Hz"
        elif any(word in mood_text for word in ["éš¾è¿‡", "ä½è½", "å§”å±ˆ", "ç–²æƒ«", "å””", "å‘œ"]):
            # ç¨å¾®æ²‰ç¨³ä¸€ç‚¹ï¼Œä½†ä¾ç„¶ä¿ç•™æ™“ä¼Šçš„åº•è‰²
            rate = "+5%"
            pitch = "+2Hz"
        elif any(word in mood_text for word in ["ç”Ÿæ°”", "æ„¤æ€’", "å“¼"]):
            # è¯­é€ŸåŠ å¿«ï¼ŒéŸ³è°ƒå˜å†²
            rate = "+25%"
            pitch = "+4Hz"
        elif any(word in mood_text for word in ["æ¸©é¦¨", "æ¸©æƒ…", "çˆ±", "ä¸»äºº"]):
            # ç¨å¾®æ…¢ä¸€ç‚¹ï¼Œæ˜¾å¾—ä¹–å·§
            rate = "+10%"
            pitch = "+5Hz"

        return voice, rate, pitch

    def _extract_triggers(self, text: str) -> dict:
        """
        [å·²å¼ƒç”¨] ä» LLM å›å¤ä¸­æå–äº¤äº’ç±»è§¦å‘å™¨æ ‡ç­¾ã€‚
        ç°å·²ç”± NIT åè®®ä¸‹çš„ UpdateStatusPlugin ç»Ÿä¸€å¤„ç†ã€‚
        """
        return {}

    async def broadcast(self, message: dict):
        """å‘æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯å¹¿æ’­æ¶ˆæ¯"""
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                logger.warning(f"Broadcast failed for client: {e}")
                disconnected.append(connection)
        
        for connection in disconnected:
            if connection in self.active_connections:
                self.active_connections.remove(connection)

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info("Realtime voice client connected")

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info("Realtime voice client disconnected")

    async def handle_websocket(self, websocket: WebSocket):
        await self.connect(websocket)
        try:
            while True:
                # æ¥æ”¶å‰ç«¯å‘é€çš„æ¶ˆæ¯
                # æ¶ˆæ¯æ ¼å¼: {"type": "audio", "data": "base64..."} æˆ– {"type": "text", "content": "..."}
                message = await websocket.receive_json()
                
                if message.get("type") == "audio_chunk":
                    # å¤„ç†éŸ³é¢‘åˆ†ç‰‡ (æš‚å­˜æˆ–æµå¼è¯†åˆ«)
                    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾å‰ç«¯å·²ç»åšäº† VADï¼Œå‘é€çš„æ˜¯ä¸€æ®µå®Œæ•´çš„è¯­éŸ³ (speech_end)
                    pass
                
                elif message.get("type") == "speech_end":
                    # è¯­éŸ³ç»“æŸï¼Œå¼€å§‹å¤„ç†
                    audio_data_base64 = message.get("data")
                    if audio_data_base64:
                        # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ (æ‰“æ–­æœºåˆ¶)
                        if self.current_task and not self.current_task.done():
                            print("[VOICE] Interruption detected! Cancelling current thinking task...")
                            self.current_task.cancel()
                            try:
                                await self.current_task
                            except asyncio.CancelledError:
                                print("[VOICE] Previous task cancelled successfully.")
                            except Exception as e:
                                print(f"[VOICE] Error cancelling previous task: {e}")
                        
                        # 2. å¯åŠ¨æ–°ä»»åŠ¡
                        self.current_task = asyncio.create_task(self._process_voice_turn(websocket, audio_data_base64))

        except WebSocketDisconnect:
            self.disconnect(websocket)
            if self.current_task and not self.current_task.done():
                self.current_task.cancel()
        except Exception as e:
            logger.error(f"WebSocket error: {e}")
            self.disconnect(websocket)
            if self.current_task and not self.current_task.done():
                self.current_task.cancel()

    async def _process_voice_turn(self, websocket: WebSocket, audio_base64: str):
        """å¤„ç†ä¸€è½®è¯­éŸ³å¯¹è¯"""
        import time
        start_turn_time = time.time()
        
        # 1. ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        temp_audio_path = f"temp_voice_{id(websocket)}.wav"
        try:
            print("\n" + "="*60)
            print(f"[VOICE] Start New Turn at {time.strftime('%H:%M:%S')}")
            print("="*60)
            
            with open(temp_audio_path, "wb") as f:
                f.write(base64.b64decode(audio_base64))
            
            # 2. ASR: è¯­éŸ³è½¬æ–‡å­— (æ— è®ºæ˜¯å¦åŸç”Ÿå¤šæ¨¡æ€ï¼Œéƒ½éœ€è¦ ASR æ–‡æœ¬ç”¨äºé•¿è®°å¿†æœç´¢å’Œå¯¹è¯å†å²)
            print("[ASR] Transcribing audio...")
            await websocket.send_json({"type": "status", "content": "listening"})
            
            asr_start = time.time()
            try:
                user_text = await self.asr_service.transcribe(temp_audio_path)
            except Exception as e:
                error_msg = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"
                logger.error(error_msg)
                await websocket.send_json({"type": "text_response", "content": f"[{error_msg}]"})
                await websocket.send_json({"type": "status", "content": "idle"})
                return

            asr_duration = time.time() - asr_start
            
            if not user_text or not user_text.strip():
                print(f"[ASR] No speech detected ({asr_duration:.2f}s).")
                await websocket.send_json({"type": "status", "content": "idle"})
                return


            print(f"[ASR] User said: \"{user_text}\" ({asr_duration:.2f}s)")
            await websocket.send_json({"type": "transcription", "content": user_text})

            # é‡ç½®é™ªä¼´æ¨¡å¼å®šæ—¶å™¨
            try:
                from services.companion_service import companion_service
                companion_service.update_activity()
            except Exception as e:
                logger.warning(f"[VoiceManager] Failed to reset companion timer: {e}")

            # 3. Agent: è·å–å›å¤
            print("[AGENT] Generating response...")
            
            async def report_status(status_type: str, content: str):
                """å†…éƒ¨å›è°ƒï¼Œç”¨äºå°† Agent çš„è¿›åº¦æ¨é€åˆ°å‰ç«¯"""
                print(f"   â³ [Status] {content}")
                try:
                    await websocket.send_json({"type": "status", "content": status_type, "message": content})
                except Exception as e:
                    logger.warning(f"Failed to send status (connection likely closed): {e}")
                    # å¦‚æœè¿æ¥æ–­å¼€ï¼Œè¿™é‡ŒæŠ›å‡ºå¼‚å¸¸ä¼šä¸­æ–­ Agent çš„æ‰§è¡Œ
                    # ä¸ºäº†ä¸è®© AgentService è®°ä¸º Errorï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©åæ‰å¼‚å¸¸ï¼Œ
                    # æˆ–è€…è®© AgentService è¯†åˆ«è¿™ç§ä¸­æ–­ã€‚
                    # ç›®å‰é€‰æ‹©æŠ›å‡ºï¼Œä»¥ä¾¿åœæ­¢åç»­æ— ç”¨çš„ç”Ÿæˆã€‚
                    raise WebSocketDisconnect()

            try:
                await websocket.send_json({"type": "status", "content": "thinking"})
            except Exception:
                return # å‘é€å¤±è´¥ç›´æ¥ç»“æŸ
            
            agent_start = time.time()
            # è·å–æ•°æ®åº“ session
            async for session in get_session():
                # --- Check for Native Audio Input ---
                enable_voice_input = False
                try:
                    # 1. Get current model ID
                    config_obj = (await session.exec(select(Config).where(Config.key == "current_model_id"))).first()
                    if config_obj and config_obj.value:
                        model_id_db = int(config_obj.value)
                        # 2. Get model config
                        model_config = await session.get(AIModelConfig, model_id_db)
                        if model_config and model_config.enable_voice:
                            enable_voice_input = True
                except Exception as e:
                    logger.warning(f"Failed to check voice input config: {e}")

                messages_payload = [{"role": "user", "content": user_text}]
                
                if enable_voice_input:
                    print(f"[VOICE] Native Audio Input Enabled. Path: {temp_audio_path}")
                    try:
                        if os.path.exists(temp_audio_path):
                            with open(temp_audio_path, "rb") as f:
                                audio_bytes = f.read()
                                audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                            
                            print(f"[VOICE] Audio loaded. Size: {len(audio_bytes)} bytes. Preparing payload...")
                            
                            # --- EXPERIMENT: Multi-modal Compatibility Payload ---
                            # We provide BOTH the new OpenAI 'input_audio' 
                            # AND a 'data_url' style content which many Gemini proxies use.
                            messages_payload = [{
                                "role": "user",
                                "content": [
                                    {
                                        "type": "text",
                                        "text": f"[ä¸»äººæ­£åœ¨é€šè¿‡è¯­éŸ³äº¤æµ (ASR é¢„è§ˆ: {user_text})]" 
                                    },
                                    {
                                        "type": "input_audio", 
                                        "input_audio": {
                                            "data": audio_b64,
                                            "format": "wav" 
                                        }
                                    },
                                    # Hack: Some Gemini proxies use image_url with audio data
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:audio/wav;base64,{audio_b64}"
                                        }
                                    }
                                ]
                            }]
                            print("[VOICE] Sent Robust Multimodal (Text + Audio + Compatibility) payload to LLM.")
                        else:
                            print(f"[VOICE] Audio file not found: {temp_audio_path}")
                            messages_payload = [{"role": "user", "content": user_text}]
                    except Exception as e:
                        print(f"[VOICE] Failed to prepare audio payload: {e}")
                        import traceback
                        traceback.print_exc()
                        # Fallback to text-only
                        messages_payload = [{"role": "user", "content": user_text}]

                agent = AgentService(session)
                full_response = ""
                
                # æµå¼è·å–å›å¤æ–‡æœ¬
                try:
                    async for chunk in agent.chat(
                        messages_payload, 
                        source="desktop",
                        session_id="voice_session",
                        on_status=report_status,
                        is_voice_mode=True,
                        user_text_override=user_text # Pass text here for memory/logging
                    ):
                        if chunk:
                            full_response += chunk
                except WebSocketDisconnect:
                    print("[VOICE] User disconnected during generation.")
                    return
                except Exception as e:
                    print(f"[VOICE] Error during generation: {e}")
                
                agent_duration = time.time() - agent_start
                print(f"[AGENT] Response generated (Length: {len(full_response)}, {agent_duration:.2f}s)")
                
                # 4. å¤„ç†å›å¤ï¼šè§£ææ ‡ç­¾ã€ä¿å­˜æ—¥å¿— (AgentService å·²å¤„ç†)ã€TTS
                print("[PROCESS] Parsing tags and preparing TTS...")
                
                # 4.1 è§£æå¹¶æ‰§è¡Œå…ƒæ•°æ® (AgentService.chat å†…éƒ¨å·²è°ƒç”¨ _save_parsed_metadata)
                # ä½†ç”±äº _save_parsed_metadata æ˜¯åœ¨ chat ç»“æŸæ—¶è°ƒç”¨çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¯ä»¥ä¿ç•™æˆ–åˆ é™¤
                # ä¸ºäº†å®‰å…¨ï¼ŒAgentService.chat å·²ç»å¤„ç†äº† _save_parsed_metadata
                
                # 4.2 æå–çº¯æ–‡æœ¬
                # UI å±•ç¤ºç”¨ï¼šä¿ç•™æ€è€ƒè¿‡ç¨‹å’ŒåŠ¨ä½œæè¿°ï¼Œç”±å‰ç«¯å¤„ç†å±•ç¤º
                ui_response = self._clean_text(full_response, for_tts=False)
                # TTS åˆæˆç”¨ï¼šç§»é™¤æ€è€ƒè¿‡ç¨‹å’ŒåŠ¨ä½œæè¿°ï¼Œç¡®ä¿è¯­éŸ³å¹²å‡€
                tts_response = self._clean_text(full_response, for_tts=True)
                
                if not ui_response:
                    ui_response = "å””...Peroå¥½åƒèµ°ç¥äº†..." # Fallback
                if not tts_response:
                    tts_response = "å””...Peroå¥½åƒèµ°ç¥äº†..." # Fallback

                # 4.3 å‘é€çº¯æ–‡æœ¬ç»™å‰ç«¯å±•ç¤º
                try:
                    await websocket.send_json({"type": "status", "content": "speaking"})
                    
                    await websocket.send_json({"type": "text_response", "content": ui_response})
                except Exception as e:
                    logger.warning(f"Failed to send text response: {e}")
                    return

                # 4.4 åŠ¨æ€é€‰æ‹©éŸ³è‰²å’Œè¯­é€Ÿ
                target_voice, target_rate, target_pitch = self._get_voice_params(full_response)
                
                # 4.6 TTS åˆæˆå¹¶æ’­æ”¾
                print(f"[TTS] Synthesizing with {target_voice} (Rate: {target_rate})...")
                tts_start = time.time()
                audio_path = await self.tts_service.synthesize(
                    tts_response, 
                    voice=target_voice, 
                    rate=target_rate, 
                    pitch=target_pitch
                )
                tts_duration = time.time() - tts_start
                
                if audio_path:
                    print(f"[TTS] Audio ready ({tts_duration:.2f}s), sending to client.")
                    # è¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶è½¬ä¸º base64 å‘é€
                    try:
                        ext = os.path.splitext(audio_path)[1].replace('.', '') or "mp3"
                        with open(audio_path, "rb") as f:
                            audio_content = f.read()
                            audio_b64 = base64.b64encode(audio_content).decode('utf-8')
                            await websocket.send_json({
                                "type": "audio_response", 
                                "data": audio_b64,
                                "format": ext
                            })
                    except Exception as e:
                        logger.warning(f"Failed to send audio response: {e}")
                        return
                else:
                    print(f"âŒ [4/4] TTS: Failed to synthesize audio ({tts_duration:.2f}s).")
                
                total_duration = time.time() - start_turn_time
                print("="*60)
                print(f"ğŸ [Voice Pipeline] Turn Completed in {total_duration:.2f}s")
                print("="*60 + "\n")
                
                try:
                    await websocket.send_json({"type": "status", "content": "idle"})
                except:
                    pass
                break # åªå¤„ç†ä¸€æ¬¡ session

        except WebSocketDisconnect:
            logger.info("Client disconnected during voice turn")
        except Exception as e:
            logger.error(f"Error processing voice turn: {e}")
            try:
                await websocket.send_json({"type": "error", "content": str(e)})
            except:
                pass # å¿½ç•¥å‘é€é”™è¯¯ä¿¡æ¯æ—¶çš„å¤±è´¥
        finally:
            if os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)

# å•ä¾‹
voice_manager = RealtimeVoiceManager()
