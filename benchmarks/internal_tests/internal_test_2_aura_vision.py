"""
AuraVision æ¨¡å‹æ¨ç†æ€§èƒ½ä¸å‡†ç¡®åº¦æµ‹è¯• (Internal Test 2)

æµ‹è¯•å†…å®¹:
1. æ¨ç†å»¶è¿Ÿ (Latency Benchmark)
2. å‘é‡è´¨é‡ (Vector Quality)
3. æ„å›¾åŒ¹é…å‡†ç¡®åº¦ (æœç´¢æ€§èƒ½)
4. ç«¯åˆ°ç«¯æ€§èƒ½
"""

import sys
import os
import time
import statistics
from pathlib import Path

# æ·»åŠ  backend ç›®å½•åˆ°è·¯å¾„
BACKEND_DIR = Path(__file__).parent.parent.parent / "backend"
sys.path.insert(0, str(BACKEND_DIR))

import numpy as np

# å°è¯•åŠ è½½ Rust æ¨¡å—
try:
    from pero_vision_core import VisionIntentMemoryManager
    RUST_AVAILABLE = True
    print("âœ… Rust æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ Rust æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    RUST_AVAILABLE = False

# å°è¯•åŠ è½½ OpenCV
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸ OpenCV ä¸å¯ç”¨ï¼Œéƒ¨åˆ†æµ‹è¯•å°†è·³è¿‡")


class AuraVisionBenchmark:
    """AuraVision æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.model_path = BACKEND_DIR / "models" / "AuraVision" / "weights" / "auravision_v1.onnx"
        self.manager = None
        self.results = {}
        
    def setup(self) -> bool:
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        if not RUST_AVAILABLE:
            print("âŒ æ— æ³•åˆå§‹åŒ–: Rust æ¨¡å—ä¸å¯ç”¨")
            return False
            
        print(f"\nğŸ“ æ¨¡å‹è·¯å¾„: {self.model_path}")
        
        if not self.model_path.exists():
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ— æ¨¡å‹æ¨¡å¼è¿›è¡ŒåŸºç¡€æµ‹è¯•")
            self.manager = VisionIntentMemoryManager(None, 384)
            return True
        
        try:
            print("â³ åŠ è½½æ¨¡å‹ä¸­...")
            start = time.perf_counter()
            self.manager = VisionIntentMemoryManager(str(self.model_path), 384)
            load_time = (time.perf_counter() - start) * 1000
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ms)")
            self.results["model_load_time_ms"] = load_time
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def generate_random_pixels(self, seed: int = None) -> list:
        """ç”Ÿæˆéšæœºæµ‹è¯•åƒç´ æ•°æ® (64x64, å½’ä¸€åŒ–åˆ° [-1, 1])"""
        if seed is not None:
            np.random.seed(seed)
        return np.random.uniform(-1, 1, 64 * 64).astype(np.float32).tolist()

    def generate_edge_like_pixels(self, pattern: str = "horizontal") -> list:
        """ç”Ÿæˆæ¨¡æ‹Ÿè¾¹ç¼˜æ£€æµ‹åçš„åƒç´ æ•°æ®"""
        img = np.zeros((64, 64), dtype=np.float32)
        
        if pattern == "horizontal":
            # æ°´å¹³çº¿æ¡ (æ¨¡æ‹Ÿä»£ç ç¼–è¾‘å™¨)
            for i in range(0, 64, 8):
                img[i:i+2, :] = 1.0
        elif pattern == "grid":
            # ç½‘æ ¼ (æ¨¡æ‹Ÿå®«æ ¼å¸ƒå±€)
            for i in range(0, 64, 16):
                img[i:i+2, :] = 1.0
                img[:, i:i+2] = 1.0
        elif pattern == "vertical":
            # å‚ç›´çº¿æ¡ (æ¨¡æ‹Ÿä¾§è¾¹æ )
            for j in range(0, 64, 12):
                img[:, j:j+2] = 1.0
        elif pattern == "dense":
            # å¯†é›†çº¹ç† (æ¨¡æ‹Ÿä»£ç å—)
            img = np.random.choice([0.0, 1.0], size=(64, 64), p=[0.7, 0.3]).astype(np.float32)
        else:
            # éšæœº
            img = np.random.uniform(0, 1, (64, 64)).astype(np.float32)
            
        # å½’ä¸€åŒ–åˆ° [-1, 1]
        pixels = (img - 0.5) / 0.5
        return pixels.flatten().tolist()

    def benchmark_intent_engine(self, num_anchors: int = 100, num_queries: int = 100):
        """æµ‹è¯•æ„å›¾å¼•æ“ (IntentEngine) çš„æœç´¢æ€§èƒ½"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ„å›¾å¼•æ“æœç´¢æ€§èƒ½æµ‹è¯• (é”šç‚¹æ•°: {num_anchors}, æŸ¥è¯¢æ•°: {num_queries})")
        print("="*60)
        
        if not self.manager:
            print("âŒ ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return
        
        # 1. æ·»åŠ æµ‹è¯•é”šç‚¹
        print(f"\nâ³ æ·»åŠ  {num_anchors} ä¸ªæµ‹è¯•é”šç‚¹...")
        add_times = []
        for i in range(num_anchors):
            vector = np.random.randn(384).astype(np.float32).tolist()
            start = time.perf_counter()
            self.manager.add_intent_anchor(
                id=i,
                vector=vector,
                description=f"æµ‹è¯•é”šç‚¹ {i}",
                importance=np.random.uniform(0.5, 1.0),
                tags="test"
            )
            add_times.append((time.perf_counter() - start) * 1000)
        
        avg_add_time = statistics.mean(add_times)
        print(f"âœ… é”šç‚¹æ·»åŠ å®Œæˆ (å¹³å‡è€—æ—¶: {avg_add_time:.4f}ms/ä¸ª)")
        self.results["anchor_add_avg_ms"] = avg_add_time
        print(f"   æ€»é”šç‚¹æ•°: {self.manager.anchor_count()}")
        
        # 2. å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œæµ‹è¯•å®Œæ•´çš„æ¨ç†+æœç´¢é“¾è·¯
        if self.manager.is_model_loaded():
            print(f"\nâ³ æµ‹è¯•å®Œæ•´æ¨ç†é“¾è·¯ ({num_queries} æ¬¡)...")
            
            latencies = []
            for i in range(num_queries):
                pixels = self.generate_edge_like_pixels("horizontal" if i % 2 == 0 else "grid")
                
                start = time.perf_counter()
                result = self.manager.process_visual_input(
                    pixels=pixels,
                    propagation_steps=2,
                    propagation_decay=0.5
                )
                latency = (time.perf_counter() - start) * 1000
                latencies.append(latency)
            
            avg_latency = statistics.mean(latencies)
            p50 = statistics.median(latencies)
            p95 = latencies[int(len(latencies) * 0.95)] if len(latencies) > 20 else max(latencies)
            p99 = latencies[int(len(latencies) * 0.99)] if len(latencies) > 100 else max(latencies)
            
            print(f"\nâœ… å®Œæ•´æ¨ç†é“¾è·¯æ€§èƒ½:")
            print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
            print(f"   P50: {p50:.2f}ms")
            print(f"   P95: {p95:.2f}ms")
            print(f"   P99: {p99:.2f}ms")
            
            self.results["full_pipeline_avg_ms"] = avg_latency
            self.results["full_pipeline_p50_ms"] = p50
            self.results["full_pipeline_p95_ms"] = p95
        
        else:
            print("\nâš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡æ¨ç†æ€§èƒ½æµ‹è¯•")

    def benchmark_vector_quality(self, num_samples: int = 50):
        """æµ‹è¯•å‘é‡è´¨é‡ (L2 èŒƒæ•°ã€ç¨³å®šæ€§)"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å‘é‡è´¨é‡æµ‹è¯• (æ ·æœ¬æ•°: {num_samples})")
        print("="*60)
        
        if not self.manager or not self.manager.is_model_loaded():
            print("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡å‘é‡è´¨é‡æµ‹è¯•")
            return
        
        # æµ‹è¯•å‘é‡ç¨³å®šæ€§ (ç›¸åŒè¾“å…¥åº”äº§ç”Ÿç›¸åŒè¾“å‡º)
        print("\nâ³ æµ‹è¯•å‘é‡ç¨³å®šæ€§...")
        pixels_fixed = self.generate_edge_like_pixels("horizontal")
        results = []
        for _ in range(10):
            result = self.manager.search_intent(pixels_fixed, top_k=3)
            results.append(result)
        
        # æ£€æŸ¥æ‰€æœ‰ç»“æœæ˜¯å¦ä¸€è‡´
        all_same = all(r == results[0] for r in results)
        stability = "âœ… ç¨³å®š" if all_same else "âŒ ä¸ç¨³å®š"
        print(f"   å‘é‡ç¨³å®šæ€§: {stability}")
        self.results["vector_stability"] = all_same

    def benchmark_preprocessing(self, num_iterations: int = 100):
        """æµ‹è¯•é¢„å¤„ç†æ€§èƒ½ (Python ä¾§)"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š é¢„å¤„ç†æ€§èƒ½æµ‹è¯• (è¿­ä»£æ¬¡æ•°: {num_iterations})")
        print("="*60)
        
        if not CV2_AVAILABLE:
            print("âš ï¸ OpenCV ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„å¤„ç†æµ‹è¯•")
            return
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„åŸå§‹æˆªå›¾ (å‡è®¾ 1920x1080)
        dummy_screenshot = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
        
        print(f"\nâ³ æµ‹è¯•é¢„å¤„ç†å»¶è¿Ÿ ({num_iterations} æ¬¡)...")
        latencies = []
        
        for _ in range(num_iterations):
            start = time.perf_counter()
            
            # 1. ç¼©æ”¾
            img_resized = cv2.resize(dummy_screenshot, (64, 64), interpolation=cv2.INTER_AREA)
            # 2. ç°åº¦åŒ–
            img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
            # 3. Canny è¾¹ç¼˜æ£€æµ‹
            img_edges = cv2.Canny(img_gray, 100, 200)
            # 4. å½’ä¸€åŒ–
            pixels = (img_edges.astype(np.float32) / 255.0 - 0.5) / 0.5
            _ = pixels.flatten().tolist()
            
            latency = (time.perf_counter() - start) * 1000
            latencies.append(latency)
        
        avg_latency = statistics.mean(latencies)
        p50 = statistics.median(latencies)
        
        print(f"\nâœ… é¢„å¤„ç†æ€§èƒ½:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.3f}ms")
        print(f"   P50: {p50:.3f}ms")
        
        self.results["preprocess_avg_ms"] = avg_latency
        self.results["preprocess_p50_ms"] = p50

    def benchmark_cold_vs_warm(self, num_warmup: int = 10, num_measure: int = 50):
        """æµ‹è¯•å†·å¯åŠ¨ vs çƒ­å¯åŠ¨æ€§èƒ½"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å†·å¯åŠ¨ vs çƒ­å¯åŠ¨æµ‹è¯•")
        print("="*60)
        
        if not self.manager or not self.manager.is_model_loaded():
            print("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
            return
        
        pixels = self.generate_edge_like_pixels("grid")
        
        # å†·å¯åŠ¨ (ç¬¬ä¸€æ¬¡æ¨ç†)
        print("\nâ³ æµ‹è¯•å†·å¯åŠ¨...")
        start = time.perf_counter()
        _ = self.manager.search_intent(pixels, top_k=5)
        cold_latency = (time.perf_counter() - start) * 1000
        print(f"   å†·å¯åŠ¨å»¶è¿Ÿ: {cold_latency:.2f}ms")
        
        # é¢„çƒ­
        print(f"\nâ³ é¢„çƒ­ ({num_warmup} æ¬¡)...")
        for _ in range(num_warmup):
            _ = self.manager.search_intent(pixels, top_k=5)
        
        # çƒ­å¯åŠ¨
        print(f"\nâ³ æµ‹è¯•çƒ­å¯åŠ¨ ({num_measure} æ¬¡)...")
        warm_latencies = []
        for _ in range(num_measure):
            start = time.perf_counter()
            _ = self.manager.search_intent(pixels, top_k=5)
            warm_latencies.append((time.perf_counter() - start) * 1000)
        
        avg_warm = statistics.mean(warm_latencies)
        print(f"   çƒ­å¯åŠ¨å¹³å‡å»¶è¿Ÿ: {avg_warm:.2f}ms")
        print(f"   åŠ é€Ÿæ¯”: {cold_latency / avg_warm:.2f}x")
        
        self.results["cold_start_ms"] = cold_latency
        self.results["warm_avg_ms"] = avg_warm

    def run_all(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸš€ AuraVision æ¨ç†æ€§èƒ½ä¸å‡†ç¡®åº¦æµ‹è¯•")
        print("="*60)
        
        if not self.setup():
            print("\nâŒ æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
            return
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.benchmark_preprocessing()
        self.benchmark_intent_engine(num_anchors=100, num_queries=100)
        self.benchmark_vector_quality()
        self.benchmark_cold_vs_warm()
        
        # æ±‡æ€»ç»“æœ
        self.print_summary()

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ±‡æ€»"""
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*60)
        
        for key, value in self.results.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.4f}")
            else:
                print(f"   {key}: {value}")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡
        print("\n" + "-"*60)
        print("ğŸ¯ æ€§èƒ½ç›®æ ‡æ£€æŸ¥ (ç›®æ ‡: <15ms æ¨ç†å»¶è¿Ÿ)")
        print("-"*60)
        
        if "full_pipeline_avg_ms" in self.results:
            avg = self.results["full_pipeline_avg_ms"]
            status = "âœ… è¾¾æ ‡" if avg < 15 else "âŒ æœªè¾¾æ ‡"
            print(f"   å®Œæ•´é“¾è·¯å¹³å‡å»¶è¿Ÿ: {avg:.2f}ms - {status}")
        
        if "preprocess_avg_ms" in self.results:
            avg = self.results["preprocess_avg_ms"]
            status = "âœ… è¾¾æ ‡" if avg < 5 else "âš ï¸ åæ…¢"
            print(f"   é¢„å¤„ç†å¹³å‡å»¶è¿Ÿ: {avg:.3f}ms - {status}")


def main():
    benchmark = AuraVisionBenchmark()
    benchmark.run_all()


if __name__ == "__main__":
    main()
