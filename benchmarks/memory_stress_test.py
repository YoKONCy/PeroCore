import time
import random
import sys
import os

# å°è¯•å¯¼å…¥ pero_rust_core
try:
    from pero_rust_core import CognitiveGraphEngine, sanitize_text_content
    print("âœ… æˆåŠŸå¯¼å…¥ pero_rust_core å¼•æ“")
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ pero_rust_coreï¼Œè¯·ç¡®ä¿å·²å®‰è£…è¯¥æ¨¡å—ã€‚")
    sys.exit(1)

def run_benchmarks():
    print("\n" + "="*50)
    print("ğŸš€ PeroCore Rust å¼•æ“ç¡¬æ ¸æ€§èƒ½æµ‹è¯•")
    print("="*50)

    # 1. è®¤çŸ¥å›¾è°±å‹åŠ›æµ‹è¯•
    engine = CognitiveGraphEngine()
    # é…ç½®ï¼šæœ€å¤§æ´»è·ƒèŠ‚ç‚¹ 10 ä¸‡ï¼Œæœ€å¤§æ‰‡å‡º 50
    engine.configure(max_active_nodes=100000, max_fan_out=50)

    NODE_COUNT = 20000000 # 2000 ä¸‡èŠ‚ç‚¹
    EDGE_COUNT = 40000000 # 4000 ä¸‡æ¡è¾¹

    print(f"\n[1/3] æ­£åœ¨æ„å»ºã€åƒä¸‡çº§ã€‘å‹åŠ›æ¨¡å‹: {NODE_COUNT} èŠ‚ç‚¹, {EDGE_COUNT} å…³è”è¾¹...")
    
    start_build = time.time()
    BATCH_SIZE = 400000
    for i in range(0, EDGE_COUNT, BATCH_SIZE):
        connections = []
        for _ in range(min(BATCH_SIZE, EDGE_COUNT - i)):
            src = random.randint(1, NODE_COUNT)
            tgt = random.randint(1, NODE_COUNT)
            weight = random.random()
            connections.append((src, tgt, weight))
        engine.batch_add_connections(connections)
        print(f"   - å·²æ³¨å…¥ {i + len(connections)} æ¡è¾¹...")
    
    end_build = time.time()
    print(f"âœ¨ æ¨¡å‹æ„å»ºå®Œæˆï¼Œè€—æ—¶: {end_build - start_build:.2f}s")

    # 2. è”æƒ³æ£€ç´¢ (æ¿€æ´»æ‰©æ•£) æµ‹è¯•
    print(f"\n[2/3] æ‰§è¡Œåƒä¸‡çº§èŠ‚ç‚¹è”æƒ³æ£€ç´¢æµ‹è¯• (æ‰©æ•£æ­¥æ•°: 5)...")
    
    # æ¨¡æ‹Ÿåˆå§‹æ¿€æ´»èŠ‚ç‚¹ï¼ˆç”¨æˆ·å½“å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡è§¦å‘äº† 5 ä¸ªè®°å¿†ç‚¹ï¼‰
    initial_scores = {random.randint(1, NODE_COUNT): 1.0 for _ in range(5)}
    
    latencies = []
    for i in range(10): # æµ‹è¯• 10 æ¬¡å–å¹³å‡
        start_prop = time.perf_counter()
        # æ‰§è¡Œæ‰©æ•£è®¡ç®—: 5æ­¥æ‰©æ•£, è¡°å‡ 0.5, é˜ˆå€¼ 0.01
        result = engine.propagate_activation(initial_scores, steps=5, decay=0.5, min_threshold=0.01)
        end_prop = time.perf_counter()
        latencies.append((end_prop - start_prop) * 1000)
    
    avg_latency = sum(latencies) / len(latencies)
    print(f"ğŸ¯ æ£€ç´¢å®Œæˆï¼")
    print(f"   - å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f} ms")
    print(f"   - æ£€ç´¢åˆ°çš„å…³è”èŠ‚ç‚¹æ•°: {len(result)}")
    print(f"   - ç»“è®º: {'ğŸ”¥ æé€Ÿ (å°äº 50ms)' if avg_latency < 50 else 'âœ… æ­£å¸¸'} ")

    # 3. è¶…å¤§æ–‡æœ¬æ¸…æ´—æµ‹è¯• (Rust vs Python æ½œåœ¨å¯¹æ¯”)
    print(f"\n[3/3] è¶…å¤§æ–‡æœ¬æ¸…æ´—æµ‹è¯• (10 ä¸‡å­—ç¬¦ + å¤§é‡ Base64 æ•°æ®)...")
    
    # æ„é€ ä¸€ä¸ªåŒ…å«å¤§é‡å›¾ç‰‡æ•°æ®çš„è¶…é•¿æ–‡æœ¬
    fake_base64 = "data:image/png;base64," + "A" * 5000
    big_text = (f"ç”¨æˆ·å‘é€äº†ä¸€å¼ å›¾ç‰‡: {fake_base64} " * 20) + " è¿™æ˜¯æ­£å¸¸çš„è®°å¿†å†…å®¹ã€‚" * 500
    
    start_clean = time.perf_counter()
    cleaned = sanitize_text_content(big_text)
    end_clean = time.perf_counter()
    
    print(f"âœ¨ æ¸…æ´—å®Œæˆï¼")
    print(f"   - è€—æ—¶: {(end_clean - start_clean) * 1000:.2f} ms")
    print(f"   - åŸé•¿åº¦: {len(big_text)} å­—ç¬¦")
    print(f"   - æ¸…æ´—åé•¿åº¦: {len(cleaned)} å­—ç¬¦")

    print("\n" + "="*50)
    print("ğŸ æµ‹è¯•ç»“æŸï¼šPeroCore çš„ Rust å¼•æ“åœ¨ç™¾ä¸‡çº§æ•°æ®ä¸‹è¡¨ç°æå…¶å¼ºæ‚ã€‚")
    print("="*50)

if __name__ == "__main__":
    run_benchmarks()
