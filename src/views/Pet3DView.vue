<template>
  <div class="pet-3d-container">
    <!-- 3D Avatar Component -->
    <!-- 3D ËßíËâ≤ÁªÑ‰ª∂ -->
    <BedrockAvatar 
      ref="avatarRef" 
      @pet="onPet"
      @hover-start="onHoverStart"
      @hover-end="onHoverEnd"
    />
    
    <!-- UI Overlay -->
    <!-- UI Ë¶ÜÁõñÂ±Ç -->
    <div class="ui-overlay" @mouseenter="onUIEnter" @mouseleave="onUILeave">
       <!-- Status Tags (Top Left) -->
       <!-- Áä∂ÊÄÅÊ†áÁ≠æ (Â∑¶‰∏äËßí) -->
       <transition name="fade">
         <div class="status-tags" v-show="showInput">
            <div class="status-tag mood" :title="'ÊÉÖÁª™: ' + moodText">‚ù§Ô∏è {{ moodText }}</div>
            <div class="status-tag vibe" :title="'Ê∞õÂõ¥: ' + vibeText">‚ú® {{ vibeText }}</div>
            <div class="status-tag mind" :title="'ÂÜÖÂøÉ: ' + mindText">üí≠ {{ mindText }}</div>
         </div>
       </transition>

      <!-- Floating Trigger (Light Orb) -->
      <!-- ÊÇ¨ÊµÆËß¶ÂèëÂô® (ÂÖâÁêÉ) -->
      <div 
        class="floating-trigger" 
        :class="{ active: showInput }"
        @click.stop="toggleUI"
        style="-webkit-app-region: no-drag;"
        @mouseenter="onUIEnter"
        @mouseleave="onUILeave"
      >
        <div class="trigger-core">
          <div class="pulse-ring"></div>
          <div class="core-dot"></div>
        </div>
      </div>

      <!-- Input Overlay -->
      <!-- ËæìÂÖ•Ë¶ÜÁõñÂ±Ç -->
      <div class="input-overlay" v-show="showInput" @mouseenter="onUIEnter">
        <input 
          ref="inputRef"
          v-model="userInput" 
          @keyup.enter="sendMessage"
          :placeholder="isWorkMode ? 'Â∑•‰ΩúÊ®°Âºè‰∏ãÂ∑≤Á¶ÅÁî®ËæìÂÖ•' : `Ë∑ü ${currentAgentName} ÂØπËØù...`"
          class="chat-input"
          :disabled="isThinking || isWorkMode"
          style="-webkit-app-region: no-drag;"
        />
      </div>

      <!-- Avatar Tools -->
      <!-- ËßíËâ≤Â∑•ÂÖ∑ -->
      <div class="pet-tools" v-show="showInput" style="-webkit-app-region: no-drag;" @mouseenter="onUIEnter">
        <button class="tool-btn" @click.stop="toggleAppearanceMenu" title="Â§ñËßÇËÆæÁΩÆ" :class="{ active: showAppearanceMenu }">üé®</button>
        <button class="tool-btn" @click.stop="reloadPet" title="ÈáçËΩΩ">üîÑ</button>
        <button 
          class="tool-btn voice-btn" 
          @click.stop="cycleVoiceMode" 
          :class="{ 
            active: voiceMode !== 0,
            'mode-vad': voiceMode === 1,
            'mode-ptt': voiceMode === 2 
          }" 
          :title="voiceModeTitle"
        >
          {{ voiceModeIcon }}
        </button>
        <button class="tool-btn" @click.stop="openChatWindow" title="ËÅäÂ§©">üí¨</button>
        <button class="tool-btn" @click.stop="openDashboard" title="Èù¢Êùø">‚öôÔ∏è</button>
      </div>

      <!-- PTT Floating Button (Voxel Style) -->
      <!-- PTT ÊÇ¨ÊµÆÊåâÈíÆ (‰ΩìÁ¥†È£éÊ†º) -->
      <transition name="fade">
        <div 
          v-if="voiceMode === 2" 
          class="ptt-voxel-container"
          @mousedown.stop="startPTT"
          @mouseup.stop="stopPTT"
          @mouseleave.stop="stopPTT"
          style="-webkit-app-region: no-drag;"
        >
          <div class="ptt-voxel-btn" :class="{ recording: isPTTRecording }" title="Êåâ‰Ωè Alt+Shift+V ËØ¥ËØù">
            <span class="ptt-icon">üéôÔ∏è</span>
            <span class="ptt-text" v-if="isPTTRecording">LISTENING...</span>
          </div>
        </div>
      </transition>

      <!-- Appearance Menu (Voxel Style) -->
      <!-- Â§ñËßÇËèúÂçï (‰ΩìÁ¥†È£éÊ†º) -->
      <transition name="fade">
        <div class="appearance-menu" v-if="showAppearanceMenu && showInput" @mouseenter="onUIEnter">
          <div class="menu-header">
            <span>Â§ñËßÇÊéßÂà∂</span>
            <button class="close-mini-btn" @click="showAppearanceMenu = false">√ó</button>
          </div>
          
          <div class="menu-section" v-if="avatarRef && avatarRef.clothingState">
            <div class="menu-label">ÊúçË£ÖÈÉ®‰ª∂</div>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.dress" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Dress
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.armour" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Armour
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.hat" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Hat
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.underwear" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Underwear
            </label>
             <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.censored" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Censored
            </label>
          </div>

          <div class="menu-section" v-if="avatarRef && avatarRef.animList && avatarRef.animList.length > 0">
            <div class="menu-label">Âä®‰ΩúË∞ÉËØï</div>
            <select class="voxel-select" @change="(e) => avatarRef.setAnimation(e.target.value)">
              <option value="">-- ÈÄâÊã©Âä®‰Ωú --</option>
              <option v-for="anim in avatarRef.animList" :key="anim" :value="anim">{{ anim }}</option>
            </select>
          </div>
        </div>
      </transition>

       <!-- ÁßªÈô§‰∫Ü mode="out-in" ‰ª•ÂÖÅËÆ∏Âø´ÈÄüÁÇπÂáªÊó∂Á´ãÂç≥ÊõøÊç¢ -->
       <transition name="bubble-fade">
        <div 
          v-if="currentText || isThinking" 
          :key="bubbleKey"
          class="bubble" 
          :class="{ expanded: isBubbleExpanded }"
          :style="{ top: bubbleTop, left: bubbleLeft }"
        >
          <div class="bubble-content" :class="{ 'cursor-pointer': isThinking }" @mousedown.stop>
             <template v-if="isThinking">
               <span class="thinking-text">{{ thinkingMessage }}</span>
             </template>
             <template v-else>
               <div class="bubble-scroll-area" ref="bubbleScrollArea">
                 <div v-for="(segment, index) in parsedBubbleContent" :key="index" class="bubble-segment">
                   <span v-if="segment.type === 'text'">{{ segment.content }}</span>
                   <span v-else-if="segment.type === 'action'" class="action-text">*{{ segment.content }}*</span>
                   <div v-else-if="segment.type === 'thinking'" class="thinking-block">
                     <div class="thinking-label">üí≠ ÊÄùËÄÉËøáÁ®ã</div>
                     <div class="thinking-content">{{ segment.content }}</div>
                   </div>
                 </div>
               </div>
               <div v-if="isContentOverflowing" class="bubble-expand-btn" @click.stop="toggleBubbleExpand" @mousedown.stop>
                 {{ isBubbleExpanded ? 'Êî∂Ëµ∑' : 'Â±ïÂºÄ' }}
               </div>
             </template>
          </div>
          <div class="bubble-tail"></div>
        </div>
      </transition>
    </div>

    <!-- Êñá‰ª∂ÊêúÁ¥¢Ê®°ÊÄÅÊ°Ü -->
    <FileSearchModal v-model:visible="showFileModal" :files="foundFiles" />
  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, computed, watch, nextTick } from 'vue';
import BedrockAvatar from '../components/avatar/BedrockAvatar.vue';
import FileSearchModal from '../components/FileSearchModal.vue';
import { invoke, listen } from '@/utils/ipcAdapter';
import { API_BASE } from '../config';

const currentText = ref('‰∏ª‰∫∫ÔºåÊàëÂú®Ê°åÈù¢Á≠â‰Ω†Âæà‰πÖÂï¶ÔºÅ');
const isBubbleExpanded = ref(false);
const bubbleKey = ref(0);
const bubbleTop = ref('15%');
const bubbleLeft = ref('50%');
const avatarRef = ref(null);
let bubbleTimer = null;

// Debug refs
const debugGlobalX = ref(0);
const debugGlobalY = ref(0);
const showDebug = ref(false);

const isContentOverflowing = ref(false);
const bubbleScrollArea = ref(null);
const thinkingMessage = ref('Âä™ÂäõÊÄùËÄÉ‰∏≠...');

// --- Áä∂ÊÄÅÁÆ°ÁêÜ (Á¨¨‰∏ÄÈò∂ÊÆµ) ---
const currentAgentName = ref('Pero');
const moodText = ref(localStorage.getItem('ppc.mood') || 'ÂºÄÂøÉ');
const vibeText = ref(localStorage.getItem('ppc.vibe') || 'ËΩªÊùæ');
const mindText = ref(localStorage.getItem('ppc.mind') || 'ÂèëÂëÜ');
const isWorkMode = ref(false);
const voiceMode = ref(parseInt(localStorage.getItem('ppc.voice_mode') || '0'));
const isThinking = ref(false);
const isPTTRecording = ref(false); // PTT State
const isSpeaking = ref(false); // TTS State
const voiceWs = ref(null);
const audioContext = ref(null);
const mediaStream = ref(null);
const scriptProcessor = ref(null);
const currentAudioSource = ref(null);
const audioQueue = ref([]);
const isAudioPlaying = ref(false);
const lipSyncFrame = ref(null);
const analyser = ref(null);
let isStartingPTT = false;
let isSpeakingState = false;
let audioBuffer = [];
let lastRmsUpdate = 0;
const VAD_THRESHOLD = 0.01;
let silenceStart = Date.now();

const showInput = ref(false);
const userInput = ref('');
const inputRef = ref(null);
const showFileModal = ref(false);
const foundFiles = ref([]);
const showAppearanceMenu = ref(false);
const localTexts = ref({});

const parsedBubbleContent = computed(() => {
  const text = currentText.value || '';
  if (!text) return [];

  const segments = [];
  const regex = /(?:„Äê(Thinking|Error|Reflection|Monologue)[:Ôºö]?\s*([\s\S]*?)„Äë)|(?:\n|^)\s*\*([\s\S]+?)\*|(?:\n|^)\s*(Thought|Action)[:Ôºö]\s*([\s\S]+?)(?=\n\s*(?:Thought|Action)[:Ôºö]|\n\s*\*|„Äê(?:Thinking|Error|Reflection|Monologue)|$)|(?:<(nit(?:-[a-zA-Z0-9-]+)?)>[\s\S]*?<\/\1>)|(?:\[\[\[NIT_CALL\]\]\][\s\S]*?\[\[\[NIT_END\]\]\])/gi;
  
  let lastIndex = 0;
  let match;

  while ((match = regex.exec(text)) !== null) {
    if (match.index > lastIndex) {
      const normalText = text.substring(lastIndex, match.index);
      if (normalText.trim()) {
        segments.push({ type: 'text', content: normalText });
      }
    }
    
    if (match[1] !== undefined) {
      const type = match[1].toLowerCase();
      segments.push({ type: type === 'thinking' ? 'thinking' : type, content: match[2].trim() });
    } else if (match[3] !== undefined) {
      segments.push({ type: 'action', content: match[3].trim() });
    } else if (match[4] !== undefined) {
      const type = match[4].toLowerCase() === 'thought' ? 'thinking' : 'action';
      segments.push({ type, content: match[5].trim() });
    }
    
    lastIndex = regex.lastIndex;
  }
  
  if (lastIndex < text.length) {
    const normalText = text.substring(lastIndex);
    if (normalText.trim()) {
      segments.push({ type: 'text', content: normalText });
    }
  }
  
  return segments.filter(s => s.type === 'text' || s.type === 'action');
});

const checkOverflow = () => {
  if (bubbleScrollArea.value) {
    const el = bubbleScrollArea.value;
    isContentOverflowing.value = el.scrollHeight > 210;
    
    if (!isContentOverflowing.value) {
      isBubbleExpanded.value = false;
    }
  }
};

watch(parsedBubbleContent, async () => {
  await nextTick();
  checkOverflow();
}, { deep: true });

// Ê∞îÊ≥°Ëá™Âä®Ê∂àÂ§±ÈÄªËæë
watch([currentText, isThinking], ([newText, newThinking]) => {
  if (bubbleTimer) {
    clearTimeout(bubbleTimer);
    bubbleTimer = null;
  }

  // Âè™ÊúâÂú®ÈùûÊÄùËÄÉÁä∂ÊÄÅ‰∏îÊúâÊñáÂ≠óÊó∂ÔºåÊâçÂêØÂä®Ëá™Âä®Ê∂àÂ§±ÂÆöÊó∂Âô®
  if (newText && !newThinking) {
    // Ê†πÊçÆÊñáÂ≠óÈïøÂ∫¶Ë∞ÉÊï¥ÂÅúÁïôÊó∂Èó¥ÔºåÊúÄÂ∞ë 5 ÁßíÔºåÊúÄÂ§ö 15 Áßí
    const duration = Math.min(Math.max(5000, newText.length * 200), 15000);
    bubbleTimer = setTimeout(() => {
      currentText.value = '';
      isBubbleExpanded.value = false;
      bubbleTimer = null;
    }, duration);
  }
});

const toggleBubbleExpand = () => {
  isBubbleExpanded.value = !isBubbleExpanded.value;
  nextTick(() => {
     checkOverflow();
  });
};

const voiceModeIcon = computed(() => {
  if (voiceMode.value === 0) return 'üîá'
  if (voiceMode.value === 1) return 'üéôÔ∏è'
  return 'üñ±Ô∏è'
})

const voiceModeTitle = computed(() => {
  if (voiceMode.value === 0) return 'ËØ≠Èü≥ÂØπËØù: Â∑≤ÂÖ≥Èó≠'
  if (voiceMode.value === 1) return 'ËØ≠Èü≥ÂØπËØù: Ëá™Âä®ÊÑüÂ∫î (VAD)'
  return 'ËØ≠Èü≥ÂØπËØù: Êåâ‰ΩèËØ¥ËØù (PTT)'
})

// --- ËØ≠Èü≥Âíå PTT ÈÄªËæë ---

const cycleVoiceMode = async () => {
  if (isWorkMode.value) {
    currentText.value = '(Â∑•‰ΩúÊ®°Âºè‰∏ãÂ∑≤Á¶ÅÁî®ËØ≠Èü≥ÂäüËÉΩ)'
    return
  }
  
  const nextMode = (voiceMode.value + 1) % 3
  voiceMode.value = nextMode
  localStorage.setItem('ppc.voice_mode', nextMode.toString())
  
  // Show mode change in bubble
  if (nextMode === 0) {
      currentText.value = 'ËØ≠Èü≥ÂØπËØù: Â∑≤ÂÖ≥Èó≠'
      stopVoiceMode()
  } else if (nextMode === 1) {
      currentText.value = 'ÂàáÊç¢Âà∞: Ëá™Âä®ÊÑüÂ∫î (VAD)'
  } else {
      currentText.value = 'ÂàáÊç¢Âà∞: Êåâ‰ΩèËØ¥ËØù (PTT)'
  }
  isBubbleExpanded.value = true;
  bubbleKey.value++;
  
  if (nextMode !== 0) {
    // Â¶ÇÊûúËøòÊ≤°ÂºÄÂêØÈ∫¶ÂÖãÈ£é/WSÔºåÂàôÂºÄÂêØ
    if (!voiceWs.value) {
      await startVoiceMode()
    }
  }
}

const startVoiceMode = async () => {
    console.log('[Voice] Starting voice mode...');
    try {
        // 0. Á°Æ‰øù AudioContext Â≠òÂú®Âπ∂ÊøÄÊ¥ª
        if (!audioContext.value || audioContext.value.state === 'closed') {
            audioContext.value = new (window.AudioContext || window.webkitAudioContext)()
        }
        if (audioContext.value.state === 'suspended') {
            await audioContext.value.resume()
        }

        // 1. Ëé∑ÂèñÈ∫¶ÂÖãÈ£éÊùÉÈôê
        mediaStream.value = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // Ê£ÄÊü•Èü≥È¢ëËΩ®ÈÅì
        const audioTracks = mediaStream.value.getAudioTracks();
        if (audioTracks.length === 0) {
            throw new Error('No audio tracks found in media stream');
        }
        console.log('[Voice] Microphone access granted:', audioTracks[0].label);
        
        // 2. ËøûÊé• WebSocket
        voiceWs.value = new WebSocket('ws://localhost:9120/ws/voice');
        
        voiceWs.value.onopen = () => {
            console.log('Voice WebSocket connected');
            // Âú®Ê∞îÊ≥°‰∏≠ÊòæÁ§∫ËøûÊé•ÊàêÂäü
            currentText.value = `ËØ≠Èü≥ËøûÊé•ÊàêÂäü: ${voiceModeTitle.value}`;
            isBubbleExpanded.value = true;
            bubbleKey.value++;
            
            // 3. ÂºÄÂßãÂΩïÈü≥Â§ÑÁêÜ
            startRecording();
        };
        
        voiceWs.value.onmessage = handleVoiceMessage;
        
        voiceWs.value.onclose = () => {
            console.log('Voice WebSocket closed');
            stopVoiceMode();
        };
        
    } catch (err) {
        console.error('Failed to start voice mode:', err);
    }
};

const stopVoiceMode = () => {
    if (voiceWs.value) {
        voiceWs.value.close()
        voiceWs.value = null
    }
    
    if (mediaStream.value) {
        mediaStream.value.getTracks().forEach(track => track.stop())
        mediaStream.value = null
    }
    
    if (audioContext.value) {
        audioContext.value.close()
        audioContext.value = null
    }
}

const startRecording = () => {
    audioContext.value = new (window.AudioContext || window.webkitAudioContext)()
    const source = audioContext.value.createMediaStreamSource(mediaStream.value)
    
    // ‰ΩøÁî® ScriptProcessorNode Â§ÑÁêÜÈü≥È¢ëÊµÅ (Â∑≤Â∫üÂºÉ‰ΩÜÂπøÊ≥õÊîØÊåÅ)
    scriptProcessor.value = audioContext.value.createScriptProcessor(4096, 1, 1)
    
    source.connect(scriptProcessor.value)
    scriptProcessor.value.connect(audioContext.value.destination)
    
    scriptProcessor.value.onaudioprocess = (e) => {
        if (voiceMode.value === 0) return

        // Â¶ÇÊûúÊ≠£Âú®ÊÄùËÄÉÊàñÊ≠£Âú®ËØ¥ËØùÔºåÁõ¥Êé•ÂøΩÁï•Êñ∞ÁöÑËØ≠Èü≥ËæìÂÖ•
        if (isThinking.value || isSpeaking.value) {
             return
        }
        
        const inputData = e.inputBuffer.getChannelData(0)
        
        // --- Ê®°Âºè 2: Êåâ‰ΩèËØ¥ËØù (PTT) ---
        if (voiceMode.value === 2) {
            if (isPTTRecording.value) {
                audioBuffer.push(new Float32Array(inputData))
            }
            return
        }

        // --- Ê®°Âºè 1: Ëá™Âä®ÊÑüÂ∫î (VAD) ---
        // 1. ËÆ°ÁÆóÈü≥Èáè (RMS)
        let sum = 0
        for (let i = 0; i < inputData.length; i++) {
            sum += inputData[i] * inputData[i]
        }
        const rms = Math.sqrt(sum / inputData.length)
        
        // Ë∞ÉËØïÊó•ÂøóÔºöÊØèÁßíËæìÂá∫‰∏ÄÊ¨°ÂΩìÂâçÈü≥Èáè
        if (Date.now() - lastRmsUpdate > 1000) {
            // console.log('Current Mic Volume (RMS):', rms.toFixed(4), 'Threshold:', VAD_THRESHOLD)
            lastRmsUpdate = Date.now()
        }
        
        // 2. VAD ÈÄªËæë
        if (rms > VAD_THRESHOLD) {
            silenceStart = Date.now()
            if (!isSpeakingState) {
                console.log('Speech detected (Volume:', rms.toFixed(4), ')')
                isSpeakingState = true
                audioBuffer = [] // Ê∏ÖÁ©∫ buffer
            }
            // Êî∂ÈõÜÈü≥È¢ëÊï∞ÊçÆ
            audioBuffer.push(new Float32Array(inputData))
        } else {
            if (isSpeakingState) {
                // Â¶ÇÊûúÈùôÈü≥Ë∂ÖËøá 1000msÔºåËÆ§‰∏∫‰∏ÄÂè•ËØùÁªìÊùü
                if (Date.now() - silenceStart > 1000) {
                    console.log('Speech ended, sending buffer...')
                    isSpeakingState = false
                    sendAudioBuffer()
                } else {
                    // Áü≠ÊöÇÈùôÈü≥ÔºåÁªßÁª≠Êî∂ÈõÜ
                     audioBuffer.push(new Float32Array(inputData))
                }
            }
        }
    }
}

const startPTT = async () => {
    if (voiceMode.value !== 2) return
    if (isPTTRecording.value || isStartingPTT) return
    
    isStartingPTT = true
    try {
      if (isThinking.value || isSpeaking.value) {
        console.log('PTT Ignored: Pero is busy', { isThinking: isThinking.value, isSpeaking: isSpeaking.value })
        return
      }
      
      // Á°Æ‰øù AudioContext Â∑≤ÊøÄÊ¥ª
      if (audioContext.value && audioContext.value.state === 'suspended') {
        await audioContext.value.resume()
      }

      isPTTRecording.value = true
      isSpeakingState = true
      audioBuffer = []
      console.log('PTT Started')
    } finally {
      isStartingPTT = false
    }
}

const stopPTT = () => {
  if (!isPTTRecording.value) return
  isPTTRecording.value = false
  isSpeakingState = false
  console.log('PTT Ended, sending buffer...')
  sendAudioBuffer()
}

const sendAudioBuffer = () => {
    if (audioBuffer.length === 0) return
    
    // 1. ÂêàÂπ∂ buffer
    const length = audioBuffer.length * 4096
    const merged = new Float32Array(length)
    let offset = 0
    for (const chunk of audioBuffer) {
        merged.set(chunk, offset)
        offset += chunk.length
    }
    
    // 2. ËΩ¨Êç¢‰∏∫ WAV
    const wavBlob = encodeWAV(merged, audioContext.value.sampleRate)
    
    // 3. ËΩ¨ Base64 ÂèëÈÄÅ
    const reader = new FileReader()
    reader.onloadend = () => {
        const base64data = reader.result.split(',')[1]
        if (voiceWs.value && voiceWs.value.readyState === WebSocket.OPEN) {
            voiceWs.value.send(JSON.stringify({
                type: 'speech_end',
                data: base64data
            }))
        }
    }
    reader.readAsDataURL(wavBlob)
    
    audioBuffer = []
}

const encodeWAV = (samples, sampleRate) => {
    const buffer = new ArrayBuffer(44 + samples.length * 2)
    const view = new DataView(buffer)
    
    const writeString = (view, offset, string) => {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i))
        }
    }
    
    writeString(view, 0, 'RIFF')
    view.setUint32(4, 36 + samples.length * 2, true)
    writeString(view, 8, 'WAVE')
    writeString(view, 12, 'fmt ')
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true)
    view.setUint16(22, 1, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * 2, true)
    view.setUint16(32, 2, true)
    view.setUint16(34, 16, true)
    writeString(view, 36, 'data')
    view.setUint32(40, samples.length * 2, true)
    
    let offset = 44
    for (let i = 0; i < samples.length; i++) {
        let s = Math.max(-1, Math.min(1, samples[i]))
        s = s < 0 ? s * 0x8000 : s * 0x7FFF
        view.setInt16(offset, s, true)
        offset += 2
    }
    
    return new Blob([view], { type: 'audio/wav' })
}

const handleVoiceMessage = (event) => {
    const msg = JSON.parse(event.data)
    
    if (msg.type === 'status') {
        if (msg.content === 'listening') {
             stopAudioPlayback(true)
             isThinking.value = true
             thinkingMessage.value = 'Ê≠£Âú®Âê¨‰∏ª‰∫∫ËØ¥ËØù...'
             currentText.value = ''
        } else if (msg.content === 'thinking') {
             isThinking.value = true
             thinkingMessage.value = msg.message || 'Âä™ÂäõÊÄùËÄÉ‰∏≠...'
             currentText.value = ''
        } else if (msg.content === 'speaking') {
             isThinking.value = false
             thinkingMessage.value = 'Âä™ÂäõÊÄùËÄÉ‰∏≠...'
        } else if (msg.content === 'idle') {
             isThinking.value = false
             thinkingMessage.value = 'Âä™ÂäõÊÄùËÄÉ‰∏≠...'
        }
    } else if (msg.type === 'transcription') {
        console.log('User said:', msg.content)
    } else if (msg.type === 'text_response') {
        currentText.value = msg.content
        isThinking.value = false
        thinkingMessage.value = 'Âä™ÂäõÊÄùËÄÉ‰∏≠...'
    } else if (msg.type === 'triggers') {
        // applyTriggers(msg.data) // Not implemented in 3D view yet
    } else if (msg.type === 'audio_response') {
        playAudio(msg.data)
    } else if (msg.type === 'error') {
        console.error('Voice Error:', msg.content)
        currentText.value = `(ÈîôËØØ: ${msg.content})`
        isThinking.value = false
    }
}

const stopAudioPlayback = (clearQueue = false) => {
    stopLipSync(); // Stop lip sync immediately
    if (clearQueue) {
        audioQueue.value = []
        isAudioPlaying.value = false
    }
    
    if (currentAudioSource.value) {
        try {
            currentAudioSource.value.stop()
        } catch (e) {
            // ignore
        }
        currentAudioSource.value = null
    }
    isSpeaking.value = false
}

const playAudio = async (base64Audio) => {
    if (!base64Audio) return
    audioQueue.value.push(base64Audio)
    if (!isAudioPlaying.value) {
        processAudioQueue()
    }
}

const startLipSync = (analyserNode) => {
    if (lipSyncFrame.value) cancelAnimationFrame(lipSyncFrame.value);

    const update = () => {
        if (!isSpeaking.value || !analyserNode) {
            if (avatarRef.value && avatarRef.value.setLipSync) {
                avatarRef.value.setLipSync(0);
            }
            return;
        }

        const dataArray = new Uint8Array(analyserNode.frequencyBinCount);
        analyserNode.getByteFrequencyData(dataArray);

        // Calculate average volume from relevant bins (voice range)
        // ËÆ°ÁÆóÁõ∏ÂÖ≥È¢ëÊÆµÔºà‰∫∫Â£∞ËåÉÂõ¥ÔºâÁöÑÂπ≥ÂùáÈü≥Èáè
        let sum = 0;
        const startBin = 2; // Skip very low rumble
        const endBin = 32;  // Focus on voice frequencies (approx 0-2.7kHz with 256 FFT/44.1k)
        for (let i = startBin; i < endBin; i++) {
            sum += dataArray[i];
        }
        const average = sum / (endBin - startBin);
        
        // Normalize (0-255 -> 0-1) and apply gain
        // ÂΩí‰∏ÄÂåñ (0-255 -> 0-1) Âπ∂Â∫îÁî®Â¢ûÁõä
        // Multiply by 3.0 to make the mouth open more for normal speech
        const volume = Math.min(1.0, (average / 255) * 3.0);

        if (avatarRef.value && avatarRef.value.setLipSync) {
            avatarRef.value.setLipSync(volume);
        }

        lipSyncFrame.value = requestAnimationFrame(update);
    };
    update();
};

const stopLipSync = () => {
    if (lipSyncFrame.value) {
        cancelAnimationFrame(lipSyncFrame.value);
        lipSyncFrame.value = null;
    }
    if (avatarRef.value && avatarRef.value.setLipSync) {
        avatarRef.value.setLipSync(0);
    }
};

const processAudioQueue = async () => {
    if (audioQueue.value.length === 0) {
        isAudioPlaying.value = false
        isSpeaking.value = false
        return
    }

    isAudioPlaying.value = true
    const base64Audio = audioQueue.value.shift()

    isSpeaking.value = true
    
    let ctx = audioContext.value
    
    if (!ctx || ctx.state === 'closed') {
        ctx = new (window.AudioContext || window.webkitAudioContext)()
        audioContext.value = ctx
    }
    
    if (ctx.state === 'suspended') {
        try {
            await ctx.resume()
        } catch (e) {
            console.warn('[Pero] Failed to resume AudioContext:', e)
        }
    }
    
    try {
        const binaryString = window.atob(base64Audio)
        const len = binaryString.length
        const bytes = new Uint8Array(len)
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i)
        }
        
        const audioBuffer = await ctx.decodeAudioData(bytes.buffer)
        
        const source = ctx.createBufferSource()
        source.buffer = audioBuffer
        currentAudioSource.value = source
        
        // Create Analyser for Lip Sync
        // ÂàõÂª∫ÂàÜÊûêÂô®Áî®‰∫éÂè£ÂûãÂêåÊ≠•
        const analyserNode = ctx.createAnalyser()
        analyserNode.fftSize = 256
        analyser.value = analyserNode
        
        source.connect(analyserNode)
        analyserNode.connect(ctx.destination)
        
        source.start(0)
        startLipSync(analyserNode)
        
        source.onended = () => {
            currentAudioSource.value = null
            stopLipSync()
            source.disconnect()
            analyserNode.disconnect()
            processAudioQueue()
        }
        
    } catch (e) {
        console.error('[Pero] Audio decode error:', e)
        processAudioQueue()
    }
}

// --- Global Key Handlers ---

const handleGlobalKeyDown = (e) => {
  if (isWorkMode.value) return

  // 1. Alt + V ÂàáÊç¢ËØ≠Èü≥Ê®°Âºè
  if (e.altKey && !e.shiftKey && e.code === 'KeyV') {
    e.preventDefault()
    cycleVoiceMode()
    return
  }

  // 2. Alt + Shift + V PTT
  if (e.altKey && e.shiftKey && e.code === 'KeyV' && voiceMode.value === 2 && !isPTTRecording.value) {
    e.preventDefault()
    startPTT()
  }
}

const handleGlobalKeyUp = (e) => {
  if (isWorkMode.value) return

  if (e.code === 'KeyV' && voiceMode.value === 2 && isPTTRecording.value) {
    stopPTT()
  }
}

// --- Agent Logic ---
const fetchActiveAgent = async () => {
    try {
        const res = await fetch(`${API_BASE}/agents`);
        if (res.ok) {
            const agents = await res.json();
            const active = agents.find(a => a.is_active);
            if (active) {
                currentAgentName.value = active.name;
                // TODO: Trigger model reload if needed
            }
        }
    } catch (e) { console.error('Failed to fetch active agent:', e); }
};

// --- Lifecycle & IPC ---
let unlistenFunctions = [];

const setIgnoreMouse = (ignore) => {
  if (window._lastIgnoreState === ignore) return;
  window._lastIgnoreState = ignore;
  invoke('set_ignore_mouse', ignore).catch(e => console.error("set_ignore_mouse failed", e));
}

const onHoverStart = () => {
  setIgnoreMouse(false);
}

const onHoverEnd = () => {
  if (!isDragging.value) {
    setIgnoreMouse(true);
  }
}

const onUIEnter = () => {
    setIgnoreMouse(false);
}

const onUILeave = () => {
    // Only set to true if not hovering character and not dragging
    if (!isDragging.value) {
        setIgnoreMouse(true);
    }
}

// Dragging State
let startX = 0;
let startY = 0;
const isDragging = ref(false);

const onMouseDown = (e) => {
    // Only start drag logic if left click
    if (e.button !== 0) return;
    
    startX = e.screenX;
    startY = e.screenY;
    
    const onMouseMove = (moveEvent) => {
        const movedX = Math.abs(moveEvent.screenX - startX);
        const movedY = Math.abs(moveEvent.screenY - startY);
        
        if (!isDragging.value && (movedX > 5 || movedY > 5)) {
            isDragging.value = true;
            // Tell main process to start dragging
            const offsetX = e.screenX - window.screenX;
            const offsetY = e.screenY - window.screenY;
            
            if (window.electron && window.electron.send) {
                window.electron.send('window-drag-start', { offsetX, offsetY });
            } else {
                invoke('window-drag-start', { offsetX, offsetY }).catch(() => {});
            }
        }
    }
    
    const onMouseUp = () => {
        window.removeEventListener('mousemove', onMouseMove);
        window.removeEventListener('mouseup', onMouseUp);
        
        if (isDragging.value) {
            isDragging.value = false;
            
            if (window.electron && window.electron.send) {
                window.electron.send('window-drag-end');
            } else {
                invoke('window-drag-end').catch(() => {});
            }

            // Reset transparency check
            setIgnoreMouse(false); // Keep false for a moment to prevent flicker? Or re-evaluate.
            // Actually if we are over the character, it should stay false.
            // If we dragged off, it might need to go true.
            // But BedrockAvatar will emit hover-end if we move off.
        }
    }
    
    window.addEventListener('mousemove', onMouseMove);
    window.addEventListener('mouseup', onMouseUp);
}

// Attach drag listener to container (captures events from BedrockAvatar too)
// BedrockAvatar uses Three.js, so we might need to handle mousedown there.
// But we can listen on the window or container 'mousedown.capture'

onMounted(async () => {
  fetchActiveAgent();
  loadLocalTexts();
  
  // 1. Initial Mouse Transparency
  await invoke('set_ignore_mouse', true);

  // Attach Drag Listener
  window.addEventListener('mousedown', onMouseDown);
  
  // ... rest of listeners ...
  // Backend Log -> Thinking Bubble
  const unlistenLog = await listen('backend-log', (event) => {
    console.log('[Backend]', event.payload);
    // Simple logic: if log contains "Thinking", show it
    if (typeof event.payload === 'string' && event.payload.includes('Thinking')) {
        currentText.value = "Ê≠£Âú®ÊÄùËÄÉ...";
        isThinking.value = true;
    }
  });
  unlistenFunctions.push(unlistenLog);

  // Status Updates
  const unlistenMood = await listen('update-mood', (event) => {
    moodText.value = event.payload;
    localStorage.setItem('ppc.mood', event.payload);
  });
  unlistenFunctions.push(unlistenMood);

  const unlistenVibe = await listen('update-vibe', (event) => {
    vibeText.value = event.payload;
    localStorage.setItem('ppc.vibe', event.payload);
  });
  unlistenFunctions.push(unlistenVibe);

  const unlistenMind = await listen('update-mind', (event) => {
    mindText.value = event.payload;
    localStorage.setItem('ppc.mind', event.payload);
  });
  unlistenFunctions.push(unlistenMind);

  // Work Mode
  const unlistenWorkMode = await listen('work-mode-changed', (event) => {
      isWorkMode.value = event.payload.is_work_mode;
      if (isWorkMode.value) {
          currentText.value = 'ËøõÂÖ•Â∑•‰ΩúÊ®°Âºè (Session Isolated)';
      } else {
          currentText.value = 'Â∑•‰ΩúËæõËã¶Âï¶ÔºÅ';
      }
  });
  unlistenFunctions.push(unlistenWorkMode);
  
  // Chat Sync (Agent Reply)
  const unlistenChat = await listen('sync-chat-to-pet', (event) => {
      if (isWorkMode.value) return;
      const { role, content } = event.payload;
      if (role === 'assistant') {
          currentText.value = content;
          isThinking.value = false;
          // Trigger bubble expand
          isBubbleExpanded.value = true;
          bubbleKey.value++;
      }
  });
  unlistenFunctions.push(unlistenChat);

  // File Search
  const unlistenSearch = await listen('file-search-result', (event) => {
    foundFiles.value = event.payload;
    showFileModal.value = true;
  });
  unlistenFunctions.push(unlistenSearch);

// Global Mouse Tracking (Fix for character not following mouse when outside window)
if (window.electron && window.electron.on) {
    const cleanupMouse = window.electron.on('global-mouse-move', (_event, { x, y }) => {
        const winW = window.innerWidth;
        const winH = window.innerHeight;
        
        // 1. Direct update to avatar (More reliable than event dispatch)
        if (avatarRef.value && avatarRef.value.setGlobalMouse) {
            avatarRef.value.setGlobalMouse(x, y);
        }

    // 2. Dispatch event for other listeners (fallback)
    // Only dispatch if outside window bounds to avoid double events
    if (x < 0 || x > winW || y < 0 || y > winH) {
        const mouseEvent = new MouseEvent('mousemove', {
            clientX: x,
            clientY: y,
            bubbles: true,
            cancelable: true,
            view: window
        });
        window.dispatchEvent(mouseEvent);
    }
            });
            unlistenFunctions.push(cleanupMouse);
        } else {
            console.warn('window.electron not found, global mouse tracking disabled');
        }
});

onUnmounted(() => {
  if (bubbleTimer) {
    clearTimeout(bubbleTimer);
    bubbleTimer = null;
  }
  unlistenFunctions.forEach(fn => fn());
  unlistenFunctions = [];
  window.removeEventListener('mousedown', onMouseDown);
});

const toggleUI = () => {
  showInput.value = !showInput.value;
  if (!showInput.value) {
    showAppearanceMenu.value = false;
  }
};

const toggleAppearanceMenu = () => {
  showAppearanceMenu.value = !showAppearanceMenu.value;
}

const loadLocalTexts = async () => {
  try {
    const response = await fetch('live2d-widget/waifu-texts.json');
    const baseTexts = await response.json();
    const storageKey = `ppc.waifu.texts.${currentAgentName.value || 'default'}`; 
    let dynamicTexts = {};
    try {
      const saved = localStorage.getItem(storageKey);
      if (saved) dynamicTexts = JSON.parse(saved);
    } catch (e) {
      console.warn('Failed to parse dynamic texts from localStorage:', e);
    }
    localTexts.value = { ...baseTexts, ...dynamicTexts };
    console.log('Local texts loaded:', Object.keys(localTexts.value).length);
  } catch (err) {
    console.error('Failed to load local texts:', err);
    // Fallback
    localTexts.value = {
        "click_head_01": "ÂòøÂòøÔºåÂ•ΩÁóíÂëÄ~",
        "click_head_02": "ÊòØÂú®Êë∏Êë∏Â§¥ÂêóÔºü",
        "click_body_01": "‰∏çË¶ÅÊà≥ÈÇ£ÈáåÂï¶ÔºÅ",
        "click_messages_01": "Ë¶ÅÁâµÊâãÊâãÂêóÔºü"
    };
  }
}

const getRandomLocalText = (category) => {
    if (!localTexts.value) return null;
    
    // Find keys starting with category (e.g. 'click_head')
    const keys = Object.keys(localTexts.value).filter(k => k.startsWith(category));
    if (keys.length === 0) return null;
    
    const randomKey = keys[Math.floor(Math.random() * keys.length)];
    return localTexts.value[randomKey];
}

const onPet = (event) => {
  // console.log('Pet detected:', event);
  
  let text = null;
  
  switch(event.type) {
    case 'head':
      text = getRandomLocalText('click_head');
      if (!text) text = "ÂòøÂòøÔºåÂ•ΩÁóíÂëÄ~";
      break;
    case 'arm':
      text = getRandomLocalText('click_messages'); // Generic interaction
      if (!text) text = "Ë¶ÅÁâµÊâãÊâãÂêóÔºü";
      break;
    case 'body':
      // Try chest first, then body
      text = getRandomLocalText('click_chest') || getRandomLocalText('click_body');
      if (!text) text = "‰∏çË¶ÅÊà≥ÈÇ£ÈáåÂï¶ÔºÅ";
      break;
    case 'leg':
      text = getRandomLocalText('click_body') || getRandomLocalText('click_messages');
      if (!text) text = "Ë£ôÂ≠ê‰∏çËÉΩÊéÄÔºÅ";
      break;
    default:
      text = getRandomLocalText('click_messages');
  }

  // console.log('Selected text:', text);

  // Fallback
  if (!text) {
      text = "ÂóØÔºü";
  }

  // Force re-render for immediate visual feedback even if text is same
  currentText.value = text;
  isBubbleExpanded.value = true;
  bubbleKey.value++; 
  
  // Random vertical offset (12% to 18%)
  const randomTop = 12 + Math.random() * 6;
  bubbleTop.value = `${randomTop}%`;

  // Random horizontal offset (-10% to 10%)
  // Since we use translate(-50%, 0), adding margin-left or just changing left is easiest.
  // Let's use calc for left: 50% + offset
  const randomLeftOffset = (Math.random() * 40 - 20); // -20px to 20px approx equivalent in %
  // Actually let's use pixels for horizontal shift to be safe with narrow bubbles
  // Or just percentage: -5% to 5%
  const randomLeftPct = (Math.random() * 10 - 5);
  // We can bind 'left' style
  // Default is left: 50%, transform: translateX(-50%)
  // We can adjust the left percentage directly
  bubbleLeft.value = `${50 + randomLeftPct}%`;
};

const sendMessage = async () => {
    if (!userInput.value.trim()) return;
    if (isThinking.value) return;
    
    const text = userInput.value;
    userInput.value = '';
    isThinking.value = true;
    currentText.value = "ÊÄùËÄÉ‰∏≠...";
    
    try {
        await invoke('chat-message', { message: text });
    } catch (e) {
        console.error('Send message failed:', e);
        isThinking.value = false;
        currentText.value = "ÂèëÈÄÅÂ§±Ë¥•...";
    }
}

const reloadPet = () => {
    window.location.reload();
}


const openChatWindow = () => {
    invoke('open_ide_window').catch(console.error);
}

const openDashboard = () => {
    invoke('open_dashboard').catch(console.error);
}
</script>

<style scoped>
/* Ensure the container takes full window space and supports transparency */
.pet-3d-container {
  width: 100vw;
  height: 100vh;
  margin: 0;
  padding: 0;
  background: transparent; /* Crucial for Electron transparent window */
  overflow: hidden;
  position: relative;
  display: flex;
  justify-content: center;
  align-items: center;
  /* Use a pixel font if available, or a clean sans-serif */
  font-family: 'Segoe UI', sans-serif; 
}

.ui-overlay {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none; /* Let clicks pass through to 3D scene/desktop */
  display: flex;
  justify-content: center;
  align-items: center;
}

/* Minecraft/RPG Style Bubble */
.bubble {
  position: absolute;
  transform: translateX(-50%);
  
  /* Voxel Style */
  /* Voxel È£éÊ†º */
  background-color: rgba(20, 20, 20, 0.85);
  border: 2px solid #e0e0e0;
  border-radius: 4px;
  padding: 12px 16px;
  z-index: 100;
  max-width: 280px;
  
  /* Hard shadow */
  /* Á°¨Èò¥ÂΩ± */
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5); 
  
  pointer-events: auto;
  animation: bubble-float 3s infinite ease-in-out;
  display: flex;
  flex-direction: column;
  transition: all 0.2s steps(4);
  
  color: #ffffff;
  font-family: 'Consolas', 'Monaco', monospace;
  font-size: 14px;
  line-height: 1.5;
  text-shadow: 1px 1px 0 #000;
}

.bubble:hover {
  transform: scale(1.02);
  background-color: rgba(30, 30, 30, 0.95);
  border-color: #ffffff;
  z-index: 110;
}

/* Pixel Tail */
/* ÂÉèÁ¥†È£éÊ†ºÂ∞æÂ∑¥ */
.bubble-tail {
  position: absolute;
  bottom: -6px;
  left: 50%;
  transform: translateX(-50%);
  width: 0;
  height: 0;
  border-left: 6px solid transparent;
  border-right: 6px solid transparent;
  border-top: 6px solid #e0e0e0;
}

.bubble-tail::after {
  content: '';
  position: absolute;
  top: -9px; 
  left: -4px;
  width: 0;
  height: 0;
  border-left: 4px solid transparent;
  border-right: 4px solid transparent;
  border-top: 4px solid rgba(20, 20, 20, 0.85);
}

.bubble-content {
  cursor: pointer;
}

.bubble.expanded {
  max-height: 500px;
  overflow-y: auto;
}

.bubble.expanded::-webkit-scrollbar {
  width: 6px;
}
.bubble.expanded::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.3);
}
.bubble.expanded::-webkit-scrollbar-thumb {
  background: #888;
  border-radius: 0;
  border: 1px solid #444;
}
.bubble.expanded::-webkit-scrollbar-thumb:hover {
  background: #aaa;
}

.bubble-scroll-area {
  max-height: 200px;
  overflow: hidden;
  transition: max-height 0.3s ease;
  position: relative;
}

.bubble.expanded .bubble-scroll-area {
  max-height: 500px;
  overflow-y: auto;
}

.bubble-expand-btn {
  font-size: 12px;
  color: #aaaaaa;
  text-align: center;
  margin-top: 8px;
  cursor: pointer;
  padding-top: 4px;
  border-top: 1px dashed #666;
  user-select: none;
  font-family: 'Consolas', monospace;
}

.bubble-expand-btn:hover {
  color: #ffffff;
  font-weight: bold;
}

.thinking-text {
  color: #aaaaaa;
  font-style: italic;
  display: flex;
  align-items: center;
  font-family: 'Consolas', monospace;
}

.thinking-text::after {
  content: "...";
  display: inline-block;
  width: 12px;
  animation: thinking-dots 1.5s infinite;
}

@keyframes thinking-dots {
  0% { content: "."; }
  33% { content: ".."; }
  66% { content: "..."; }
}

.thinking-block {
  margin: 12px 0;
  background: rgba(0, 0, 0, 0.3);
  border-radius: 4px;
  border: 1px solid #555;
  overflow: hidden;
}

.thinking-label {
  padding: 4px 8px;
  background: rgba(50, 50, 50, 0.5);
  font-size: 11px;
  font-weight: bold;
  color: #ccc;
  border-bottom: 1px solid #555;
  font-family: 'Consolas', monospace;
}

.thinking-content {
  padding: 8px;
  font-family: 'Consolas', monospace;
  font-size: 12px;
  color: #ddd;
  white-space: pre-wrap;
  background: rgba(0, 0, 0, 0.2);
}

.action-text {
  color: #aaddff;
  font-style: italic;
  font-size: 0.95em;
  margin: 0 2px;
}

@keyframes bubble-float {
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-4px); }
}

.bubble-fade-enter-active {
  transition: all 0.15s cubic-bezier(0.175, 0.885, 0.32, 1.275);
}
.bubble-fade-leave-active {
  transition: opacity 0.1s ease-out;
  position: absolute;
}
.bubble-fade-enter-from {
  opacity: 0;
  transform: translateX(-50%) scale(0.8) translateY(10px);
}
.bubble-fade-leave-to {
  opacity: 0;
  transform: translateX(-50%) scale(1.1);
}

/* Status Tags (Voxel) */
/* Áä∂ÊÄÅÊ†áÁ≠æ (Voxel) */
.status-tags {
  position: absolute;
  left: 50%; 
  top: 50%;
  transform: translate(-320px, -250px);
  display: flex;
  flex-direction: column;
  gap: 12px;
  perspective: 1000px;
  align-items: flex-end;
  pointer-events: auto;
}

.status-tag {
  background: rgba(20, 20, 20, 0.85);
  padding: 8px 14px;
  border-radius: 4px;
  font-size: 12px;
  font-weight: bold;
  color: #ffffff;
  border: 2px solid #e0e0e0;
  white-space: nowrap;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  max-width: 160px;
  overflow: hidden;
  text-overflow: ellipsis;
  display: flex;
  align-items: center;
  gap: 8px;
  transition: all 0.2s;
  cursor: default;
  font-family: 'Consolas', monospace;
  text-shadow: 1px 1px 0 #000;
}

.status-tag:hover {
  transform: translateX(-5px);
  background: rgba(40, 40, 40, 0.95);
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  z-index: 110;
  border-color: #ffffff;
}

.status-tag.mood {
  border-color: #ff88aa;
  color: #ffccdd;
}

.status-tag.vibe {
  border-color: #88ccff;
  color: #cceeff;
}

.status-tag.mind {
  border-color: #88ffaa;
  color: #ccffdd;
  white-space: normal;
  max-width: 180px;
  word-break: break-all;
  line-height: 1.4;
  padding: 8px 12px;
  align-items: flex-start;
}

@keyframes float-tag {
  /* Reduced float for voxel style */
  /* ÂáèÂ∞ë Voxel È£éÊ†ºÁöÑÊµÆÂä® */
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-2px); }
}

/* Floating Trigger (Voxel Cube) */
/* ÊÇ¨ÊµÆËß¶ÂèëÂô® (Voxel Á´ãÊñπ‰Ωì) */
.floating-trigger {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(140px, -50%);
  width: 44px;
  height: 44px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  z-index: 100;
  pointer-events: auto;
}

.trigger-core {
  position: relative;
  width: 24px;
  height: 24px;
  transition: all 0.3s ease;
  animation: core-idle 4s infinite ease-in-out;
}

@keyframes core-idle {
  0% { transform: translateY(0) rotate(0deg); }
  25% { transform: translateY(-3px) rotate(15deg); }
  50% { transform: translateY(0) rotate(0deg); }
  75% { transform: translateY(3px) rotate(-15deg); }
  100% { transform: translateY(0) rotate(0deg); }
}

.core-dot {
  position: absolute;
  width: 100%;
  height: 100%;
  background: rgba(255, 255, 255, 0.95);
  border-radius: 4px; /* Slightly more rounded */
  transition: all 0.2s ease;
  box-shadow: 
    0 0 15px rgba(255, 255, 255, 0.6),
    2px 2px 0px rgba(0, 0, 0, 0.3);
  border: 2px solid #fff;
}

.pulse-ring {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 2px solid rgba(255, 255, 255, 0.5);
  border-radius: 4px;
  opacity: 0;
  animation: pulse-ring-smooth 2s infinite cubic-bezier(0.215, 0.61, 0.355, 1);
  box-sizing: border-box;
}

@keyframes pulse-ring-smooth {
  0% { transform: scale(0.8) rotate(0deg); opacity: 0.8; border-width: 2px; }
  50% { opacity: 0.5; }
  100% { transform: scale(2.4) rotate(90deg); opacity: 0; border-width: 0px; }
}

.floating-trigger:hover .trigger-core {
  animation-play-state: paused;
  transform: scale(1.1) rotate(45deg);
}

.floating-trigger:hover .core-dot {
  background: #ffffff;
  transform: scale(1.0);
  box-shadow: 
    0 0 20px rgba(255, 255, 255, 1),
    0 0 40px rgba(255, 255, 255, 0.6);
}

.floating-trigger.active .trigger-core {
  transform: rotate(45deg);
}

.floating-trigger.active .core-dot {
  background: #ff88aa;
  border-color: #ffccdd;
  box-shadow: 0 0 15px rgba(255, 136, 170, 0.6);
}

.floating-trigger.active .pulse-ring {
  border-color: rgba(255, 136, 170, 0.5);
  animation-duration: 1.5s;
}

.fade-enter-active,
.fade-leave-active {
  transition: opacity 0.2s ease;
}

.fade-enter-from,
.fade-leave-to {
  opacity: 0;
}

.input-overlay {
  position: absolute;
  bottom: 80px;
  left: 50%;
  transform: translateX(-50%);
  -webkit-app-region: no-drag;
  perspective: 1000px;
  pointer-events: auto;
}

.chat-input {
  background: rgba(20, 20, 20, 0.85);
  backdrop-filter: blur(4px);
  -webkit-backdrop-filter: blur(4px);
  border: 2px solid #e0e0e0;
  border-radius: 4px;
  padding: 10px 16px;
  width: 240px;
  outline: none;
  font-size: 14px;
  font-weight: 500;
  color: #ffffff;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  transition: all 0.2s;
  font-family: 'Consolas', monospace;
}

.chat-input::placeholder {
  color: #888;
  font-weight: 400;
}

.chat-input:focus {
  width: 280px;
  background: rgba(30, 30, 30, 0.95);
  border-color: #ffffff;
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  transform: translateY(-2px);
  color: #ffffff;
}

.pet-tools {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(200px, -50%);
  display: flex;
  flex-direction: column;
  gap: 12px;
  background: rgba(20, 20, 20, 0.7);
  backdrop-filter: blur(4px);
  -webkit-backdrop-filter: blur(4px);
  padding: 8px;
  border-radius: 6px;
  -webkit-app-region: no-drag;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  border: 2px solid #666;
  pointer-events: auto;
}

.tool-btn {
  background: rgba(40, 40, 40, 0.8);
  border: 2px solid #888;
  width: 38px;
  height: 38px;
  border-radius: 4px;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 18px;
  transition: all 0.15s;
  box-shadow: 2px 2px 0px rgba(0, 0, 0, 0.5);
  color: #ddd;
}

.tool-btn:hover, .tool-btn.active {
  transform: translate(-1px, -1px);
  background: #555;
  border-color: #fff;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.6);
  color: #fff;
}

.tool-btn:active {
  transform: translate(2px, 2px);
  box-shadow: 0px 0px 0px rgba(0, 0, 0, 0.5);
}

.voice-btn.active.mode-vad {
  color: #ff99cc;
  border-color: #ff99cc;
}

.voice-btn.active.mode-ptt {
  color: #5fb878;
  border-color: #5fb878;
}

/* Appearance Menu (Voxel) */
.appearance-menu {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(-320px, -50%);
  background: rgba(20, 20, 20, 0.95);
  border: 2px solid #fff;
  border-radius: 6px;
  padding: 12px;
  width: 200px;
  color: white;
  box-shadow: 6px 6px 0px rgba(0,0,0,0.6);
  pointer-events: auto;
  font-family: 'Consolas', monospace;
  z-index: 101;
}

.menu-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 12px;
  padding-bottom: 8px;
  border-bottom: 2px solid #444;
  font-weight: bold;
}

.close-mini-btn {
  background: none;
  border: none;
  color: #888;
  cursor: pointer;
  font-size: 18px;
  line-height: 1;
}
.close-mini-btn:hover {
  color: #fff;
}

.menu-section {
  margin-bottom: 12px;
}

.menu-label {
  font-size: 11px;
  color: #aaa;
  margin-bottom: 6px;
  text-transform: uppercase;
}

.voxel-checkbox {
  display: flex;
  align-items: center;
  gap: 8px;
  margin-bottom: 6px;
  cursor: pointer;
  font-size: 13px;
  user-select: none;
}

.voxel-checkbox input {
  display: none;
}

.voxel-checkbox .checkmark {
  width: 16px;
  height: 16px;
  background: #333;
  border: 2px solid #888;
  position: relative;
  display: inline-block;
  transition: all 0.1s;
}

.voxel-checkbox:hover .checkmark {
  border-color: #fff;
}

.voxel-checkbox input:checked + .checkmark {
  background: #ff88aa;
  border-color: #fff;
}

.voxel-checkbox input:checked + .checkmark::after {
  content: '';
  position: absolute;
  left: 4px;
  top: 1px;
  width: 4px;
  height: 8px;
  border: solid white;
  border-width: 0 2px 2px 0;
  transform: rotate(45deg);
}

.voxel-select {
  width: 100%;
  padding: 6px;
  background: #333;
  border: 2px solid #888;
  color: white;
  font-family: inherit;
  cursor: pointer;
  outline: none;
}
.voxel-select:hover {
  border-color: #fff;
}

/* PTT Button (Voxel) */
.ptt-voxel-container {
  position: absolute;
  left: 50%;
  bottom: 70px;
  top: auto;
  transform: translateX(-220px);
  z-index: 100;
  pointer-events: auto;
}

.ptt-voxel-btn {
  background: rgba(40, 40, 40, 0.9);
  border: 2px solid #888;
  border-radius: 50%;
  width: 64px;
  height: 64px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  transition: all 0.1s;
  color: #ddd;
}

.ptt-voxel-btn:hover {
  transform: translate(-1px, -1px);
  background: #555;
  border-color: #fff;
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  color: #fff;
}

.ptt-voxel-btn:active {
  transform: translate(2px, 2px);
  box-shadow: 0px 0px 0px rgba(0, 0, 0, 0.5);
}

.ptt-voxel-btn.recording {
  background: #ff4444;
  border-color: #ffcccc;
  color: white;
  animation: pulse-recording 1.5s infinite;
}

.ptt-icon {
  font-size: 24px;
  line-height: 1;
}

.ptt-text {
  font-size: 9px;
  margin-top: 4px;
  font-weight: bold;
  font-family: 'Consolas', monospace;
  letter-spacing: 1px;
}

@keyframes pulse-recording {
  0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 68, 68, 0.7); }
  70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(255, 68, 68, 0); }
  100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 68, 68, 0); }
}
</style>