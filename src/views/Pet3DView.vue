<template>
  <div class="pet-3d-container">
    <!-- 3D Avatar Component -->
    <!-- 3D è§’è‰²ç»„ä»¶ -->
    <BedrockAvatar 
      ref="avatarRef" 
      @pet="onPet"
      @hover-start="onHoverStart"
      @hover-end="onHoverEnd"
    />
    
    <!-- UI Overlay -->
    <!-- UI è¦†ç›–å±‚ -->
    <div class="ui-overlay" @mouseenter="onUIEnter" @mouseleave="onUILeave">
       <!-- Status Tags (Top Left) -->
       <!-- çŠ¶æ€æ ‡ç­¾ (å·¦ä¸Šè§’) -->
       <transition name="fade">
         <div class="status-tags" v-show="showInput">
            <div class="status-tag mood" :title="'æƒ…ç»ª: ' + moodText">â¤ï¸ {{ moodText }}</div>
            <div class="status-tag vibe" :title="'æ°›å›´: ' + vibeText">âœ¨ {{ vibeText }}</div>
            <div class="status-tag mind" :title="'å†…å¿ƒ: ' + mindText">ğŸ’­ {{ mindText }}</div>
         </div>
       </transition>

      <!-- Floating Trigger (Light Orb) -->
      <!-- æ‚¬æµ®è§¦å‘å™¨ (å…‰çƒ) -->
      <div 
        class="floating-trigger" 
        :class="{ active: showInput }"
        @click.stop="toggleUI"
        style="-webkit-app-region: no-drag;"
        @mouseenter="onUIEnter"
        @mouseleave="onUILeave"
      >
        <div class="trigger-core">
          <div class="pulse-ring"></div>
          <div class="core-dot"></div>
        </div>
      </div>

      <!-- Input Overlay -->
      <!-- è¾“å…¥è¦†ç›–å±‚ -->
      <div class="input-overlay" v-show="showInput" @mouseenter="onUIEnter">
        <input 
          ref="inputRef"
          v-model="userInput" 
          @keyup.enter="sendMessage"
          :placeholder="isWorkMode ? 'å·¥ä½œæ¨¡å¼ä¸‹å·²ç¦ç”¨è¾“å…¥' : `è·Ÿ ${currentAgentName} å¯¹è¯...`"
          class="chat-input"
          :disabled="isThinking || isWorkMode"
          style="-webkit-app-region: no-drag;"
        />
      </div>

      <!-- Avatar Tools -->
      <!-- è§’è‰²å·¥å…· -->
      <div class="pet-tools" v-show="showInput" style="-webkit-app-region: no-drag;" @mouseenter="onUIEnter">
        <button class="tool-btn" @click.stop="toggleAppearanceMenu" title="å¤–è§‚è®¾ç½®" :class="{ active: showAppearanceMenu }">ğŸ¨</button>
        <button class="tool-btn" @click.stop="reloadPet" title="é‡è½½">ğŸ”„</button>
        <button class="tool-btn" @click.stop="toggleWindowSize" title="è°ƒæ•´å¤§å°">ğŸ“</button>
        <button 
          class="tool-btn voice-btn" 
          @click.stop="cycleVoiceMode" 
          :class="{ 
            active: voiceMode !== 0,
            'mode-vad': voiceMode === 1,
            'mode-ptt': voiceMode === 2 
          }" 
          :title="voiceModeTitle"
        >
          {{ voiceModeIcon }}
        </button>
        <button class="tool-btn" @click.stop="openChatWindow" title="èŠå¤©">ğŸ’¬</button>
        <button class="tool-btn" @click.stop="openDashboard" title="é¢æ¿">âš™ï¸</button>
      </div>

      <!-- PTT Floating Button (Voxel Style) -->
      <!-- PTT æ‚¬æµ®æŒ‰é’® (ä½“ç´ é£æ ¼) -->
      <transition name="fade">
        <div 
          v-if="voiceMode === 2" 
          class="ptt-voxel-container"
          @mousedown.stop="startPTT"
          @mouseup.stop="stopPTT"
          @mouseleave.stop="stopPTT"
          style="-webkit-app-region: no-drag;"
        >
          <div class="ptt-voxel-btn" :class="{ recording: isPTTRecording }" title="æŒ‰ä½ Alt+Shift+V è¯´è¯">
            <span class="ptt-icon">ğŸ™ï¸</span>
            <span class="ptt-text" v-if="isPTTRecording">LISTENING...</span>
          </div>
        </div>
      </transition>

      <!-- Appearance Menu (Voxel Style) -->
      <!-- å¤–è§‚èœå• (ä½“ç´ é£æ ¼) -->
      <transition name="fade">
        <div class="appearance-menu" v-if="showAppearanceMenu && showInput" @mouseenter="onUIEnter">
          <div class="menu-header">
            <span>å¤–è§‚æ§åˆ¶</span>
            <button class="close-mini-btn" @click="showAppearanceMenu = false">Ã—</button>
          </div>
          
          <div class="menu-section" v-if="avatarRef && avatarRef.clothingState">
            <div class="menu-label">æœè£…éƒ¨ä»¶</div>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.dress" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Dress
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.armour" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Armour
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.hat" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Hat
            </label>
            <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.underwear" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Underwear
            </label>
             <label class="voxel-checkbox">
              <input type="checkbox" v-model="avatarRef.clothingState.censored" @change="avatarRef.updateClothing()">
              <span class="checkmark"></span>
              Censored
            </label>
          </div>

          <div class="menu-section" v-if="avatarRef && avatarRef.animList && avatarRef.animList.length > 0">
            <div class="menu-label">åŠ¨ä½œè°ƒè¯•</div>
            <select class="voxel-select" @change="(e) => avatarRef.setAnimation(e.target.value)">
              <option value="">-- é€‰æ‹©åŠ¨ä½œ --</option>
              <option v-for="anim in avatarRef.animList" :key="anim" :value="anim">{{ anim }}</option>
            </select>
          </div>
        </div>
      </transition>

       <!-- ç§»é™¤äº† mode="out-in" ä»¥å…è®¸å¿«é€Ÿç‚¹å‡»æ—¶ç«‹å³æ›¿æ¢ -->
       <transition name="bubble-fade">
        <div 
          v-if="currentText || isThinking" 
          :key="bubbleKey"
          class="bubble" 
          :class="{ expanded: isBubbleExpanded }"
          :style="{ top: bubbleTop, left: bubbleLeft }"
        >
          <div class="bubble-content" :class="{ 'cursor-pointer': isThinking }" @mousedown.stop>
             <template v-if="isThinking">
               <span class="thinking-text">{{ thinkingMessage }}</span>
             </template>
             <template v-else>
               <div class="bubble-scroll-area" ref="bubbleScrollArea">
                 <div v-for="(segment, index) in parsedBubbleContent" :key="index" class="bubble-segment">
                   <span v-if="segment.type === 'text'">{{ segment.content }}</span>
                   <span v-else-if="segment.type === 'action'" class="action-text">*{{ segment.content }}*</span>
                   <div v-else-if="segment.type === 'thinking'" class="thinking-block">
                     <div class="thinking-label">ğŸ’­ æ€è€ƒè¿‡ç¨‹</div>
                     <div class="thinking-content">{{ segment.content }}</div>
                   </div>
                 </div>
               </div>
               <div v-if="isContentOverflowing" class="bubble-expand-btn" @click.stop="toggleBubbleExpand" @mousedown.stop>
                 {{ isBubbleExpanded ? 'æ”¶èµ·' : 'å±•å¼€' }}
               </div>
             </template>
          </div>
          <div class="bubble-tail"></div>
        </div>
      </transition>
    </div>

    <!-- æ–‡ä»¶æœç´¢æ¨¡æ€æ¡† -->
    <FileSearchModal v-model:visible="showFileModal" :files="foundFiles" />
  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, computed, watch, nextTick } from 'vue';
import BedrockAvatar from '../components/avatar/BedrockAvatar.vue';
import FileSearchModal from '../components/FileSearchModal.vue';
import { invoke, listen } from '@/utils/ipcAdapter';
import { API_BASE } from '../config';
import { gatewayClient } from '../api/gateway';

const currentText = ref('ä¸»äººï¼Œæˆ‘åœ¨æ¡Œé¢ç­‰ä½ å¾ˆä¹…å•¦ï¼');
const isBubbleExpanded = ref(false);
const bubbleKey = ref(0);
const bubbleTop = ref('15%');
const bubbleLeft = ref('50%');
const avatarRef = ref(null);
let bubbleTimer = null;

// Debug refs
const debugGlobalX = ref(0);
const debugGlobalY = ref(0);
const showDebug = ref(false);

const isContentOverflowing = ref(false);
const bubbleScrollArea = ref(null);
const thinkingMessage = ref('åŠªåŠ›æ€è€ƒä¸­...');

// --- çŠ¶æ€ç®¡ç† (ç¬¬ä¸€é˜¶æ®µ) ---
const currentAgentName = ref('Pero');
const moodText = ref(localStorage.getItem('ppc.mood') || 'å¼€å¿ƒ');
const vibeText = ref(localStorage.getItem('ppc.vibe') || 'è½»æ¾');
const mindText = ref(localStorage.getItem('ppc.mind') || 'å‘å‘†');
const isWorkMode = ref(false);
const voiceMode = ref(parseInt(localStorage.getItem('ppc.voice_mode') || '0'));
const isThinking = ref(false);
const isPTTRecording = ref(false); // PTT State
const isSpeaking = ref(false); // TTS State
// const voiceWs = ref(null); // Deprecated
const audioContext = ref(null);
const mediaStream = ref(null);
const scriptProcessor = ref(null);
const currentAudioSource = ref(null);
const audioQueue = ref([]);
const isAudioPlaying = ref(false);
const lipSyncFrame = ref(null);
const analyser = ref(null);
let isStartingPTT = false;
let isSpeakingState = false;
let audioBuffer = [];
let lastRmsUpdate = 0;
const VAD_THRESHOLD = 0.01;
let silenceStart = Date.now();

const showInput = ref(false);
const userInput = ref('');
const inputRef = ref(null);
const showFileModal = ref(false);
const foundFiles = ref([]);
const showAppearanceMenu = ref(false);
const localTexts = ref({});

const parsedBubbleContent = computed(() => {
  const text = currentText.value || '';
  if (!text) return [];

  const segments = [];
  const regex = /(?:ã€(Thinking|Error|Reflection|Monologue)[:ï¼š]?\s*([\s\S]*?)ã€‘)|(?:\n|^)\s*\*([\s\S]+?)\*|(?:\n|^)\s*(Thought|Action)[:ï¼š]\s*([\s\S]+?)(?=\n\s*(?:Thought|Action)[:ï¼š]|\n\s*\*|ã€(?:Thinking|Error|Reflection|Monologue)|$)|(?:<(nit(?:-[a-zA-Z0-9-]+)?)>[\s\S]*?<\/\1>)|(?:\[\[\[NIT_CALL\]\]\][\s\S]*?\[\[\[NIT_END\]\]\])/gi;
  
  let lastIndex = 0;
  let match;

  while ((match = regex.exec(text)) !== null) {
    if (match.index > lastIndex) {
      const normalText = text.substring(lastIndex, match.index);
      if (normalText.trim()) {
        segments.push({ type: 'text', content: normalText });
      }
    }
    
    if (match[1] !== undefined) {
      const type = match[1].toLowerCase();
      segments.push({ type: type === 'thinking' ? 'thinking' : type, content: match[2].trim() });
    } else if (match[3] !== undefined) {
      segments.push({ type: 'action', content: match[3].trim() });
    } else if (match[4] !== undefined) {
      const type = match[4].toLowerCase() === 'thought' ? 'thinking' : 'action';
      segments.push({ type, content: match[5].trim() });
    }
    
    lastIndex = regex.lastIndex;
  }
  
  if (lastIndex < text.length) {
    const normalText = text.substring(lastIndex);
    if (normalText.trim()) {
      segments.push({ type: 'text', content: normalText });
    }
  }
  
  return segments.filter(s => s.type === 'text' || s.type === 'action');
});

const checkOverflow = () => {
  if (bubbleScrollArea.value) {
    const el = bubbleScrollArea.value;
    isContentOverflowing.value = el.scrollHeight > 210;
    
    if (!isContentOverflowing.value) {
      isBubbleExpanded.value = false;
    }
  }
};

watch(parsedBubbleContent, async () => {
  await nextTick();
  checkOverflow();
}, { deep: true });

// æ°”æ³¡è‡ªåŠ¨æ¶ˆå¤±é€»è¾‘
watch([currentText, isThinking], ([newText, newThinking]) => {
  if (bubbleTimer) {
    clearTimeout(bubbleTimer);
    bubbleTimer = null;
  }

  // åªæœ‰åœ¨éæ€è€ƒçŠ¶æ€ä¸”æœ‰æ–‡å­—æ—¶ï¼Œæ‰å¯åŠ¨è‡ªåŠ¨æ¶ˆå¤±å®šæ—¶å™¨
  if (newText && !newThinking) {
    // æ ¹æ®æ–‡å­—é•¿åº¦è°ƒæ•´åœç•™æ—¶é—´ï¼Œæœ€å°‘ 5 ç§’ï¼Œæœ€å¤š 15 ç§’
    const duration = Math.min(Math.max(5000, newText.length * 200), 15000);
    bubbleTimer = setTimeout(() => {
      currentText.value = '';
      isBubbleExpanded.value = false;
      bubbleTimer = null;
    }, duration);
  }
});

const toggleBubbleExpand = () => {
  isBubbleExpanded.value = !isBubbleExpanded.value;
  nextTick(() => {
     checkOverflow();
  });
};

const voiceModeIcon = computed(() => {
  if (voiceMode.value === 0) return 'ğŸ”‡'
  if (voiceMode.value === 1) return 'ğŸ™ï¸'
  return 'ğŸ–±ï¸'
})

const voiceModeTitle = computed(() => {
  if (voiceMode.value === 0) return 'è¯­éŸ³å¯¹è¯: å·²å…³é—­'
  if (voiceMode.value === 1) return 'è¯­éŸ³å¯¹è¯: è‡ªåŠ¨æ„Ÿåº” (VAD)'
  return 'è¯­éŸ³å¯¹è¯: æŒ‰ä½è¯´è¯ (PTT)'
})

// --- è¯­éŸ³å’Œ PTT é€»è¾‘ ---

const cycleVoiceMode = async () => {
  if (isWorkMode.value) {
    currentText.value = '(å·¥ä½œæ¨¡å¼ä¸‹å·²ç¦ç”¨è¯­éŸ³åŠŸèƒ½)'
    return
  }
  
  const nextMode = (voiceMode.value + 1) % 3
  voiceMode.value = nextMode
  localStorage.setItem('ppc.voice_mode', nextMode.toString())
  
  // Show mode change in bubble
  if (nextMode === 0) {
      currentText.value = 'è¯­éŸ³å¯¹è¯: å·²å…³é—­'
      stopVoiceMode()
  } else if (nextMode === 1) {
      currentText.value = 'åˆ‡æ¢åˆ°: è‡ªåŠ¨æ„Ÿåº” (VAD)'
  } else {
      currentText.value = 'åˆ‡æ¢åˆ°: æŒ‰ä½è¯´è¯ (PTT)'
  }
  isBubbleExpanded.value = true;
  bubbleKey.value++;
  
  if (nextMode !== 0) {
    // å¦‚æœè¿˜æ²¡å¼€å¯éº¦å…‹é£ï¼Œåˆ™å¼€å¯
    // if (!voiceWs.value) { // WS check removed
      await startVoiceMode()
    // }
  }
}

const startVoiceMode = async () => {
    console.log('[è¯­éŸ³] æ­£åœ¨å¯åŠ¨è¯­éŸ³æ¨¡å¼...');
    try {
        // 0. ç¡®ä¿ AudioContext å­˜åœ¨å¹¶æ¿€æ´»
        if (!audioContext.value || audioContext.value.state === 'closed') {
            audioContext.value = new (window.AudioContext || window.webkitAudioContext)()
        }
        if (audioContext.value.state === 'suspended') {
            await audioContext.value.resume()
        }

        // 1. è·å–éº¦å…‹é£æƒé™
        mediaStream.value = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // æ£€æŸ¥éŸ³é¢‘è½¨é“
        const audioTracks = mediaStream.value.getAudioTracks();
        if (audioTracks.length === 0) {
            throw new Error('åª’ä½“æµä¸­æœªæ‰¾åˆ°éŸ³é¢‘è½¨é“');
        }
        console.log('[è¯­éŸ³] å·²è·å¾—éº¦å…‹é£æƒé™:', audioTracks[0].label);
        
        // 2. Gateway è¿æ¥ (å‡è®¾å·²ç»è¿æ¥ï¼Œåªéœ€æ³¨å†Œç›‘å¬å™¨)
        // ç›‘å¬æ¥è‡ª Backend çš„ Voice Update Request
        gatewayClient.on('action:voice_update', handleVoiceUpdateRequest);
        
        // ç›‘å¬æ¥è‡ª Backend çš„ Audio Stream (TTS)
        gatewayClient.on('stream', handleAudioStream);
        
        console.log('è¯­éŸ³ç½‘å…³ç›‘å¬å™¨å·²æ³¨å†Œ');
        // åœ¨æ°”æ³¡ä¸­æ˜¾ç¤ºè¿æ¥æˆåŠŸ
        currentText.value = `è¯­éŸ³è¿æ¥æˆåŠŸ: ${voiceModeTitle.value}`;
        isBubbleExpanded.value = true;
        bubbleKey.value++;
        
        // 3. å¼€å§‹å½•éŸ³å¤„ç†
        startRecording();
        
    } catch (err) {
        console.error('å¯åŠ¨è¯­éŸ³æ¨¡å¼å¤±è´¥:', err);
    }
};

const stopVoiceMode = () => {
    // Remove listeners
    gatewayClient.off('action:voice_update', handleVoiceUpdateRequest);
    gatewayClient.off('stream', handleAudioStream);
    
    if (mediaStream.value) {
        mediaStream.value.getTracks().forEach(track => track.stop())
        mediaStream.value = null
    }
    
    if (audioContext.value) {
        audioContext.value.close()
        audioContext.value = null
    }
}

const startRecording = () => {
    audioContext.value = new (window.AudioContext || window.webkitAudioContext)()
    const source = audioContext.value.createMediaStreamSource(mediaStream.value)
    
    // ä½¿ç”¨ ScriptProcessorNode å¤„ç†éŸ³é¢‘æµ (å·²åºŸå¼ƒä½†å¹¿æ³›æ”¯æŒ)
    scriptProcessor.value = audioContext.value.createScriptProcessor(4096, 1, 1)
    
    source.connect(scriptProcessor.value)
    scriptProcessor.value.connect(audioContext.value.destination)
    
    scriptProcessor.value.onaudioprocess = (e) => {
        if (voiceMode.value === 0) return

        // å¦‚æœæ­£åœ¨æ€è€ƒæˆ–æ­£åœ¨è¯´è¯ï¼Œç›´æ¥å¿½ç•¥æ–°çš„è¯­éŸ³è¾“å…¥
        if (isThinking.value || isSpeaking.value) {
             return
        }
        
        const inputData = e.inputBuffer.getChannelData(0)
        
        // --- æ¨¡å¼ 2: æŒ‰ä½è¯´è¯ (PTT) ---
        if (voiceMode.value === 2) {
            if (isPTTRecording.value) {
                audioBuffer.push(new Float32Array(inputData))
            }
            return
        }

        // --- æ¨¡å¼ 1: è‡ªåŠ¨æ„Ÿåº” (VAD) ---
        // 1. è®¡ç®—éŸ³é‡ (RMS)
        let sum = 0
        for (let i = 0; i < inputData.length; i++) {
            sum += inputData[i] * inputData[i]
        }
        const rms = Math.sqrt(sum / inputData.length)
        
        // è°ƒè¯•æ—¥å¿—ï¼šæ¯ç§’è¾“å‡ºä¸€æ¬¡å½“å‰éŸ³é‡
        if (Date.now() - lastRmsUpdate > 1000) {
            // console.log('Current Mic Volume (RMS):', rms.toFixed(4), 'Threshold:', VAD_THRESHOLD)
            lastRmsUpdate = Date.now()
        }
        
        // 2. VAD é€»è¾‘
        if (rms > VAD_THRESHOLD) {
            silenceStart = Date.now()
            if (!isSpeakingState) {
                console.log('æ£€æµ‹åˆ°è¯­éŸ³ (éŸ³é‡:', rms.toFixed(4), ')')
                isSpeakingState = true
                audioBuffer = [] // æ¸…ç©º buffer
            }
            // æ”¶é›†éŸ³é¢‘æ•°æ®
            audioBuffer.push(new Float32Array(inputData))
        } else {
            if (isSpeakingState) {
                // å¦‚æœé™éŸ³è¶…è¿‡ 1000msï¼Œè®¤ä¸ºä¸€å¥è¯ç»“æŸ
                if (Date.now() - silenceStart > 1000) {
                    console.log('è¯­éŸ³ç»“æŸï¼Œæ­£åœ¨å‘é€ç¼“å†²åŒº...')
                    isSpeakingState = false
                    sendAudioBuffer()
                } else {
                    // çŸ­æš‚é™éŸ³ï¼Œç»§ç»­æ”¶é›†
                     audioBuffer.push(new Float32Array(inputData))
                }
            }
        }
    }
}

const startPTT = async () => {
    if (voiceMode.value !== 2) return
    if (isPTTRecording.value || isStartingPTT) return
    
    isStartingPTT = true
    try {
      if (isThinking.value || isSpeaking.value) {
        console.log('PTT å·²å¿½ç•¥: Pero æ­£å¿™', { isThinking: isThinking.value, isSpeaking: isSpeaking.value })
        return
      }
      
      // ç¡®ä¿ AudioContext å·²æ¿€æ´»
      if (audioContext.value && audioContext.value.state === 'suspended') {
        await audioContext.value.resume()
      }

      isPTTRecording.value = true
      isSpeakingState = true
      audioBuffer = []
      console.log('PTT å·²å¯åŠ¨')
    } finally {
      isStartingPTT = false
    }
}

const stopPTT = () => {
  if (!isPTTRecording.value) return
  isPTTRecording.value = false
  isSpeakingState = false
  console.log('PTT ç»“æŸï¼Œæ­£åœ¨å‘é€ç¼“å†²åŒº...')
  sendAudioBuffer()
}

const sendAudioBuffer = () => {
    if (audioBuffer.length === 0) return
    
    // 1. åˆå¹¶ buffer
    const length = audioBuffer.length * 4096
    const merged = new Float32Array(length)
    let offset = 0
    for (const chunk of audioBuffer) {
        merged.set(chunk, offset)
        offset += chunk.length
    }
    
    // 2. è½¬æ¢ä¸º WAV
    const wavBlob = encodeWAV(merged, audioContext.value.sampleRate)
    
    // 3. è½¬ Base64 å‘é€
    const reader = new FileReader()
    reader.onloadend = () => {
        const base64data = reader.result.split(',')[1]
        if (voiceWs.value && voiceWs.value.readyState === WebSocket.OPEN) {
            voiceWs.value.send(JSON.stringify({
                type: 'speech_end',
                data: base64data
            }))
        }
    }
    reader.readAsDataURL(wavBlob)
    
    audioBuffer = []
}

const encodeWAV = (samples, sampleRate) => {
    const buffer = new ArrayBuffer(44 + samples.length * 2)
    const view = new DataView(buffer)
    
    const writeString = (view, offset, string) => {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i))
        }
    }
    
    writeString(view, 0, 'RIFF')
    view.setUint32(4, 36 + samples.length * 2, true)
    writeString(view, 8, 'WAVE')
    writeString(view, 12, 'fmt ')
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true)
    view.setUint16(22, 1, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * 2, true)
    view.setUint16(32, 2, true)
    view.setUint16(34, 16, true)
    writeString(view, 36, 'data')
    view.setUint32(40, samples.length * 2, true)
    
    let offset = 44
    for (let i = 0; i < samples.length; i++) {
        let s = Math.max(-1, Math.min(1, samples[i]))
        s = s < 0 ? s * 0x8000 : s * 0x7FFF
        view.setInt16(offset, s, true)
        offset += 2
    }
    
    return new Blob([view], { type: 'audio/wav' })
}

// Handler for Voice Update Requests (Status, Text, etc.)
const handleVoiceUpdateRequest = (req) => {
    const type = req.params.type;
    const content = req.params.content;
    const message = req.params.message;
    
    if (type === 'status') {
        if (content === 'listening') {
             stopAudioPlayback(true)
             isThinking.value = true
             thinkingMessage.value = 'æ­£åœ¨å¬ä¸»äººè¯´è¯...'
             currentText.value = ''
        } else if (content === 'thinking') {
             isThinking.value = true
             thinkingMessage.value = message || 'åŠªåŠ›æ€è€ƒä¸­...'
             currentText.value = ''
        } else if (content === 'speaking') {
             isThinking.value = false
             thinkingMessage.value = 'åŠªåŠ›æ€è€ƒä¸­...'
        } else if (content === 'idle') {
             isThinking.value = false
             thinkingMessage.value = 'åŠªåŠ›æ€è€ƒä¸­...'
        }
    } else if (type === 'transcription') {
        console.log('ç”¨æˆ·è¯´:', content)
    } else if (type === 'text_response') {
        currentText.value = content
        isThinking.value = false
        thinkingMessage.value = 'åŠªåŠ›æ€è€ƒä¸­...'
        bubbleKey.value++;
    } else if (type === 'error') {
        console.error('è¯­éŸ³é”™è¯¯:', content)
        currentText.value = `(é”™è¯¯: ${content})`
        isThinking.value = false
    }
}

// Handler for Audio Stream (TTS)
const handleAudioStream = (stream) => {
    if (stream.data) {
        playAudio(stream.data)
    }
}

// Removed handleVoiceMessage (Legacy WS)
const handleVoiceMessage = (event) => {}

const stopAudioPlayback = (clearQueue = false) => {
    stopLipSync(); // Stop lip sync immediately
    if (clearQueue) {
        audioQueue.value = []
        isAudioPlaying.value = false
    }
    
    if (currentAudioSource.value) {
        try {
            currentAudioSource.value.stop()
        } catch (e) {
            // ignore
        }
        currentAudioSource.value = null
    }
    isSpeaking.value = false
}

const playAudio = async (base64Audio) => {
    if (!base64Audio) return
    audioQueue.value.push(base64Audio)
    if (!isAudioPlaying.value) {
        processAudioQueue()
    }
}

const startLipSync = (analyserNode) => {
    if (lipSyncFrame.value) cancelAnimationFrame(lipSyncFrame.value);

    const update = () => {
        if (!isSpeaking.value || !analyserNode) {
            if (avatarRef.value && avatarRef.value.setLipSync) {
                avatarRef.value.setLipSync(0);
            }
            return;
        }

        const dataArray = new Uint8Array(analyserNode.frequencyBinCount);
        analyserNode.getByteFrequencyData(dataArray);

        // Calculate average volume from relevant bins (voice range)
        // è®¡ç®—ç›¸å…³é¢‘æ®µï¼ˆäººå£°èŒƒå›´ï¼‰çš„å¹³å‡éŸ³é‡
        let sum = 0;
        const startBin = 2; // Skip very low rumble
        const endBin = 32;  // Focus on voice frequencies (approx 0-2.7kHz with 256 FFT/44.1k)
        for (let i = startBin; i < endBin; i++) {
            sum += dataArray[i];
        }
        const average = sum / (endBin - startBin);
        
        // Normalize (0-255 -> 0-1) and apply gain
        // å½’ä¸€åŒ– (0-255 -> 0-1) å¹¶åº”ç”¨å¢ç›Š
        // Multiply by 3.0 to make the mouth open more for normal speech
        const volume = Math.min(1.0, (average / 255) * 3.0);

        if (avatarRef.value && avatarRef.value.setLipSync) {
            avatarRef.value.setLipSync(volume);
        }

        lipSyncFrame.value = requestAnimationFrame(update);
    };
    update();
};

const stopLipSync = () => {
    if (lipSyncFrame.value) {
        cancelAnimationFrame(lipSyncFrame.value);
        lipSyncFrame.value = null;
    }
    if (avatarRef.value && avatarRef.value.setLipSync) {
        avatarRef.value.setLipSync(0);
    }
};

const processAudioQueue = async () => {
    if (audioQueue.value.length === 0) {
        isAudioPlaying.value = false
        isSpeaking.value = false
        return
    }

    isAudioPlaying.value = true
    const audioData = audioQueue.value.shift()

    isSpeaking.value = true
    
    let ctx = audioContext.value
    
    if (!ctx || ctx.state === 'closed') {
        ctx = new (window.AudioContext || window.webkitAudioContext)()
        audioContext.value = ctx
    }
    
    if (ctx.state === 'suspended') {
        try {
            await ctx.resume()
        } catch (e) {
            console.warn('[Pero] æ¢å¤ AudioContext å¤±è´¥:', e)
        }
    }
    
    try {
        let arrayBuffer;
        if (typeof audioData === 'string') {
             // Fallback for base64 string if any legacy path remains
             const binaryString = window.atob(audioData)
             const len = binaryString.length
             const bytes = new Uint8Array(len)
             for (let i = 0; i < len; i++) {
                 bytes[i] = binaryString.charCodeAt(i)
             }
             arrayBuffer = bytes.buffer;
        } else if (audioData instanceof Uint8Array) {
             // New path: Uint8Array from Protobuf
             // Need to copy to ArrayBuffer because decodeAudioData detaches it? 
             // Or just use .buffer. 
             // Note: Uint8Array.buffer might be the whole buffer of the message if it's a slice.
             // Safe way: new Uint8Array(audioData).buffer
             arrayBuffer = new Uint8Array(audioData).buffer;
        } else {
             throw new Error("æœªçŸ¥éŸ³é¢‘æ•°æ®ç±»å‹");
        }
        
        const audioBuffer = await ctx.decodeAudioData(arrayBuffer)
        
        const source = ctx.createBufferSource()
        source.buffer = audioBuffer
        currentAudioSource.value = source
        
        // Create Analyser for Lip Sync
        // åˆ›å»ºåˆ†æå™¨ç”¨äºå£å‹åŒæ­¥
        const analyserNode = ctx.createAnalyser()
        analyserNode.fftSize = 256
        analyser.value = analyserNode
        
        source.connect(analyserNode)
        analyserNode.connect(ctx.destination)
        
        source.start(0)
        startLipSync(analyserNode)
        
        source.onended = () => {
            currentAudioSource.value = null
            stopLipSync()
            source.disconnect()
            analyserNode.disconnect()
            processAudioQueue()
        }
        
    } catch (e) {
        console.error('[Pero] éŸ³é¢‘è§£ç é”™è¯¯:', e)
        processAudioQueue()
    }
}

// --- Global Key Handlers ---

const handleGlobalKeyDown = (e) => {
  if (isWorkMode.value) return

  // 1. Alt + V åˆ‡æ¢è¯­éŸ³æ¨¡å¼
  if (e.altKey && !e.shiftKey && e.code === 'KeyV') {
    e.preventDefault()
    cycleVoiceMode()
    return
  }

  // 2. Alt + Shift + V PTT
  if (e.altKey && e.shiftKey && e.code === 'KeyV' && voiceMode.value === 2 && !isPTTRecording.value) {
    e.preventDefault()
    startPTT()
  }
}

const handleGlobalKeyUp = (e) => {
  if (isWorkMode.value) return

  if (e.code === 'KeyV' && voiceMode.value === 2 && isPTTRecording.value) {
    stopPTT()
  }
}

// --- Agent Logic ---
const fetchActiveAgent = async () => {
    try {
        const res = await fetch(`${API_BASE}/agents`);
        if (res.ok) {
            const agents = await res.json();
            const active = agents.find(a => a.is_active);
            if (active) {
                currentAgentName.value = active.name;
                // TODO: Trigger model reload if needed
            }
        }
    } catch (e) { console.error('è·å–æ´»è·ƒ Agent å¤±è´¥:', e); }
};

// --- Lifecycle & IPC ---
let unlistenFunctions = [];

const setIgnoreMouse = (ignore) => {
  if (window._lastIgnoreState === ignore) return;
  window._lastIgnoreState = ignore;
  invoke('set_ignore_mouse', ignore).catch(e => console.error("set_ignore_mouse å¤±è´¥", e));
}

const onHoverStart = () => {
  setIgnoreMouse(false);
}

const onHoverEnd = () => {
  if (!isDragging.value) {
    setIgnoreMouse(true);
  }
}

const onUIEnter = () => {
    setIgnoreMouse(false);
}

const onUILeave = () => {
    // Only set to true if not hovering character and not dragging
    if (!isDragging.value) {
        setIgnoreMouse(true);
    }
}

// Dragging State
let startX = 0;
let startY = 0;
const isDragging = ref(false);

const onMouseDown = (e) => {
    // Only start drag logic if left click
    if (e.button !== 0) return;
    
    startX = e.screenX;
    startY = e.screenY;
    
    const onMouseMove = (moveEvent) => {
        const movedX = Math.abs(moveEvent.screenX - startX);
        const movedY = Math.abs(moveEvent.screenY - startY);
        
        if (!isDragging.value && (movedX > 5 || movedY > 5)) {
            isDragging.value = true;
            // Tell main process to start dragging
            const offsetX = e.screenX - window.screenX;
            const offsetY = e.screenY - window.screenY;
            
            if (window.electron && window.electron.send) {
                window.electron.send('window-drag-start', { offsetX, offsetY });
            } else {
                invoke('window-drag-start', { offsetX, offsetY }).catch(() => {});
            }
        }
    }
    
    const onMouseUp = () => {
        window.removeEventListener('mousemove', onMouseMove);
        window.removeEventListener('mouseup', onMouseUp);
        
        if (isDragging.value) {
            isDragging.value = false;
            
            if (window.electron && window.electron.send) {
                window.electron.send('window-drag-end');
            } else {
                invoke('window-drag-end').catch(() => {});
            }

            // Reset transparency check
            setIgnoreMouse(false); // Keep false for a moment to prevent flicker? Or re-evaluate.
            // Actually if we are over the character, it should stay false.
            // If we dragged off, it might need to go true.
            // But BedrockAvatar will emit hover-end if we move off.
        }
    }
    
    window.addEventListener('mousemove', onMouseMove);
    window.addEventListener('mouseup', onMouseUp);
}

// Attach drag listener to container (captures events from BedrockAvatar too)
// BedrockAvatar uses Three.js, so we might need to handle mousedown there.
// But we can listen on the window or container 'mousedown.capture'

onMounted(async () => {
  fetchActiveAgent();
  loadLocalTexts();
  
  // 1. Initial Mouse Transparency
  await invoke('set_ignore_mouse', true);

  // Attach Drag Listener
  window.addEventListener('mousedown', onMouseDown);
  
  // Attach Key Listeners
  window.addEventListener('keydown', handleGlobalKeyDown);
  window.addEventListener('keyup', handleGlobalKeyUp);
  
  // ... rest of listeners ...
  // Backend Log -> Thinking Bubble
  const unlistenLog = await listen('backend-log', (event) => {
    console.log('[Backend]', event.payload);
    // Simple logic: if log contains "Thinking", show it
    if (typeof event.payload === 'string' && event.payload.includes('Thinking')) {
        currentText.value = "æ­£åœ¨æ€è€ƒ...";
        isThinking.value = true;
    }
  });
  unlistenFunctions.push(unlistenLog);

  // Status Updates
  const unlistenMood = await listen('update-mood', (event) => {
    moodText.value = event.payload;
    localStorage.setItem('ppc.mood', event.payload);
  });
  unlistenFunctions.push(unlistenMood);

  const unlistenVibe = await listen('update-vibe', (event) => {
    vibeText.value = event.payload;
    localStorage.setItem('ppc.vibe', event.payload);
  });
  unlistenFunctions.push(unlistenVibe);

  const unlistenMind = await listen('update-mind', (event) => {
    mindText.value = event.payload;
    localStorage.setItem('ppc.mind', event.payload);
  });
  unlistenFunctions.push(unlistenMind);

  // Work Mode
  const unlistenWorkMode = await listen('work-mode-changed', (event) => {
      isWorkMode.value = event.payload.is_work_mode;
      if (isWorkMode.value) {
          currentText.value = 'è¿›å…¥å·¥ä½œæ¨¡å¼ (Session Isolated)';
      } else {
          currentText.value = 'å·¥ä½œè¾›è‹¦å•¦ï¼';
      }
  });
  unlistenFunctions.push(unlistenWorkMode);
  
  // Chat Sync (Agent Reply)
  const unlistenChat = await listen('sync-chat-to-pet', (event) => {
      if (isWorkMode.value) return;
      const { role, content } = event.payload;
      if (role === 'assistant') {
          currentText.value = content;
          isThinking.value = false;
          // Trigger bubble expand
          isBubbleExpanded.value = true;
          bubbleKey.value++;
      }
  });
  unlistenFunctions.push(unlistenChat);

  // File Search
  const unlistenSearch = await listen('file-search-result', (event) => {
    foundFiles.value = event.payload;
    showFileModal.value = true;
  });
  unlistenFunctions.push(unlistenSearch);

  // Reminder Trigger (from Gateway)
  gatewayClient.on('action:reminder_trigger', (params) => {
    const content = params.content || 'æé†’æ—¶é—´åˆ°ï¼';
    
    // 1. Show Bubble
    currentText.value = `â° ${content}`;
    isBubbleExpanded.value = true;
    bubbleKey.value++;
    
    // 2. Play Sound / TTS
    if (voiceMode.value !== 0) {
        // Use browser native TTS for instant feedback
        if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance(content);
            // Try to find a Chinese voice
            const voices = window.speechSynthesis.getVoices();
            const zhVoice = voices.find(v => v.lang.includes('zh'));
            if (zhVoice) utterance.voice = zhVoice;
            window.speechSynthesis.speak(utterance);
        }
    }
    
    // 3. Desktop Notification (Native)
    if (window.electron && window.electron.send) {
        window.electron.send('show-notification', { title: 'Pero æé†’', body: content });
    }
  });

// Global Mouse Tracking (Fix for character not following mouse when outside window)
if (window.electron && window.electron.on) {
    const cleanupMouse = window.electron.on('global-mouse-move', (_event, { x, y }) => {
        const winW = window.innerWidth;
        const winH = window.innerHeight;
        
        // 1. Direct update to avatar (More reliable than event dispatch)
        if (avatarRef.value && avatarRef.value.setGlobalMouse) {
            avatarRef.value.setGlobalMouse(x, y);
        }

    // 2. Dispatch event for other listeners (fallback)
    // Only dispatch if outside window bounds to avoid double events
    if (x < 0 || x > winW || y < 0 || y > winH) {
        const mouseEvent = new MouseEvent('mousemove', {
            clientX: x,
            clientY: y,
            bubbles: true,
            cancelable: true,
            view: window
        });
        window.dispatchEvent(mouseEvent);
    }
            });
            unlistenFunctions.push(cleanupMouse);
        } else {
            console.warn('window.electron not found, global mouse tracking disabled');
        }
});

onUnmounted(() => {
  if (bubbleTimer) {
    clearTimeout(bubbleTimer);
    bubbleTimer = null;
  }
  unlistenFunctions.forEach(fn => fn());
  unlistenFunctions = [];
  window.removeEventListener('mousedown', onMouseDown);
});

const toggleUI = () => {
  showInput.value = !showInput.value;
  if (!showInput.value) {
    showAppearanceMenu.value = false;
  }
};

const toggleAppearanceMenu = () => {
  showAppearanceMenu.value = !showAppearanceMenu.value;
}

const loadLocalTexts = async () => {
  try {
    const response = await fetch('live2d-widget/waifu-texts.json');
    const baseTexts = await response.json();
    const storageKey = `ppc.waifu.texts.${currentAgentName.value || 'default'}`; 
    let dynamicTexts = {};
    try {
      const saved = localStorage.getItem(storageKey);
      if (saved) dynamicTexts = JSON.parse(saved);
    } catch (e) {
      console.warn('Failed to parse dynamic texts from localStorage:', e);
    }
    localTexts.value = { ...baseTexts, ...dynamicTexts };
    console.log('Local texts loaded:', Object.keys(localTexts.value).length);
  } catch (err) {
    console.error('Failed to load local texts:', err);
    // Fallback
    localTexts.value = {
        "click_head_01": "å˜¿å˜¿ï¼Œå¥½ç—’å‘€~",
        "click_head_02": "æ˜¯åœ¨æ‘¸æ‘¸å¤´å—ï¼Ÿ",
        "click_body_01": "ä¸è¦æˆ³é‚£é‡Œå•¦ï¼",
        "click_messages_01": "è¦ç‰µæ‰‹æ‰‹å—ï¼Ÿ"
    };
  }
}

const getRandomLocalText = (category) => {
    if (!localTexts.value) return null;
    
    // Find keys starting with category (e.g. 'click_head')
    const keys = Object.keys(localTexts.value).filter(k => k.startsWith(category));
    if (keys.length === 0) return null;
    
    const randomKey = keys[Math.floor(Math.random() * keys.length)];
    return localTexts.value[randomKey];
}

const onPet = (event) => {
  // console.log('Pet detected:', event);
  
  let text = null;
  
  switch(event.type) {
    case 'head':
      text = getRandomLocalText('click_head');
      if (!text) text = "å˜¿å˜¿ï¼Œå¥½ç—’å‘€~";
      break;
    case 'arm':
      text = getRandomLocalText('click_messages'); // Generic interaction
      if (!text) text = "è¦ç‰µæ‰‹æ‰‹å—ï¼Ÿ";
      break;
    case 'body':
      // Try chest first, then body
      text = getRandomLocalText('click_chest') || getRandomLocalText('click_body');
      if (!text) text = "ä¸è¦æˆ³é‚£é‡Œå•¦ï¼";
      break;
    case 'leg':
      text = getRandomLocalText('click_body') || getRandomLocalText('click_messages');
      if (!text) text = "è£™å­ä¸èƒ½æ€ï¼";
      break;
    default:
      text = getRandomLocalText('click_messages');
  }

  // console.log('Selected text:', text);

  // Fallback
  if (!text) {
      text = "å—¯ï¼Ÿ";
  }

  // Force re-render for immediate visual feedback even if text is same
  currentText.value = text;
  isBubbleExpanded.value = true;
  bubbleKey.value++; 
  
  // Random vertical offset (12% to 18%)
  const randomTop = 12 + Math.random() * 6;
  bubbleTop.value = `${randomTop}%`;

  // Random horizontal offset (-10% to 10%)
  // Since we use translate(-50%, 0), adding margin-left or just changing left is easiest.
  // Let's use calc for left: 50% + offset
  const randomLeftOffset = (Math.random() * 40 - 20); // -20px to 20px approx equivalent in %
  // Actually let's use pixels for horizontal shift to be safe with narrow bubbles
  // Or just percentage: -5% to 5%
  const randomLeftPct = (Math.random() * 10 - 5);
  // We can bind 'left' style
  // Default is left: 50%, transform: translateX(-50%)
  // We can adjust the left percentage directly
  bubbleLeft.value = `${50 + randomLeftPct}%`;
};

const sendMessage = async () => {
    if (!userInput.value.trim()) return;
    if (isThinking.value) return;
    
    const text = userInput.value;
    userInput.value = '';
    isThinking.value = true;
    currentText.value = "æ€è€ƒä¸­...";
    
    try {
        await invoke('chat-message', { message: text });
    } catch (e) {
        console.error('Send message failed:', e);
        isThinking.value = false;
        currentText.value = "å‘é€å¤±è´¥...";
    }
}

// ç›‘å¬åç«¯å›å¤
onMounted(async () => {
    // ç›‘å¬ Gateway æ¶ˆæ¯ï¼ˆé€šè¿‡ IPC æˆ– WebSocketï¼‰
    // å‡è®¾åç«¯é€šè¿‡ Gateway å¹¿æ’­ 'action:text_response'
    gatewayClient.on('action:text_response', (data) => {
        const content = data.content;
        currentText.value = content;
        isThinking.value = false;
        isBubbleExpanded.value = true;
        bubbleKey.value++;
    });
    
    // ç›‘å¬çŠ¶æ€æ›´æ–°
    gatewayClient.on('action:voice_update', handleVoiceUpdateRequest);
    
    // ç›‘å¬ TTS éŸ³é¢‘æµ
    gatewayClient.on('stream', handleAudioStream);
    
    // åˆå§‹åŒ–æ—¶è¿æ¥ Gateway
    // (å¦‚æœ App.vue æˆ–å…¶ä»–åœ°æ–¹å·²ç»è¿æ¥ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦è°ƒæ•´ï¼Œä½† GatewayClient æ˜¯å•ä¾‹æˆ–å…±äº«çš„å—ï¼Ÿ)
    // å‡è®¾ gatewayClient æ˜¯å…¨å±€å¯¼å…¥çš„å•ä¾‹
});

const windowSizes = [
    { width: 600, height: 600 },
    { width: 800, height: 800 },
    { width: 1000, height: 1000 },
    { width: 1200, height: 1200 }
];
const currentSizeIndex = ref(1); // Default 800x800

const toggleWindowSize = () => {
    currentSizeIndex.value = (currentSizeIndex.value + 1) % windowSizes.length;
    const size = windowSizes[currentSizeIndex.value];
    if (window.electron && window.electron.send) {
        window.electron.send('resize-pet-window', size);
    }
};

const reloadPet = () => {
    window.location.reload();
}


const openChatWindow = () => {
    invoke('open_ide_window').catch(console.error);
}

const openDashboard = () => {
    invoke('open_dashboard').catch(console.error);
}
</script>

<style scoped>
/* Ensure the container takes full window space and supports transparency */
.pet-3d-container {
  width: 100vw;
  height: 100vh;
  margin: 0;
  padding: 0;
  background: transparent; /* Crucial for Electron transparent window */
  overflow: hidden;
  position: relative;
  display: flex;
  justify-content: center;
  align-items: center;
  /* Use a pixel font if available, or a clean sans-serif */
  font-family: 'Segoe UI', sans-serif; 
}

.ui-overlay {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none; /* Let clicks pass through to 3D scene/desktop */
  display: flex;
  justify-content: center;
  align-items: center;
}

/* Minecraft/RPG Style Bubble */
.bubble {
  position: absolute;
  transform: translateX(-50%);
  
  /* Voxel Style */
  /* Voxel é£æ ¼ */
  background-color: rgba(20, 20, 20, 0.85);
  border: 2px solid #e0e0e0;
  border-radius: 4px;
  padding: 12px 16px;
  z-index: 100;
  max-width: 280px;
  
  /* Hard shadow */
  /* ç¡¬é˜´å½± */
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5); 
  
  pointer-events: auto;
  animation: bubble-float 3s infinite ease-in-out;
  display: flex;
  flex-direction: column;
  transition: all 0.2s steps(4);
  
  color: #ffffff;
  font-family: 'Consolas', 'Monaco', monospace;
  font-size: 14px;
  line-height: 1.5;
  text-shadow: 1px 1px 0 #000;
}

.bubble:hover {
  transform: scale(1.02);
  background-color: rgba(30, 30, 30, 0.95);
  border-color: #ffffff;
  z-index: 110;
}

/* Pixel Tail */
/* åƒç´ é£æ ¼å°¾å·´ */
.bubble-tail {
  position: absolute;
  bottom: -6px;
  left: 50%;
  transform: translateX(-50%);
  width: 0;
  height: 0;
  border-left: 6px solid transparent;
  border-right: 6px solid transparent;
  border-top: 6px solid #e0e0e0;
}

.bubble-tail::after {
  content: '';
  position: absolute;
  top: -9px; 
  left: -4px;
  width: 0;
  height: 0;
  border-left: 4px solid transparent;
  border-right: 4px solid transparent;
  border-top: 4px solid rgba(20, 20, 20, 0.85);
}

.bubble-content {
  cursor: pointer;
}

.bubble.expanded {
  max-height: 500px;
  overflow-y: auto;
}

.bubble.expanded::-webkit-scrollbar {
  width: 6px;
}
.bubble.expanded::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.3);
}
.bubble.expanded::-webkit-scrollbar-thumb {
  background: #888;
  border-radius: 0;
  border: 1px solid #444;
}
.bubble.expanded::-webkit-scrollbar-thumb:hover {
  background: #aaa;
}

.bubble-scroll-area {
  max-height: 200px;
  overflow: hidden;
  transition: max-height 0.3s ease;
  position: relative;
}

.bubble.expanded .bubble-scroll-area {
  max-height: 500px;
  overflow-y: auto;
}

.bubble-expand-btn {
  font-size: 12px;
  color: #aaaaaa;
  text-align: center;
  margin-top: 8px;
  cursor: pointer;
  padding-top: 4px;
  border-top: 1px dashed #666;
  user-select: none;
  font-family: 'Consolas', monospace;
}

.bubble-expand-btn:hover {
  color: #ffffff;
  font-weight: bold;
}

.thinking-text {
  color: #aaaaaa;
  font-style: italic;
  display: flex;
  align-items: center;
  font-family: 'Consolas', monospace;
}

.thinking-text::after {
  content: "...";
  display: inline-block;
  width: 12px;
  animation: thinking-dots 1.5s infinite;
}

@keyframes thinking-dots {
  0% { content: "."; }
  33% { content: ".."; }
  66% { content: "..."; }
}

.thinking-block {
  margin: 12px 0;
  background: rgba(0, 0, 0, 0.3);
  border-radius: 4px;
  border: 1px solid #555;
  overflow: hidden;
}

.thinking-label {
  padding: 4px 8px;
  background: rgba(50, 50, 50, 0.5);
  font-size: 11px;
  font-weight: bold;
  color: #ccc;
  border-bottom: 1px solid #555;
  font-family: 'Consolas', monospace;
}

.thinking-content {
  padding: 8px;
  font-family: 'Consolas', monospace;
  font-size: 12px;
  color: #ddd;
  white-space: pre-wrap;
  background: rgba(0, 0, 0, 0.2);
}

.action-text {
  color: #aaddff;
  font-style: italic;
  font-size: 0.95em;
  margin: 0 2px;
}

@keyframes bubble-float {
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-4px); }
}

.bubble-fade-enter-active {
  transition: all 0.15s cubic-bezier(0.175, 0.885, 0.32, 1.275);
}
.bubble-fade-leave-active {
  transition: opacity 0.1s ease-out;
  position: absolute;
}
.bubble-fade-enter-from {
  opacity: 0;
  transform: translateX(-50%) scale(0.8) translateY(10px);
}
.bubble-fade-leave-to {
  opacity: 0;
  transform: translateX(-50%) scale(1.1);
}

/* Status Tags (Voxel) */
/* çŠ¶æ€æ ‡ç­¾ (Voxel) */
.status-tags {
  position: absolute;
  left: 50%; 
  top: 50%;
  transform: translate(-320px, -250px);
  display: flex;
  flex-direction: column;
  gap: 12px;
  perspective: 1000px;
  align-items: flex-end;
  pointer-events: auto;
}

.status-tag {
  background: rgba(20, 20, 20, 0.85);
  padding: 8px 14px;
  border-radius: 4px;
  font-size: 12px;
  font-weight: bold;
  color: #ffffff;
  border: 2px solid #e0e0e0;
  white-space: nowrap;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  max-width: 160px;
  overflow: hidden;
  text-overflow: ellipsis;
  display: flex;
  align-items: center;
  gap: 8px;
  transition: all 0.2s;
  cursor: default;
  font-family: 'Consolas', monospace;
  text-shadow: 1px 1px 0 #000;
}

.status-tag:hover {
  transform: translateX(-5px);
  background: rgba(40, 40, 40, 0.95);
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  z-index: 110;
  border-color: #ffffff;
}

.status-tag.mood {
  border-color: #ff88aa;
  color: #ffccdd;
}

.status-tag.vibe {
  border-color: #88ccff;
  color: #cceeff;
}

.status-tag.mind {
  border-color: #88ffaa;
  color: #ccffdd;
  white-space: normal;
  max-width: 180px;
  word-break: break-all;
  line-height: 1.4;
  padding: 8px 12px;
  align-items: flex-start;
}

@keyframes float-tag {
  /* Reduced float for voxel style */
  /* å‡å°‘ Voxel é£æ ¼çš„æµ®åŠ¨ */
  0%, 100% { transform: translateY(0); }
  50% { transform: translateY(-2px); }
}

/* Floating Trigger (Voxel Cube) */
/* æ‚¬æµ®è§¦å‘å™¨ (Voxel ç«‹æ–¹ä½“) */
.floating-trigger {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(140px, -50%);
  width: 44px;
  height: 44px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  z-index: 100;
  pointer-events: auto;
}

.trigger-core {
  position: relative;
  width: 24px;
  height: 24px;
  transition: all 0.3s ease;
  animation: core-idle 4s infinite ease-in-out;
}

@keyframes core-idle {
  0% { transform: translateY(0) rotate(0deg); }
  25% { transform: translateY(-3px) rotate(15deg); }
  50% { transform: translateY(0) rotate(0deg); }
  75% { transform: translateY(3px) rotate(-15deg); }
  100% { transform: translateY(0) rotate(0deg); }
}

.core-dot {
  position: absolute;
  width: 100%;
  height: 100%;
  background: rgba(255, 255, 255, 0.95);
  border-radius: 4px; /* Slightly more rounded */
  transition: all 0.2s ease;
  box-shadow: 
    0 0 15px rgba(255, 255, 255, 0.6),
    2px 2px 0px rgba(0, 0, 0, 0.3);
  border: 2px solid #fff;
}

.pulse-ring {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 2px solid rgba(255, 255, 255, 0.5);
  border-radius: 4px;
  opacity: 0;
  animation: pulse-ring-smooth 2s infinite cubic-bezier(0.215, 0.61, 0.355, 1);
  box-sizing: border-box;
}

@keyframes pulse-ring-smooth {
  0% { transform: scale(0.8) rotate(0deg); opacity: 0.8; border-width: 2px; }
  50% { opacity: 0.5; }
  100% { transform: scale(2.4) rotate(90deg); opacity: 0; border-width: 0px; }
}

.floating-trigger:hover .trigger-core {
  animation-play-state: paused;
  transform: scale(1.1) rotate(45deg);
}

.floating-trigger:hover .core-dot {
  background: #ffffff;
  transform: scale(1.0);
  box-shadow: 
    0 0 20px rgba(255, 255, 255, 1),
    0 0 40px rgba(255, 255, 255, 0.6);
}

.floating-trigger.active .trigger-core {
  transform: rotate(45deg);
}

.floating-trigger.active .core-dot {
  background: #ff88aa;
  border-color: #ffccdd;
  box-shadow: 0 0 15px rgba(255, 136, 170, 0.6);
}

.floating-trigger.active .pulse-ring {
  border-color: rgba(255, 136, 170, 0.5);
  animation-duration: 1.5s;
}

.fade-enter-active,
.fade-leave-active {
  transition: opacity 0.2s ease;
}

.fade-enter-from,
.fade-leave-to {
  opacity: 0;
}

.input-overlay {
  position: absolute;
  bottom: 80px;
  left: 50%;
  transform: translateX(-50%);
  -webkit-app-region: no-drag;
  perspective: 1000px;
  pointer-events: auto;
}

.chat-input {
  background: rgba(20, 20, 20, 0.85);
  backdrop-filter: blur(4px);
  -webkit-backdrop-filter: blur(4px);
  border: 2px solid #e0e0e0;
  border-radius: 4px;
  padding: 10px 16px;
  width: 240px;
  outline: none;
  font-size: 14px;
  font-weight: 500;
  color: #ffffff;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  transition: all 0.2s;
  font-family: 'Consolas', monospace;
}

.chat-input::placeholder {
  color: #888;
  font-weight: 400;
}

.chat-input:focus {
  width: 280px;
  background: rgba(30, 30, 30, 0.95);
  border-color: #ffffff;
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  transform: translateY(-2px);
  color: #ffffff;
}

.pet-tools {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(200px, -50%);
  display: flex;
  flex-direction: column;
  gap: 12px;
  background: rgba(20, 20, 20, 0.7);
  backdrop-filter: blur(4px);
  -webkit-backdrop-filter: blur(4px);
  padding: 8px;
  border-radius: 6px;
  -webkit-app-region: no-drag;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  border: 2px solid #666;
  pointer-events: auto;
}

.tool-btn {
  background: rgba(40, 40, 40, 0.8);
  border: 2px solid #888;
  width: 38px;
  height: 38px;
  border-radius: 4px;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 18px;
  transition: all 0.15s;
  box-shadow: 2px 2px 0px rgba(0, 0, 0, 0.5);
  color: #ddd;
}

.tool-btn:hover, .tool-btn.active {
  transform: translate(-1px, -1px);
  background: #555;
  border-color: #fff;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.6);
  color: #fff;
}

.tool-btn:active {
  transform: translate(2px, 2px);
  box-shadow: 0px 0px 0px rgba(0, 0, 0, 0.5);
}

.voice-btn.active.mode-vad {
  color: #ff99cc;
  border-color: #ff99cc;
}

.voice-btn.active.mode-ptt {
  color: #5fb878;
  border-color: #5fb878;
}

/* Appearance Menu (Voxel) */
.appearance-menu {
  position: absolute;
  left: 50%;
  top: 55%;
  transform: translate(-320px, -50%);
  background: rgba(20, 20, 20, 0.95);
  border: 2px solid #fff;
  border-radius: 6px;
  padding: 12px;
  width: 200px;
  color: white;
  box-shadow: 6px 6px 0px rgba(0,0,0,0.6);
  pointer-events: auto;
  font-family: 'Consolas', monospace;
  z-index: 101;
}

.menu-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 12px;
  padding-bottom: 8px;
  border-bottom: 2px solid #444;
  font-weight: bold;
}

.close-mini-btn {
  background: none;
  border: none;
  color: #888;
  cursor: pointer;
  font-size: 18px;
  line-height: 1;
}
.close-mini-btn:hover {
  color: #fff;
}

.menu-section {
  margin-bottom: 12px;
}

.menu-label {
  font-size: 11px;
  color: #aaa;
  margin-bottom: 6px;
  text-transform: uppercase;
}

.voxel-checkbox {
  display: flex;
  align-items: center;
  gap: 8px;
  margin-bottom: 6px;
  cursor: pointer;
  font-size: 13px;
  user-select: none;
}

.voxel-checkbox input {
  display: none;
}

.voxel-checkbox .checkmark {
  width: 16px;
  height: 16px;
  background: #333;
  border: 2px solid #888;
  position: relative;
  display: inline-block;
  transition: all 0.1s;
}

.voxel-checkbox:hover .checkmark {
  border-color: #fff;
}

.voxel-checkbox input:checked + .checkmark {
  background: #ff88aa;
  border-color: #fff;
}

.voxel-checkbox input:checked + .checkmark::after {
  content: '';
  position: absolute;
  left: 4px;
  top: 1px;
  width: 4px;
  height: 8px;
  border: solid white;
  border-width: 0 2px 2px 0;
  transform: rotate(45deg);
}

.voxel-select {
  width: 100%;
  padding: 6px;
  background: #333;
  border: 2px solid #888;
  color: white;
  font-family: inherit;
  cursor: pointer;
  outline: none;
}
.voxel-select:hover {
  border-color: #fff;
}

/* PTT Button (Voxel) */
.ptt-voxel-container {
  position: absolute;
  left: 50%;
  bottom: 70px;
  top: auto;
  transform: translateX(-220px);
  z-index: 100;
  pointer-events: auto;
}

.ptt-voxel-btn {
  background: rgba(40, 40, 40, 0.9);
  border: 2px solid #888;
  border-radius: 50%;
  width: 64px;
  height: 64px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  box-shadow: 4px 4px 0px rgba(0, 0, 0, 0.5);
  transition: all 0.1s;
  color: #ddd;
}

.ptt-voxel-btn:hover {
  transform: translate(-1px, -1px);
  background: #555;
  border-color: #fff;
  box-shadow: 6px 6px 0px rgba(0, 0, 0, 0.6);
  color: #fff;
}

.ptt-voxel-btn:active {
  transform: translate(2px, 2px);
  box-shadow: 0px 0px 0px rgba(0, 0, 0, 0.5);
}

.ptt-voxel-btn.recording {
  background: #ff4444;
  border-color: #ffcccc;
  color: white;
  animation: pulse-recording 1.5s infinite;
}

.ptt-icon {
  font-size: 24px;
  line-height: 1;
}

.ptt-text {
  font-size: 9px;
  margin-top: 4px;
  font-weight: bold;
  font-family: 'Consolas', monospace;
  letter-spacing: 1px;
}

@keyframes pulse-recording {
  0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 68, 68, 0.7); }
  70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(255, 68, 68, 0); }
  100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 68, 68, 0); }
}
</style>